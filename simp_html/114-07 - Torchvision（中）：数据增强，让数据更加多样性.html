
                <html lang="en" class="simpread-font simpread-theme-root" style=''>
                    <head>
                        <meta charset="utf-8">
                        <meta http-equiv="content-type" content="text/html; charset=UTF-8;charset=utf-8">
                        <meta http-equiv="X-UA-Compatible" content="IE=Edge">
                        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
                        <meta name="author" content="Kenshin"/>
                        <meta name="description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展" />
                        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, 简悦, 简阅, read mode, reading mode, reader view, firefox, firefox addon, userscript, safari, opera, tampermonkey"/>
                        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:title" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <meta property="og:type" content="website">
                        <meta property="og:local" content="zh_CN"/>
                        <meta property="og:url" content="http://ksria.com/simpread"/>
                        <meta property="og:image" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:image:type" content="image/png"/>
                        <meta property="og:image:width" content="960"/>
                        <meta property="og:image:height" content="355"/>
                        <meta property="og:site_name" content="http://ksria.com/simpread"/>
                        <meta property="og:description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <style type="text/css">.simpread-font{font:300 16px/1.8 -apple-system,PingFang SC,Microsoft Yahei,Lantinghei SC,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#333;text-rendering:optimizelegibility;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased}.simpread-hidden{display:none}.simpread-read-root{display:-webkit-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;margin:0;top:-1000px;left:0;width:100%;z-index:2147483646;overflow-x:hidden;opacity:0;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}.simpread-read-root-show{top:0}.simpread-read-root-hide{top:1000px}sr-read{display:-webkit-flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-flow:column nowrap;flex-flow:column;margin:20px 20%;min-width:400px;min-height:400px;text-align:center}read-process{position:fixed;top:0;left:0;height:3px;width:100%;background-color:#64b5f6;-webkit-transition:width 2s;transition:width 2s;z-index:20000}sr-rd-content-error{display:block;position:relative;margin:0;margin-bottom:30px;padding:25px;background-color:rgba(0,0,0,.05)}sr-rd-footer{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column;font-size:14px}sr-rd-footer,sr-rd-footer-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}sr-rd-footer-group{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-rd-footer-line{width:100%;border-top:1px solid #e0e0e0}sr-rd-footer-text{min-width:150px}sr-rd-footer-copywrite{margin:10px 0 0;color:inherit}sr-rd-footer-copywrite abbr{-webkit-font-feature-settings:normal;font-feature-settings:normal;font-variant:normal;text-decoration:none}sr-rd-footer-copywrite .second{margin:10px 0}sr-rd-footer-copywrite .third a:hover{border:none!important}sr-rd-footer-copywrite .third a:first-child{margin-right:50px}sr-rd-footer-copywrite .sr-icon{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:33px;height:33px;opacity:.8;-webkit-transition:opacity .5s ease;transition:opacity .5s ease;cursor:pointer}sr-rd-footer-copywrite .sr-icon:hover{opacity:1}sr-rd-footer-copywrite a,sr-rd-footer-copywrite a:link,sr-rd-footer-copywrite a:visited{margin:0;padding:0;color:inherit;background-color:transparent;font-size:inherit!important;line-height:normal;text-decoration:none;vertical-align:baseline;vertical-align:initial;border:none!important;box-sizing:border-box}sr-rd-footer-copywrite a:focus,sr-rd-footer-copywrite a:hover,sr-rd-footer a:active{color:inherit;text-decoration:none;border-bottom:1px dotted!important}.simpread-blocks{text-decoration:none!important}.simpread-blocks *{margin:0}.simpread-blocks a{padding:0;text-decoration:none!important}.simpread-blocks img{margin:0;padding:0;border:0;background:transparent;box-shadow:none}.simpread-focus-root{display:block;position:fixed;top:0;left:0;right:0;bottom:0;background-color:hsla(0,0%,92%,.9);z-index:2147483645;opacity:0;-webkit-transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms;transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms}.simpread-focus-highlight{position:relative;box-shadow:0 0 0 20px #fff;background-color:#fff;overflow:visible;z-index:2147483646}.sr-controlbar-bg sr-rd-crlbar,.sr-controlbar-bg sr-rd-crlbar fab{z-index:2147483647}sr-rd-crlbar.controlbar{position:fixed;right:0;bottom:0;width:100px;height:100%;opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}sr-rd-crlbar.controlbar:hover{opacity:1}sr-rd-crlbar fap *{box-sizing:border-box}@media (max-height:620px){fab{zoom:.8}}@media (max-height:783px){dialog-gp dialog-content{max-height:580px}dialog-gp dialog-footer{border-top:1px solid #e0e0e0}}.simpread-highlight-selector{outline:3px dashed #1976d2!important;cursor:pointer!important}.simpread-highlight-controlbar,.simpread-highlight-selector{background-color:#fafafa!important;opacity:.8!important;-webkit-transition:opacity .5s ease!important;transition:opacity .5s ease!important}.simpread-highlight-controlbar{position:relative!important;border:3px dashed #1976d2!important}simpread-highlight,sr-snapshot-ctlbar{position:fixed;top:0;left:0;right:0;padding:15px;height:50px;background-color:rgba(50,50,50,.9);box-shadow:0 2px 5px rgba(0,0,0,.26);box-sizing:border-box;z-index:2147483640}simpread-highlight,sr-highlight-ctl,sr-snapshot-ctlbar{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-highlight-ctl{margin:0 5px;width:50px;height:20px;color:#fff;background-color:#1976d2;border-radius:4px;box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12);cursor:pointer}toc-bg{position:fixed;left:0;top:0;width:50px;height:200px;font-size:medium}toc-bg:hover{z-index:3}.toc-bg-hidden{opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}.toc-bg-hidden:hover{opacity:1;z-index:3}.toc-bg-hidden:hover toc{width:180px}toc *{all:unset}toc{position:fixed;left:0;top:100px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;padding:10px;width:0;max-width:200px;max-height:500px;overflow-x:hidden;overflow-y:hidden;cursor:pointer;border:1px solid hsla(0,0%,62%,.22);-webkit-transition:width .5s;transition:width .5s}toc:hover{overflow-y:auto}toc.mini:hover{width:200px!important}toc::-webkit-scrollbar{width:3px}toc::-webkit-scrollbar-thumb{border-radius:10px;background-color:hsla(36,2%,54%,.5)}toc outline{position:relative;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;padding:2px 0;min-height:21px;line-height:21px;text-align:left}toc outline a,toc outline a:active,toc outline a:focus,toc outline a:visited{display:block;width:100%;color:inherit;font-size:11px;text-decoration:none!important;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}toc outline a:hover{font-weight:700!important}toc outline a.toc-outline-theme-dark,toc outline a.toc-outline-theme-night{color:#fff!important}.toc-level-h1{padding-left:5px}.toc-level-h2{padding-left:15px}.toc-level-h3{padding-left:25px}.toc-level-h4{padding-left:35px}.toc-outline-active{border-left:2px solid #f44336}toc outline active{position:absolute;left:0;top:0;bottom:0;padding:0 0 0 3px;border-left:2px solid #e8e8e8}sr-kbd{background:-webkit-gradient(linear,0 0,0 100%,from(#fff785),to(#ffc542));border:1px solid #e3be23;-o-border-image:none;border-image:none;-o-border-image:initial;border-image:initial;position:absolute;left:0;padding:1px 3px 0;font-size:11px!important;font-weight:700;box-shadow:0 3px 7px 0 rgba(0,0,0,.3);overflow:hidden;border-radius:3px}.sr-kbd-a{position:relative}kbd-mapping{position:fixed;left:5px;bottom:5px;-ms-flex-flow:row;flex-flow:row;width:250px;height:500px;background-color:#fff;border:1px solid hsla(0,0%,62%,.22);box-shadow:0 2px 5px rgba(0,0,0,.26);border-radius:3px}kbd-mapping,kbd-maps{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}kbd-maps{margin:40px 0 20px;width:100%;overflow-x:auto}kbd-maps::-webkit-scrollbar-thumb{background-clip:padding-box;border-radius:10px;border:2px solid transparent;background-color:rgba(85,85,85,.55)}kbd-maps::-webkit-scrollbar{width:10px;-webkit-transition:width .7s cubic-bezier(.4,0,.2,1);transition:width .7s cubic-bezier(.4,0,.2,1)}kbd-mapping kbd-map-title{position:absolute;margin:5px 0;width:100%;font-size:14px;font-weight:700}kbd-maps-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}kbd-maps-title{margin:5px 0;padding-left:53px;font-size:12px;font-weight:700}kbd-map kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fafbfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}kbd-map kbd-name{display:inline-block;text-align:right;width:50px}kbd-map kbd-desc{padding-left:3px}sharecard-bg{position:fixed;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,.4);z-index:2147483647}sharecard{max-width:450px;background-color:#64b5f6}sharecard,sharecard-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-head{margin:25px;color:#fff;border-radius:10px;box-shadow:0 2px 6px 0 rgba(0,0,0,.2),0 25px 50px 0 rgba(0,0,0,.15)}sharecard-card{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-card,sharecard-top{display:-webkit-box;display:-ms-flexbox;display:flex}sharecard-top{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:65px;background-color:#fff;color:#878787;font-size:25px;font-weight:500;border-top-left-radius:10px;border-top-right-radius:10px}sharecard-top span.logos{display:block;width:48px;height:48px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAMAAABg3Am1AAABU1BMVEUAAAAnNJMnNZI3Q5onNJInNJMnNJInNJMnNJI8SJ0tOZY/S55EUKAoNJI6RpwoNJNIU6InNJInNJImNJI7SJwmNJJ2fLUiMJFKVaNCTJ9faK1HUaJOWKVSXaUnNJNYY6pye7cmM5JXYKhwebMjMI8mL4719fW9vb0oNZP/UlLz8/QqN5TAwMAnNJPv7+/Pz8/q6+/p6enNzc3Kysry8vMsOJXc3env7/LU1uXo29vR0dHOzs7ExMTwjo73bW37XV3Aj1TCYELl5u3n5+fW2Obn6O7f4OrZ2+g0QJkxPpgvO5bh4uvS1OTP0ePCwsJQW6ZLVqTs7fHd3d3V1dXqv79VX6lET6A1TIxXUIBSgHxWQnpelHf+WVnopkXqbC7j5Ozi4uLDw8NGUaFATJ9SgH3r6+vGyd7BxNva2trX19ejqM2gpczHx8dze7Zha67Z2dlTgH1aXQeSAAAAJnRSTlMA6ff+497Y8NL+/fv49P379sqab/BeOiX06tzVy8m/tKqpalA7G6oKj0EAAAJlSURBVEjHndNXWxpBFIDhcS2ICRLAkt4Dx4WhLk0E6R0MYoIISrWX5P9f5cwSIRC2+T1czMV5n2FnZwn2eWONUqCAv3H2Uf5Ra1hx4+0WEXtDQW0fCPYJ1EffEfIV4CSROAE4jsePoTFsNmTJF/IeIHF2lgCIn57GodlqDWXBK7IwBYatVlMWFAildPKX7I3m74Z9fsCiQChoimoFQAz04Ad2gH1n9fv9n9hgMNDr9euLWD6fLxQKxaLfb7dTSlahbFVdEPwIQtrAihZQgyKCtCagbQe3xh0QFMgy5MR11+ewYY5/qlZ7vT2xu93ULKjbFLpiUxnIIwjgKmVTLDUFXMrAi2NJWCRLIthTBo4xyOLKpwyqU6CuDCI41hFBCVdOhyLw4FgJ1skCAiyl9BSHbCorgo6VJXTru5hrVCQS8Yr5xLzX59YJSFpVFwD9U0BGC3hGdFpATgRupTGe9R9I1b1ePBvXKDyvq/O/44LT4/E4BUbSCAwj8Evq6HlnOBprx6JhJz8Gktc7xeaP9ndY+0coQvCccFBD4JW60UIY50ciLOAODAQRVOeCHm4Q3Xks6uRDY+CQ+AR4T2wMYh6+jMCIQOp78CFoj0H7EQgIuhI3dGaHCrwgADwCPjJvA372GRigCJg49FUdk3D87pq3zp4SA5zc1Zh9DxfwkpjgUg5Mv+lbeE3McC8Lpu7SA3wk2xzcqL2tN5DfIsQC8HB7UamUy6FQOpTO5QKBQDZbKnWSyUzGjdWCwaDA8+7Le4BNgm3qQGWchYh9s5hNq6wVbBlbwhZYOp3OYOA4zmgEypnM2zj8ByIdedKrH8vDAAAAAElFTkSuQmCC");zoom:.8}sharecard-content{padding:15px;max-height:500px;font-size:20px;text-align:justify;background-color:#2196f3;overflow-x:hidden;overflow-y:auto}sharecard-via{padding:10px;font-size:10px;background-color:#2196f3}sharecard-footer{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:100px;background-color:#fff;color:#878787;font-size:15px;font-weight:500;border-bottom-left-radius:10px;border-bottom-right-radius:10px}sharecard-footer,sharecard-footer div{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sharecard-footer span.qrcode{display:block;width:100px;height:100px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,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")}sharecard-control{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 19px;height:80px;background-color:#fff}simpread-snapshot{width:100%;height:100%;cursor:move;z-index:2147483645}simpread-snapshot,sr-mask{position:fixed;left:0;top:0}sr-mask{background-color:rgba(0,0,0,.1)}.simpread-feedback,.simpread-urlscheme{position:fixed;right:20px;bottom:20px;z-index:2147483646}simpread-feedback,simpread-urlscheme{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;padding:20px 20px 0;width:500px;color:rgba(51,51,51,.87);background-color:#fff;border-radius:3px;box-shadow:0 0 2px rgba(0,0,0,.12),0 2px 2px rgba(0,0,0,.26);overflow:hidden;-webkit-transform-origin:bottom;transform-origin:bottom;-webkit-transition:all .6s ease;transition:all .6s ease}simpread-feedback *,simpread-urlscheme *{font-size:12px!important;box-sizing:border-box}simpread-feedback.active,simpread-urlscheme.active{-webkit-animation-name:srFadeInUp;animation-name:srFadeInUp;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback.hide,simpread-urlscheme.hide{-webkit-animation-name:srFadeInDown;animation-name:srFadeInDown;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback sr-fb-label,simpread-urlscheme sr-urls-label{width:100%}simpread-feedback sr-fb-head,simpread-urlscheme sr-urls-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:5px;width:100%}simpread-feedback sr-fb-content,simpread-urlscheme sr-urls-content{margin-bottom:5px;width:100%}simpread-feedback sr-urls-footer,simpread-urlscheme sr-urls-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-fb-a,simpread-urlscheme sr-urls-a{color:#2163f7;cursor:pointer}simpread-feedback text-field-state,simpread-urlscheme text-field-state{border-top:none rgba(34,101,247,.8)!important;border-left:none rgba(34,101,247,.8)!important;border-right:none rgba(34,101,247,.8)!important;border-bottom:2px solid rgba(34,101,247,.8)!important}simpread-feedback switch,simpread-urlscheme switch{margin-top:0!important}@-webkit-keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@-webkit-keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}@keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}simpread-feedback sr-fb-head{font-weight:700}simpread-feedback sr-fb-content{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column}simpread-feedback sr-fb-content,simpread-feedback sr-fb-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}simpread-feedback sr-fb-footer{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-close{position:absolute;right:20px;cursor:pointer;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s;z-index:200}simpread-feedback sr-close:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin-top:10px}simpread-feedback sr-stars i{margin-right:10px;cursor:pointer}simpread-feedback sr-stars i svg{-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}simpread-feedback sr-stars i svg:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars i.active svg{-webkit-transform:rotate(0) scale(1);transform:rotate(0) scale(1)}simpread-feedback sr-emojis{display:block;height:100px;overflow:hidden}simpread-feedback sr-emoji{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:.3s;transition:.3s}simpread-feedback sr-emoji>svg{margin:15px 0;width:70px;height:70px;-ms-flex-negative:0;flex-shrink:0}simpread-feedback sr-stars-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin:10px 0 20px}</style>
                        <style type="text/css">.simpread-theme-root{font-size:62.5%!important}sr-rd-content,sr-rd-desc,sr-rd-title{width:100%}sr-rd-title{display:-webkit-box;margin:1em 0 .5em;overflow:hidden;text-overflow:ellipsis;text-rendering:optimizelegibility;-webkit-line-clamp:3;-webkit-box-orient:vertical}sr-rd-content{text-align:left;word-break:break-word}sr-rd-desc{text-align:justify;line-height:2.4;margin:0 0 1.2em;box-sizing:border-box}sr-rd-content{font-size:25.6px;font-size:1.6rem;line-height:1.6}sr-rd-content h1,sr-rd-content h1 *,sr-rd-content h2,sr-rd-content h2 *,sr-rd-content h3,sr-rd-content h3 *,sr-rd-content h4,sr-rd-content h4 *,sr-rd-content h5,sr-rd-content h5 *,sr-rd-content h6,sr-rd-content h6 *{word-break:break-all}sr-rd-content div,sr-rd-content p{display:block;float:inherit;line-height:1.6;font-size:25.6px;font-size:1.6rem}sr-rd-content div,sr-rd-content p,sr-rd-content pre,sr-rd-content sr-blockquote{margin:0 0 1.2em;word-break:break-word}sr-rd-content a{padding:0 5px;vertical-align:baseline;vertical-align:initial}sr-rd-content a,sr-rd-content a:link{color:inherit;font-size:inherit;font-weight:inherit;border:none}sr-rd-content a:hover{background:transparent}sr-rd-content img{margin:10px;padding:5px;max-width:100%;background:#fff;border:1px solid #bbb;box-shadow:1px 1px 3px #d4d4d4}sr-rd-content figcaption{text-align:center;font-size:14px}sr-rd-content sr-blockquote{display:block;position:relative;padding:15px 25px;text-align:left;line-height:inherit}sr-rd-content sr-blockquote:before{position:absolute}sr-rd-content sr-blockquote *{margin:0;font-size:inherit}sr-rd-content table{width:100%;margin:0 0 1.2em;word-break:keep-all;word-break:normal;overflow:auto;border:none}sr-rd-content table td,sr-rd-content table th{border:none}sr-rd-content ul{margin:0 0 1.2em;margin-left:1.3em;padding:0;list-style:disc}sr-rd-content ol{list-style:decimal;margin:0;padding:0}sr-rd-content ol li,sr-rd-content ul li{font-size:inherit;list-style:disc;margin:0 0 1.2em}sr-rd-content ol li{list-style:decimal;margin-left:1.3em}sr-rd-content ol li *,sr-rd-content ul li *{margin:0;text-align:left;text-align:initial}sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em}sr-rd-content li ul{list-style:circle}sr-rd-content pre{font-family:Consolas,Monaco,Andale Mono,Source Code Pro,Liberation Mono,Courier,monospace;display:block;padding:15px;line-height:1.5;word-break:break-all;word-wrap:break-word;white-space:pre;overflow:auto}sr-rd-content pre,sr-rd-content pre *,sr-rd-content pre div{font-size:17.6px;font-size:1.1rem}sr-rd-content li pre code,sr-rd-content p pre code,sr-rd-content pre{background-color:transparent;border:none}sr-rd-content pre code{margin:0;padding:0}sr-rd-content pre code,sr-rd-content pre code *{font-size:17.6px;font-size:1.1rem}sr-rd-content pre p{margin:0;padding:0;color:inherit;font-size:inherit;line-height:inherit}sr-rd-content li code,sr-rd-content p code{margin:0 4px;padding:2px 4px;font-size:17.6px;font-size:1.1rem}sr-rd-content mark{margin:0 5px;padding:2px;background:#fffdd1;border-bottom:1px solid #ffedce}.sr-rd-content-img{width:90%;height:auto}.sr-rd-content-img-load{width:48px;height:48px;margin:0;padding:0;border-style:none;border-width:0;background-repeat:no-repeat;background-image:url(data:image/gif;base64,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)}.sr-rd-content-center{text-align:center;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;-webkit-box-orient:vertical}.sr-rd-content-center-small{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.sr-rd-content-center-small img{margin:0;padding:0;border:0;box-shadow:none}img.simpread-img-broken{cursor:pointer}.sr-rd-content-nobeautify{margin:0;padding:0;border:0;box-shadow:0 0 0}sr-rd-mult{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin:0 0 16px;padding:16px 0 24px;width:100%;background-color:#fff;border-radius:4px;box-shadow:0 1px 2px 0 rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}sr-rd-mult:hover{-webkit-transition:all .45s 0ms;transition:all .45s 0ms;box-shadow:1px 1px 8px rgba(0,0,0,.16)}sr-rd-mult sr-rd-mult-content{padding:0 16px;overflow:auto}sr-rd-mult sr-rd-mult-avatar,sr-rd-mult sr-rd-mult-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sr-rd-mult sr-rd-mult-avatar{-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 15px}sr-rd-mult sr-rd-mult-avatar span{display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;max-width:75px;overflow:hidden;text-overflow:ellipsis;text-align:left;font-size:16px;font-size:1rem}sr-rd-mult sr-rd-mult-avatar img{margin-bottom:0;max-width:50px;max-height:50px;width:50px;height:50px;border-radius:50%}sr-rd-mult sr-rd-mult-content img{max-width:80%}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center{margin:0}sr-page{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;width:100%}</style>
                        <style type="text/css">sr-rd-theme-github{display:none}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{position:relative;margin-top:1em;margin-bottom:1pc;font-weight:700;line-height:1.4;text-align:left;color:#363636}sr-rd-content h1{padding-bottom:.3em;font-size:57.6px;font-size:3.6rem;line-height:1.2}sr-rd-content h2{padding-bottom:.3em;font-size:44.8px;font-size:2.8rem;line-height:1.225}sr-rd-content h3{font-size:38.4px;font-size:2.4rem;line-height:1.43}sr-rd-content h4{font-size:32px;font-size:2rem}sr-rd-content h5,sr-rd-content h6{font-size:25.6px;font-size:1.6rem}sr-rd-content h6{color:#777}sr-rd-content ol,sr-rd-content ul{list-style-type:disc;padding:0;padding-left:2em}sr-rd-content ol ol,sr-rd-content ul ol{list-style-type:lower-roman}sr-rd-content ol ol ol,sr-rd-content ol ul ol,sr-rd-content ul ol ol,sr-rd-content ul ul ol{list-style-type:lower-alpha}sr-rd-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all}sr-rd-content table th{font-weight:700}sr-rd-content table td,sr-rd-content table th{padding:6px 13px;border:1px solid #ddd}sr-rd-content table tr{background-color:#fff;border-top:1px solid #ccc}sr-rd-content table tr:nth-child(2n){background-color:#f8f8f8}sr-rd-content sr-blockquote{border-left:4px solid #ddd}.simpread-theme-root{background-color:#fff;color:#333}sr-rd-title{font-family:PT Sans,SF UI Display,\.PingFang SC,PingFang SC,Neue Haas Grotesk Text Pro,Arial Nova,Segoe UI,Microsoft YaHei,Microsoft JhengHei,Helvetica Neue,Source Han Sans SC,Noto Sans CJK SC,Source Han Sans CN,Noto Sans SC,Source Han Sans TC,Noto Sans CJK TC,Hiragino Sans GB,sans-serif;font-size:54.4px;font-size:3.4rem;font-weight:700;line-height:1.3}sr-rd-desc{position:relative;margin:0;margin-bottom:30px;padding:25px;padding-left:56px;font-size:28.8px;font-size:1.8rem;color:#777;background-color:rgba(0,0,0,.05);box-sizing:border-box}sr-rd-desc:before{content:"\201C";position:absolute;top:-28px;left:16px;font-size:80px;font-family:Arial;color:rgba(0,0,0,.15)}sr-rd-content,sr-rd-content *,sr-rd-content div,sr-rd-content p{color:#363636;font-weight:400;line-height:1.8}sr-rd-content b *,sr-rd-content strong,sr-rd-content strong * sr-rd-content b{-webkit-animation:none 0s ease 0s 1 normal none running;animation:none 0s ease 0s 1 normal none running;-webkit-backface-visibility:visible;backface-visibility:visible;background:transparent none repeat 0 0/auto auto padding-box border-box scroll;border:medium none currentColor;border-collapse:separate;-o-border-image:none;border-image:none;border-radius:0;border-spacing:0;bottom:auto;box-shadow:none;box-sizing:content-box;caption-side:top;clear:none;clip:auto;color:#000;-webkit-columns:auto;-moz-columns:auto;columns:auto;-webkit-column-count:auto;-moz-column-count:auto;column-count:auto;-webkit-column-fill:balance;-moz-column-fill:balance;column-fill:balance;-webkit-column-gap:normal;-moz-column-gap:normal;column-gap:normal;-webkit-column-rule:medium none currentColor;-moz-column-rule:medium none currentColor;column-rule:medium none currentColor;-webkit-column-span:1;-moz-column-span:1;column-span:1;-webkit-column-width:auto;-moz-column-width:auto;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;direction:ltr;display:inline;empty-cells:show;float:none;font-family:serif;font-size:medium;font-style:normal;font-variant:normal;font-weight:400;font-stretch:normal;line-height:normal;height:auto;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;left:auto;letter-spacing:normal;list-style:disc outside none;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;opacity:1;orphans:2;outline:medium none invert;overflow:visible;overflow-x:visible;overflow-y:visible;padding:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;-webkit-perspective:none;perspective:none;-webkit-perspective-origin:50% 50%;perspective-origin:50% 50%;position:static;right:auto;-moz-tab-size:8;-o-tab-size:8;tab-size:8;table-layout:auto;text-align:left;text-align-last:auto;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;top:auto;-webkit-transform:none;transform:none;-webkit-transform-origin:50% 50% 0;transform-origin:50% 50% 0;-webkit-transform-style:flat;transform-style:flat;-webkit-transition:none 0s ease 0s;transition:none 0s ease 0s;unicode-bidi:normal;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;word-spacing:normal;z-index:auto;all:initial}sr-rd-content a,sr-rd-content a:link{color:#4183c4;text-decoration:none}sr-rd-content a:active,sr-rd-content a:focus,sr-rd-content a:hover{color:#4183c4;text-decoration:underline}sr-rd-content pre{background-color:#f7f7f7;border-radius:3px}sr-rd-content li code,sr-rd-content p code{background-color:rgba(0,0,0,.04);border-radius:3px}.simpread-multi-root{background:#f8f9fa}</style>
                        <style type="text/css"></style>
                        <style type="text/css">@media (pointer:coarse){sr-read{margin:20px 5%!important;min-width:0!important;max-width:90%!important}sr-rd-title{margin-top:0;font-size:2.7rem}sr-rd-content sr-blockquote,sr-rd-desc{margin:10 0!important;padding:0 0 0 10px!important;width:90%;font-size:1.8rem;font-style:normal;line-height:1.7;text-align:justify}sr-rd-content{font-size:1.75rem;font-weight:300}sr-rd-content figure{margin:0;padding:0;text-align:center}sr-rd-content a,sr-rd-content a:link,sr-rd-content li code,sr-rd-content p code{font-size:inherit}sr-rd-footer{margin-top:20px}sr-blockquote,sr-blockquote *{margin:5px!important;padding:5px!important}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6,sr-rd-title{font-family:PingFang SC,Verdana,Helvetica Neue,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;font-weight:100;line-height:1.35}sr-rd-content-h1,sr-rd-content-h2,sr-rd-content-h3,sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}sr-rd-content-h1,sr-rd-content h1{font-size:1.8em}sr-rd-content-h2,sr-rd-content h2{font-size:1.6em}sr-rd-content-h3,sr-rd-content h3{font-size:1.4em}sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{font-size:1.2em}sr-rd-content-ul,sr-rd-content ul{margin-left:1.3em!important;list-style:disc}sr-rd-content-ol,sr-rd-content ol{list-style:decimal;margin-left:1.9em!important}sr-rd-content-ol ol,sr-rd-content-ol ul,sr-rd-content-ul ol,sr-rd-content-ul ul,sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em!important}sr-rd-content img{margin:0;padding:0;border:0;max-width:100%!important;height:auto;box-shadow:0 20px 20px -10px rgba(0,0,0,.1)}sr-rd-mult{min-width:0;background-color:#fff;box-shadow:0 1px 6px rgba(32,33,36,.28);border-radius:8px}sr-rd-mult sr-rd-mult-avatar div{margin:0}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center-small{margin:7px 0!important}sr-rd-mult sr-rd-mult-avatar span{display:block}sr-rd-mult sr-rd-mult-content{padding-left:0}@media only screen and (max-device-width:1024px){.simpread-theme-root,html.simpread-theme-root{font-size:80%!important}sr-rd-mult sr-rd-mult-avatar img{width:50px;height:50px;min-width:50px;min-height:50px}toc-bg toc{width:10px!important}toc-bg:hover toc{width:auto!important}}@media only screen and (max-device-width:414px){.simpread-theme-root,html.simpread-theme-root{font-size:70%!important}sr-rd-mult sr-rd-mult-avatar img{width:30px;height:30px;min-width:30px;min-height:30px}}@media only screen and (max-device-width:320px){.simpread-theme-root,html.simpread-theme-root{font-size:90%!important}sr-rd-content p{margin-bottom:.5em}}}</style>
                        <style type="text/css">undefinedsr-rd-content *, sr-rd-content p, sr-rd-content div {}sr-rd-content pre code, sr-rd-content pre code * {}sr-rd-desc {}sr-rd-content pre {}sr-rd-title {}</style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css">sr-rd-content *, sr-rd-content p, sr-rd-content div {
        font-size: 15px;
    }

    .annote-perview, .annote-perview * {
        color: rgb(85, 85, 85);
        font-weight: 400;
        line-height: 1.8;
    }</style>
                        
                        
                        <script>setTimeout(()=>{const e=location.hash.replace("#id=","");let t,a=!1;const n=t=>{for(let n of t){let t;if((t=e.length>6?n.getAttribute("data-id"):n.getAttribute("data-idx"))==e){n.scrollIntoView({behavior:"smooth",block:"start",inline:"nearest"}),a=!0;break}}};e&&(0==(t=document.getElementsByClassName("sr-unread-card")).length&&(t=document.getElementsByTagName("sr-annote")),n(t),a||n(t=document.getElementsByClassName("sr-annote")))},500);</script>
                        <script>document.addEventListener("DOMContentLoaded",function(){if("localhost"==location.hostname){const t=document.getElementsByTagName("img");for(let o of t){const t=o.src;t.startsWith("http")&&(o.src=location.origin+"/proxy?url="+t)}}},!1);</script>
                        <style>toc a {font-size: inherit!important;font-weight: 300!important;}</style><script>setTimeout(()=>{const max=document.getElementsByTagName('sr-annote-note-tip').length;for(let i=0;i<max;i++){const target=document.getElementsByTagName('sr-annote-note-tip')[i],value=target.dataset.value;value&&(target.innerText=value)}},1000);</script><title>简悦 | 07 | Torchvision（中）：数据增强，让数据更加多样性</title>
                    </head>
                    <body>
                        <sr-read style='font-family: "LXGW WenKai Screen";'>
                            <sr-rd-title>07 | Torchvision（中）：数据增强，让数据更加多样性</sr-rd-title>
                    <sr-rd-desc style="margin: 0;padding-top: 0;padding-bottom: 0;font-style: normal;font-size: 18px;">今天这次加餐，我们就一起来看看什么是机器学习，它是怎么分类的，都有哪些常见名词。在补充了这些基础知识之后，我还会和你聊聊模型训练的本质是什么</sr-rd-desc>
                    <sr-rd-content><h1 id="sr-toc-0"> 07 | Torchvision（中）：数据增强，让数据更加多样性</h1><div><span>方远</span> <span> 2021-10-25</span></div><div><div><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/ca/cf/ca63c75752c5e2492ea8d925ebfcf4cf.jpg"></div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADEAAAABCAYAAAB35kaxAAAAAXNSR0IArs4c6QAAAChJREFUGFdjfPfu3X8GKBAUFASz3r9/DxNiQBbDxcamn1yzSLEDZi8A2agny86FR+IAAAAASUVORK5CYII="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAABCAYAAAA8TpVcAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFCYtjkAcT9D8ti7hUOAAAAAElFTkSuQmCC"></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD0AAAABCAYAAABt2qY/AAAAAXNSR0IArs4c6QAAACdJREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULy2PQQK0YLewiZCQDhUS3LBhDf1QAAAABJRU5ErkJggg=="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAABCAYAAAA4u0VhAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULyAF6lD8tbqYWOAAAAAElFTkSuQmCC"></div></div></div><div><div><div></div></div><div><div><div><div><div><div>00:00</div></div><div></div></div></div><a href="javascript:;"> 1.0x <i><span></span></i></a></div><div><span>讲述：方远</span><span>大小：13.89M</span><span> 时长：15:12</span></div></div><audio title="07 | Torchvision（中）：数据增强，让数据更加多样性" src="https://res001.geekbang.org/media/audio/06/2e/06420d25d4cf7bf374df485fdc098c2e/ld/ld.m3u8"></audio></div><div><div><div><div data-slate-editor="true" data-key="4644" autocorrect="off" spellcheck="false" data-gramm="false"><div data-slate-type="paragraph" data-slate-object="block" data-key="4645"><span data-slate-object="text" data-key="4646"><span data-slate-leaf="true" data-offset-key="4646:0" data-first-offset="true"><span data-slate-string="true">你好，我是方远。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4647"><span data-slate-object="text" data-key="4648"><span data-slate-leaf="true" data-offset-key="4648:0" data-first-offset="true"><span data-slate-string="true">上一节课，我们一同迈出了训练开始的第一步 —— 数据读取，初步认识了 Torchvision，学习了如何利用 Torchvision 读取数据。不过仅仅将数据集中的图片读取出来是不够的，在训练的过程中，神经网络模型接收的数据类型是 Tensor，而不是 PIL 对象，因此我们还需要对数据进行预处理操作，比如图像格式的转换。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4649"><span data-slate-object="text" data-key="4650"><span data-slate-leaf="true" data-offset-key="4650:0" data-first-offset="true"><span data-slate-string="true">与此同时，加载后的图像数据可能还需要进行一系列图像变换与增强操作，例如裁切边框、调整图像比例和大小、标准化等，以便模型能够更好地学习到数据的特征。这些操作都可以使用</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4651"><span data-slate-object="text" data-key="4652"><span data-slate-leaf="true" data-offset-key="4652:0" data-first-offset="true"><span data-slate-string="true"> torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="4653"><span data-slate-leaf="true" data-offset-key="4653:0" data-first-offset="true"><span data-slate-string="true"> 工具完成。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4654"><span data-slate-object="text" data-key="4655"><span data-slate-leaf="true" data-offset-key="4655:0" data-first-offset="true"><span data-slate-string="true">今天我们就来学习一下，利用 Torchvision 如何进行数据预处理操作，如何进行图像变换与增强。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4656" id="sr-toc-1"><span data-slate-object="text" data-key="4657"><span data-slate-leaf="true" data-offset-key="4657:0" data-first-offset="true"><span data-slate-string="true">图像处理工具之 torchvision.transforms</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4658"><span data-slate-object="text" data-key="4659"><span data-slate-leaf="true" data-offset-key="4659:0" data-first-offset="true"><span data-slate-string="true">Torchvision 库中的</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4660"><span data-slate-object="text" data-key="4661"><span data-slate-leaf="true" data-offset-key="4661:0" data-first-offset="true"><span data-slate-string="true"> torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="4662"><span data-slate-leaf="true" data-offset-key="4662:0" data-first-offset="true"><span data-slate-string="true"> 包中提供了常用的图像操作，包括对 Tensor 及 PIL Image 对象的操作，例如随机切割、旋转、数据类型转换等等。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4663"><span data-slate-object="text" data-key="4664"><span data-slate-leaf="true" data-offset-key="4664:0" data-first-offset="true"><span data-slate-string="true">按照</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4665"><span data-slate-object="text" data-key="4666"><span data-slate-leaf="true" data-offset-key="4666:0" data-first-offset="true"><span data-slate-string="true"> torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="4667"><span data-slate-leaf="true" data-offset-key="4667:0" data-first-offset="true"><span data-slate-string="true"> 的功能，大致分为以下几类：数据类型转换、对 PIL.Image 和 Tensor 进行变化和变换的组合。下面我们依次来学习这些类别中的操作。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4668" id="sr-toc-2"><span data-slate-object="text" data-key="4669"><span data-slate-leaf="true" data-offset-key="4669:0" data-first-offset="true"><span data-slate-string="true">数据类型转换</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4670"><span data-slate-object="text" data-key="4671"><span data-slate-leaf="true" data-offset-key="4671:0" data-first-offset="true"><span data-slate-string="true">在上一节课中，我们学习了读取数据集中的图片，读取到的数据是 PIL.Image 的对象。而在模型训练阶段，需要传入 Tensor 类型的数据，神经网络才能进行运算。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4672"><span data-slate-object="text" data-key="4673"><span data-slate-leaf="true" data-offset-key="4673:0" data-first-offset="true"><span data-slate-string="true">那么如何将 PIL.Image 或 Numpy.ndarray 格式的数据转化为 Tensor 格式呢？这需要用到</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4674"><span data-slate-object="text" data-key="4675"><span data-slate-leaf="true" data-offset-key="4675:0" data-first-offset="true"><span data-slate-string="true"> transforms.ToTensor()</span></span></span></span><span data-slate-object="text" data-key="4676"><span data-slate-leaf="true" data-offset-key="4676:0" data-first-offset="true"><span data-slate-string="true"> 类。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4677"><span data-slate-object="text" data-key="4678"><span data-slate-leaf="true" data-offset-key="4678:0" data-first-offset="true"><span data-slate-string="true">而反之，将 Tensor 或 Numpy.ndarray 格式的数据转化为 PIL.Image 格式，则使用</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4679"><span data-slate-object="text" data-key="4680"><span data-slate-leaf="true" data-offset-key="4680:0" data-first-offset="true"><span data-slate-string="true"> transforms.ToPILImage(mode=None)</span></span></span></span><span data-slate-object="text" data-key="4681"><span data-slate-leaf="true" data-offset-key="4681:0" data-first-offset="true"><span data-slate-string="true"> 类。它则是 ToTensor 的一个逆操作，它能把 Tensor 或 Numpy 的数组转换成 PIL.Image 对象。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4682"><span data-slate-object="text" data-key="4683"><span data-slate-leaf="true" data-offset-key="4683:0" data-first-offset="true"><span data-slate-string="true">其中，参数 mode 代表 PIL.Image 的模式，如果 mode 为 None（默认值），则根据输入数据的维度进行推断：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="4684"><div data-slate-type="list-line" data-slate-object="block" data-key="4685"><span data-slate-object="text" data-key="4686"><span data-slate-leaf="true" data-offset-key="4686:0" data-first-offset="true"><span data-slate-string="true">输入为 3 通道：mode 为’RGB’；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4687"><span data-slate-object="text" data-key="4688"><span data-slate-leaf="true" data-offset-key="4688:0" data-first-offset="true"><span data-slate-string="true">输入为 4 通道：mode 为’RGBA’；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4689"><span data-slate-object="text" data-key="4690"><span data-slate-leaf="true" data-offset-key="4690:0" data-first-offset="true"><span data-slate-string="true">输入为 2 通道：mode 为’LA’;</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4691"><span data-slate-object="text" data-key="4692"><span data-slate-leaf="true" data-offset-key="4692:0" data-first-offset="true"><span data-slate-string="true">输入为单通道：mode 根据输入数据的类型确定具体模式。</span></span></span></div></div><div data-slate-type="image" data-slate-object="block" data-key="4693"><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/d3/0c/d3013753ef85937a39b64ef8f556df0c.jpg?wh=318x116"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4694"><span data-slate-object="text" data-key="4695"><span data-slate-leaf="true" data-offset-key="4695:0" data-first-offset="true"><span data-slate-string="true">说完用法，我们来看一个具体的例子加深理解。以极客时间的 LOGO 图片（文件名为：jk.jpg）为例，进行一下数据类型的相互转换。具体代码如下。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4696"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div><div data-code-line-number="18"></div><div data-code-line-number="19"></div><div data-code-line-number="20"></div><div data-code-line-number="21"></div><div data-code-line-number="22"></div><div data-code-line-number="23"></div><div data-code-line-number="24"></div><div data-code-line-number="25"></div><div data-code-line-number="26"></div><div data-code-line-number="27"></div><div data-code-line-number="28"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4697"><span data-slate-object="text" data-key="4698"><span data-slate-leaf="true" data-offset-key="4698:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4699"><span data-slate-leaf="true" data-offset-key="4699:0" data-first-offset="true"><span data-slate-string="true"> PIL </span></span></span><span data-slate-object="text" data-key="4700"><span data-slate-leaf="true" data-offset-key="4700:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4701"><span data-slate-leaf="true" data-offset-key="4701:0" data-first-offset="true"><span data-slate-string="true"> Image</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4702"><span data-slate-object="text" data-key="4703"><span data-slate-leaf="true" data-offset-key="4703:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4704"><span data-slate-leaf="true" data-offset-key="4704:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="4705"><span data-slate-leaf="true" data-offset-key="4705:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4706"><span data-slate-leaf="true" data-offset-key="4706:0" data-first-offset="true"><span data-slate-string="true"> transforms </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4707"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4708"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4709"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4710"><span data-slate-object="text" data-key="4711"><span data-slate-leaf="true" data-offset-key="4711:0" data-first-offset="true"><span data-slate-string="true">img = Image.</span></span></span><span data-slate-object="text" data-key="4712"><span data-slate-leaf="true" data-offset-key="4712:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">open</span></span></span></span><span data-slate-object="text" data-key="4713"><span data-slate-leaf="true" data-offset-key="4713:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4714"><span data-slate-leaf="true" data-offset-key="4714:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'jk.jpg'</span></span></span></span><span data-slate-object="text" data-key="4715"><span data-slate-leaf="true" data-offset-key="4715:0" data-first-offset="true"><span data-slate-string="true">) </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4716"><span data-slate-object="text" data-key="4717"><span data-slate-leaf="true" data-offset-key="4717:0" data-first-offset="true"><span data-slate-object="annotation" data-annotation-key="gkann_7fff8497" data-attr-id="42315" data-attr-name="public" data-annotation-type="public"><span data-slate-string="true">display(img)</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4718"><span data-slate-object="text" data-key="4719"><span data-slate-leaf="true" data-offset-key="4719:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4720"><span data-slate-leaf="true" data-offset-key="4720:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4721"><span data-slate-leaf="true" data-offset-key="4721:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">type</span></span></span></span><span data-slate-object="text" data-key="4722"><span data-slate-leaf="true" data-offset-key="4722:0" data-first-offset="true"><span data-slate-string="true">(img)) </span></span></span><span data-slate-object="text" data-key="4723"><span data-slate-leaf="true" data-offset-key="4723:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># PIL.Image.Image 是 PIL.JpegImagePlugin.JpegImageFile 的基类</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4724"><span data-slate-object="text" data-key="4725"><span data-slate-leaf="true" data-offset-key="4725:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4726"><span data-slate-object="text" data-key="4727"><span data-slate-leaf="true" data-offset-key="4727:0" data-first-offset="true"><span data-slate-string="true">输出: </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4728"><span data-slate-object="text" data-key="4729"><span data-slate-leaf="true" data-offset-key="4729:0" data-first-offset="true"><span data-slate-string="true">&lt;class 'PIL.JpegImagePlugin.JpegImageFile'&gt;</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4730"><span data-slate-object="text" data-key="4731"><span data-slate-leaf="true" data-offset-key="4731:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4732"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4733"><span data-slate-object="text" data-key="4734"><span data-slate-leaf="true" data-offset-key="4734:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># PIL.Image 转换为 Tensor</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4735"><span data-slate-object="text" data-key="4736"><span data-slate-leaf="true" data-offset-key="4736:0" data-first-offset="true"><span data-slate-string="true">img1 = transforms.ToTensor()(img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4737"><span data-slate-object="text" data-key="4738"><span data-slate-leaf="true" data-offset-key="4738:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4739"><span data-slate-leaf="true" data-offset-key="4739:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4740"><span data-slate-leaf="true" data-offset-key="4740:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">type</span></span></span></span><span data-slate-object="text" data-key="4741"><span data-slate-leaf="true" data-offset-key="4741:0" data-first-offset="true"><span data-slate-string="true">(img1))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4742"><span data-slate-object="text" data-key="4743"><span data-slate-leaf="true" data-offset-key="4743:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4744"><span data-slate-object="text" data-key="4745"><span data-slate-leaf="true" data-offset-key="4745:0" data-first-offset="true"><span data-slate-string="true">输出: </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4746"><span data-slate-object="text" data-key="4747"><span data-slate-leaf="true" data-offset-key="4747:0" data-first-offset="true"><span data-slate-string="true">&lt;class 'torch.Tensor'&gt;</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4748"><span data-slate-object="text" data-key="4749"><span data-slate-leaf="true" data-offset-key="4749:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4750"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4751"><span data-slate-object="text" data-key="4752"><span data-slate-leaf="true" data-offset-key="4752:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># Tensor 转换为 PIL.Image</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4753"><span data-slate-object="text" data-key="4754"><span data-slate-leaf="true" data-offset-key="4754:0" data-first-offset="true"><span data-slate-string="true">img2 = transforms.ToPILImage()(img1)  </span></span></span><span data-slate-object="text" data-key="4755"><span data-slate-leaf="true" data-offset-key="4755:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#PIL.Image.Image</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4756"><span data-slate-object="text" data-key="4757"><span data-slate-leaf="true" data-offset-key="4757:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4758"><span data-slate-leaf="true" data-offset-key="4758:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4759"><span data-slate-leaf="true" data-offset-key="4759:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">type</span></span></span></span><span data-slate-object="text" data-key="4760"><span data-slate-leaf="true" data-offset-key="4760:0" data-first-offset="true"><span data-slate-string="true">(img2))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4761"><span data-slate-object="text" data-key="4762"><span data-slate-leaf="true" data-offset-key="4762:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4763"><span data-slate-object="text" data-key="4764"><span data-slate-leaf="true" data-offset-key="4764:0" data-first-offset="true"><span data-slate-string="true">输出: </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4765"><span data-slate-object="text" data-key="4766"><span data-slate-leaf="true" data-offset-key="4766:0" data-first-offset="true"><span data-slate-string="true">&lt;class 'PIL.Image.Image'&gt;</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4767"><span data-slate-object="text" data-key="4768"><span data-slate-leaf="true" data-offset-key="4768:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4769"><span data-slate-object="text" data-key="4770"><span data-slate-leaf="true" data-offset-key="4770:0" data-first-offset="true"><span data-slate-string="true">首先用读取图片，查看一下图片的类型为 PIL.JpegImagePlugin.JpegImageFile，这里需要注意</span></span></span><span data-slate-object="text" data-key="4771"><span data-slate-leaf="true" data-offset-key="4771:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">，PIL.JpegImagePlugin.JpegImageFile 类是 PIL.Image.Image 类的子类</span></span></span></span><span data-slate-object="text" data-key="4772"><span data-slate-leaf="true" data-offset-key="4772:0" data-first-offset="true"><span data-slate-string="true">。然后，用</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4773"><span data-slate-object="text" data-key="4774"><span data-slate-leaf="true" data-offset-key="4774:0" data-first-offset="true"><span data-slate-string="true"> transforms.ToTensor()</span></span></span></span><span data-slate-object="text" data-key="4775"><span data-slate-leaf="true" data-offset-key="4775:0" data-first-offset="true"><span data-slate-string="true"> 将 PIL.Image 转换为 Tensor。最后，再将 Tensor 转换回 PIL.Image。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4776" id="sr-toc-3"><span data-slate-object="text" data-key="4777"><span data-slate-leaf="true" data-offset-key="4777:0" data-first-offset="true"><span data-slate-string="true">对 PIL.Image 和 Tensor 进行变换</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4778"><span data-slate-type="code" data-slate-object="inline" data-key="4779"><span data-slate-object="text" data-key="4780"><span data-slate-leaf="true" data-offset-key="4780:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="4781"><span data-slate-leaf="true" data-offset-key="4781:0" data-first-offset="true"><span data-slate-string="true"> 提供了丰富的图像变换方法，例如：改变尺寸、剪裁、翻转等。并且这些图像变换操作可以接收多种数据格式，不仅可以直接对 PIL 格式的图像进行变换，也可以对 Tensor 进行变换，无需我们再去做额外的数据类型转换。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4782"><span data-slate-object="text" data-key="4783"><span data-slate-leaf="true" data-offset-key="4783:0" data-first-offset="true"><span data-slate-string="true">下面我们依次来看一看。</span></span></span></div><h4 data-slate-type="heading" data-slate-object="block" data-key="4784" id="sr-toc-4"><span data-slate-object="text" data-key="4785"><span data-slate-leaf="true" data-offset-key="4785:0" data-first-offset="true"><span data-slate-string="true">Resize</span></span></span></h4><div data-slate-type="paragraph" data-slate-object="block" data-key="4786"><span data-slate-object="text" data-key="4787"><span data-slate-leaf="true" data-offset-key="4787:0" data-first-offset="true"><span data-slate-string="true">将输入的 PIL Image 或 Tensor 尺寸调整为给定的尺寸，具体定义为：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4788"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4789"><span data-slate-object="text" data-key="4790"><span data-slate-leaf="true" data-offset-key="4790:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.Resize(size, interpolation=</span></span></span><span data-slate-object="text" data-key="4791"><span data-slate-leaf="true" data-offset-key="4791:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">2</span></span></span></span><span data-slate-object="text" data-key="4792"><span data-slate-leaf="true" data-offset-key="4792:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4793"><span data-slate-object="text" data-key="4794"><span data-slate-leaf="true" data-offset-key="4794:0" data-first-offset="true"><span data-slate-string="true">我们依次看下相关的参数：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="4795"><div data-slate-type="list-line" data-slate-object="block" data-key="4796"><span data-slate-object="text" data-key="4797"><span data-slate-leaf="true" data-offset-key="4797:0" data-first-offset="true"><span data-slate-string="true">size：期望输出的尺寸。如果 size 是一个像 (h, w) 这样的元组，则图像输出尺寸将与之匹配。如果 size 是一个 int 类型的整数，图像较小的边将被匹配到该整数，另一条边按比例缩放。</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4798"><span data-slate-object="text" data-key="4799"><span data-slate-leaf="true" data-offset-key="4799:0" data-first-offset="true"><span data-slate-string="true">interpolation：插值算法，int 类型，默认为 2，表示 PIL.Image.BILINEAR。</span></span></span></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4800"><span data-slate-object="text" data-key="4801"><span data-slate-leaf="true" data-offset-key="4801:0" data-first-offset="true"><span data-slate-string="true">有关 Size 中是 tuple 还是 int 这一点请你一定要注意。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4802"><span data-slate-object="text" data-key="4803"><span data-slate-leaf="true" data-offset-key="4803:0" data-first-offset="true"><span data-slate-string="true">让我说明一下，在我们训练时，通常要把图片 resize 到一定的大小，比如说 128x128，256x256 这样的。如果直接给定 resize 后的高与宽，是没有问题的。但如果设定的是一个 int 型，较长的边就会按比例缩放。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4804"><span data-slate-object="text" data-key="4805"><span data-slate-leaf="true" data-offset-key="4805:0" data-first-offset="true"><span data-slate-string="true">在 resize 之后呢，一般会接一个 crop 操作，crop 到指定的大小。对于高与宽接近的图片来说，这么做问题不大，但是高与宽的差距较大时，就会 crop 掉很多有用的信息。关于这一点，我们在后续的图像分类部分还会遇到，到时我在详细展开。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4806"><span data-slate-object="text" data-key="4807"><span data-slate-leaf="true" data-offset-key="4807:0" data-first-offset="true"><span data-slate-string="true">我们还是以极客时间的 LOGO 图片为例，一起看一下 Resize 的效果。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4808"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4809"><span data-slate-object="text" data-key="4810"><span data-slate-leaf="true" data-offset-key="4810:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4811"><span data-slate-leaf="true" data-offset-key="4811:0" data-first-offset="true"><span data-slate-string="true"> PIL </span></span></span><span data-slate-object="text" data-key="4812"><span data-slate-leaf="true" data-offset-key="4812:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4813"><span data-slate-leaf="true" data-offset-key="4813:0" data-first-offset="true"><span data-slate-string="true"> Image</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4814"><span data-slate-object="text" data-key="4815"><span data-slate-leaf="true" data-offset-key="4815:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4816"><span data-slate-leaf="true" data-offset-key="4816:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="4817"><span data-slate-leaf="true" data-offset-key="4817:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4818"><span data-slate-leaf="true" data-offset-key="4818:0" data-first-offset="true"><span data-slate-string="true"> transforms </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4819"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4820"><span data-slate-object="text" data-key="4821"><span data-slate-leaf="true" data-offset-key="4821:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 定义一个 Resize 操作</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4822"><span data-slate-object="text" data-key="4823"><span data-slate-leaf="true" data-offset-key="4823:0" data-first-offset="true"><span data-slate-string="true">resize_img_oper = transforms.Resize((</span></span></span><span data-slate-object="text" data-key="4824"><span data-slate-leaf="true" data-offset-key="4824:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">200</span></span></span></span><span data-slate-object="text" data-key="4825"><span data-slate-leaf="true" data-offset-key="4825:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span><span data-slate-object="text" data-key="4826"><span data-slate-leaf="true" data-offset-key="4826:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">200</span></span></span></span><span data-slate-object="text" data-key="4827"><span data-slate-leaf="true" data-offset-key="4827:0" data-first-offset="true"><span data-slate-string="true">), interpolation=</span></span></span><span data-slate-object="text" data-key="4828"><span data-slate-leaf="true" data-offset-key="4828:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">2</span></span></span></span><span data-slate-object="text" data-key="4829"><span data-slate-leaf="true" data-offset-key="4829:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4830"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4831"><span data-slate-object="text" data-key="4832"><span data-slate-leaf="true" data-offset-key="4832:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 原图</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4833"><span data-slate-object="text" data-key="4834"><span data-slate-leaf="true" data-offset-key="4834:0" data-first-offset="true"><span data-slate-string="true">orig_img = Image.</span></span></span><span data-slate-object="text" data-key="4835"><span data-slate-leaf="true" data-offset-key="4835:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">open</span></span></span></span><span data-slate-object="text" data-key="4836"><span data-slate-leaf="true" data-offset-key="4836:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4837"><span data-slate-leaf="true" data-offset-key="4837:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'jk.jpg'</span></span></span></span><span data-slate-object="text" data-key="4838"><span data-slate-leaf="true" data-offset-key="4838:0" data-first-offset="true"><span data-slate-string="true">) </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4839"><span data-slate-object="text" data-key="4840"><span data-slate-leaf="true" data-offset-key="4840:0" data-first-offset="true"><span data-slate-string="true">display(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4841"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4842"><span data-slate-object="text" data-key="4843"><span data-slate-leaf="true" data-offset-key="4843:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># Resize 操作后的图</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4844"><span data-slate-object="text" data-key="4845"><span data-slate-leaf="true" data-offset-key="4845:0" data-first-offset="true"><span data-slate-string="true">img = resize_img_oper(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4846"><span data-slate-object="text" data-key="4847"><span data-slate-leaf="true" data-offset-key="4847:0" data-first-offset="true"><span data-slate-string="true">display(img)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4848"><span data-slate-object="text" data-key="4849"><span data-slate-leaf="true" data-offset-key="4849:0" data-first-offset="true"><span data-slate-string="true">首先定义一个 Resize 操作，设置好变换后的尺寸为 (200, 200)，然后对极客时间 LOGO 图片进行 Resize 变换。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4850"><span data-slate-object="text" data-key="4851"><span data-slate-leaf="true" data-offset-key="4851:0" data-first-offset="true"><span data-slate-string="true">原图以及 Resize 变换后的效果如下表所示。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4852"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/56/09/5611e53aaed88bb079909992db5c6d09.jpg?wh=1232x505"></div></div><h4 data-slate-type="heading" data-slate-object="block" data-key="4853" id="sr-toc-5"><span data-slate-object="text" data-key="4854"><span data-slate-leaf="true" data-offset-key="4854:0" data-first-offset="true"><span data-slate-string="true">剪裁</span></span></span></h4><div data-slate-type="paragraph" data-slate-object="block" data-key="4855"><span data-slate-type="code" data-slate-object="inline" data-key="4856"><span data-slate-object="text" data-key="4857"><span data-slate-leaf="true" data-offset-key="4857:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="4858"><span data-slate-leaf="true" data-offset-key="4858:0" data-first-offset="true"><span data-slate-string="true"> 提供了多种剪裁方法，例如中心剪裁、随机剪裁、四角和中心剪裁等。我们依次来看下它们的定义。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4859"><span data-slate-object="text" data-key="4860"><span data-slate-leaf="true" data-offset-key="4860:0" data-first-offset="true"><span data-slate-string="true">先说中心剪裁，顾名思义，在中心裁剪指定的 PIL Image 或 Tensor，其定义如下：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4861"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4862"><span data-slate-object="text" data-key="4863"><span data-slate-leaf="true" data-offset-key="4863:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.CenterCrop(size)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4864"><span data-slate-object="text" data-key="4865"><span data-slate-leaf="true" data-offset-key="4865:0" data-first-offset="true"><span data-slate-string="true">其中，size 表示期望输出的剪裁尺寸。如果 size 是一个像 (h, w) 这样的元组，则剪裁后的图像尺寸将与之匹配。如果 &nbsp;size&nbsp; 是 &nbsp;int&nbsp; 类型的整数，剪裁出来的图像是 &nbsp;(size, size)&nbsp; 的正方形。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4866"><span data-slate-object="text" data-key="4867"><span data-slate-leaf="true" data-offset-key="4867:0" data-first-offset="true"><span data-slate-string="true">然后是随机剪裁，就是在一个随机位置剪裁指定的 PIL Image 或 Tensor，定义如下：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4868"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4869"><span data-slate-object="text" data-key="4870"><span data-slate-leaf="true" data-offset-key="4870:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.RandomCrop(size, padding=</span></span></span><span data-slate-object="text" data-key="4871"><span data-slate-leaf="true" data-offset-key="4871:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4872"><span data-slate-leaf="true" data-offset-key="4872:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4873"><span data-slate-object="text" data-key="4874"><span data-slate-leaf="true" data-offset-key="4874:0" data-first-offset="true"><span data-slate-string="true">其中，size 代表期望输出的剪裁尺寸，用法同上。而 padding 表示图像的每个边框上的可选填充。默认值是 None，即没有填充。通常来说，不会用 padding 这个参数，至少对于我来说至今没用过。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4875"><span data-slate-object="text" data-key="4876"><span data-slate-leaf="true" data-offset-key="4876:0" data-first-offset="true"><span data-slate-string="true">最后要说的是 FiveCrop，我们将给定的 PIL Image  或 Tensor ，分别从四角和中心进行剪裁，共剪裁成五块，定义如下：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="4877"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4878"><span data-slate-object="text" data-key="4879"><span data-slate-leaf="true" data-offset-key="4879:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.FiveCrop(size)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4880"><span data-slate-object="text" data-key="4881"><span data-slate-leaf="true" data-offset-key="4881:0" data-first-offset="true"><span data-slate-string="true">size 可以是 int 或 tuple，用法同上。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4882"><span data-slate-object="text" data-key="4883"><span data-slate-leaf="true" data-offset-key="4883:0" data-first-offset="true"><span data-slate-string="true">掌握了各种剪裁的定义和参数用法以后，我们来看一下这些剪裁操作具体如何调用，代码如下。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4884"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div><div data-code-line-number="18"></div><div data-code-line-number="19"></div><div data-code-line-number="20"></div><div data-code-line-number="21"></div><div data-code-line-number="22"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4885"><span data-slate-object="text" data-key="4886"><span data-slate-leaf="true" data-offset-key="4886:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4887"><span data-slate-leaf="true" data-offset-key="4887:0" data-first-offset="true"><span data-slate-string="true"> PIL </span></span></span><span data-slate-object="text" data-key="4888"><span data-slate-leaf="true" data-offset-key="4888:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4889"><span data-slate-leaf="true" data-offset-key="4889:0" data-first-offset="true"><span data-slate-string="true"> Image</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4890"><span data-slate-object="text" data-key="4891"><span data-slate-leaf="true" data-offset-key="4891:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4892"><span data-slate-leaf="true" data-offset-key="4892:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="4893"><span data-slate-leaf="true" data-offset-key="4893:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4894"><span data-slate-leaf="true" data-offset-key="4894:0" data-first-offset="true"><span data-slate-string="true"> transforms </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4895"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4896"><span data-slate-object="text" data-key="4897"><span data-slate-leaf="true" data-offset-key="4897:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 定义剪裁操作</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4898"><span data-slate-object="text" data-key="4899"><span data-slate-leaf="true" data-offset-key="4899:0" data-first-offset="true"><span data-slate-string="true">center_crop_oper = transforms.CenterCrop((</span></span></span><span data-slate-object="text" data-key="4900"><span data-slate-leaf="true" data-offset-key="4900:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">60</span></span></span></span><span data-slate-object="text" data-key="4901"><span data-slate-leaf="true" data-offset-key="4901:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span><span data-slate-object="text" data-key="4902"><span data-slate-leaf="true" data-offset-key="4902:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">70</span></span></span></span><span data-slate-object="text" data-key="4903"><span data-slate-leaf="true" data-offset-key="4903:0" data-first-offset="true"><span data-slate-string="true">))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4904"><span data-slate-object="text" data-key="4905"><span data-slate-leaf="true" data-offset-key="4905:0" data-first-offset="true"><span data-slate-string="true">random_crop_oper = transforms.RandomCrop((</span></span></span><span data-slate-object="text" data-key="4906"><span data-slate-leaf="true" data-offset-key="4906:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">80</span></span></span></span><span data-slate-object="text" data-key="4907"><span data-slate-leaf="true" data-offset-key="4907:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span><span data-slate-object="text" data-key="4908"><span data-slate-leaf="true" data-offset-key="4908:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">80</span></span></span></span><span data-slate-object="text" data-key="4909"><span data-slate-leaf="true" data-offset-key="4909:0" data-first-offset="true"><span data-slate-string="true">))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4910"><span data-slate-object="text" data-key="4911"><span data-slate-leaf="true" data-offset-key="4911:0" data-first-offset="true"><span data-slate-string="true">five_crop_oper = transforms.FiveCrop((</span></span></span><span data-slate-object="text" data-key="4912"><span data-slate-leaf="true" data-offset-key="4912:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">60</span></span></span></span><span data-slate-object="text" data-key="4913"><span data-slate-leaf="true" data-offset-key="4913:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span><span data-slate-object="text" data-key="4914"><span data-slate-leaf="true" data-offset-key="4914:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">70</span></span></span></span><span data-slate-object="text" data-key="4915"><span data-slate-leaf="true" data-offset-key="4915:0" data-first-offset="true"><span data-slate-string="true">))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4916"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4917"><span data-slate-object="text" data-key="4918"><span data-slate-leaf="true" data-offset-key="4918:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 原图</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4919"><span data-slate-object="text" data-key="4920"><span data-slate-leaf="true" data-offset-key="4920:0" data-first-offset="true"><span data-slate-string="true">orig_img = Image.</span></span></span><span data-slate-object="text" data-key="4921"><span data-slate-leaf="true" data-offset-key="4921:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">open</span></span></span></span><span data-slate-object="text" data-key="4922"><span data-slate-leaf="true" data-offset-key="4922:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4923"><span data-slate-leaf="true" data-offset-key="4923:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'jk.jpg'</span></span></span></span><span data-slate-object="text" data-key="4924"><span data-slate-leaf="true" data-offset-key="4924:0" data-first-offset="true"><span data-slate-string="true">) </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4925"><span data-slate-object="text" data-key="4926"><span data-slate-leaf="true" data-offset-key="4926:0" data-first-offset="true"><span data-slate-string="true">display(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4927"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4928"><span data-slate-object="text" data-key="4929"><span data-slate-leaf="true" data-offset-key="4929:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 中心剪裁</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4930"><span data-slate-object="text" data-key="4931"><span data-slate-leaf="true" data-offset-key="4931:0" data-first-offset="true"><span data-slate-string="true">img1 = center_crop_oper(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4932"><span data-slate-object="text" data-key="4933"><span data-slate-leaf="true" data-offset-key="4933:0" data-first-offset="true"><span data-slate-string="true">display(img1)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4934"><span data-slate-object="text" data-key="4935"><span data-slate-leaf="true" data-offset-key="4935:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 随机剪裁</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4936"><span data-slate-object="text" data-key="4937"><span data-slate-leaf="true" data-offset-key="4937:0" data-first-offset="true"><span data-slate-string="true">img2 = random_crop_oper(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4938"><span data-slate-object="text" data-key="4939"><span data-slate-leaf="true" data-offset-key="4939:0" data-first-offset="true"><span data-slate-string="true">display(img2)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4940"><span data-slate-object="text" data-key="4941"><span data-slate-leaf="true" data-offset-key="4941:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 四角和中心剪裁</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4942"><span data-slate-object="text" data-key="4943"><span data-slate-leaf="true" data-offset-key="4943:0" data-first-offset="true"><span data-slate-string="true">imgs = five_crop_oper(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4944"><span data-slate-object="text" data-key="4945"><span data-slate-leaf="true" data-offset-key="4945:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">for</span></span></span></span><span data-slate-object="text" data-key="4946"><span data-slate-leaf="true" data-offset-key="4946:0" data-first-offset="true"><span data-slate-string="true"> img </span></span></span><span data-slate-object="text" data-key="4947"><span data-slate-leaf="true" data-offset-key="4947:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4948"><span data-slate-leaf="true" data-offset-key="4948:0" data-first-offset="true"><span data-slate-string="true"> imgs:</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4949"><span data-slate-object="text" data-key="4950"><span data-slate-leaf="true" data-offset-key="4950:0" data-first-offset="true"><span data-slate-string="true">    display(img)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4951"><span data-slate-object="text" data-key="4952"><span data-slate-leaf="true" data-offset-key="4952:0" data-first-offset="true"><span data-slate-string="true">流程和 Resize 类似，都是先定义剪裁操作，然后对极客时间 LOGO 图片进行不同的剪裁。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4953"><span data-slate-object="text" data-key="4954"><span data-slate-leaf="true" data-offset-key="4954:0" data-first-offset="true"><span data-slate-string="true">具体剪裁效果如下表所示。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4955"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/60/b5/60ca577c5f08eef4ca727c1f0aac9cb5.jpg?wh=1384x896"></div></div><h4 data-slate-type="heading" data-slate-object="block" data-key="4956" id="sr-toc-6"><span data-slate-object="text" data-key="4957"><span data-slate-leaf="true" data-offset-key="4957:0" data-first-offset="true"><span data-slate-string="true">翻转</span></span></span></h4><div data-slate-type="paragraph" data-slate-object="block" data-key="4958"><span data-slate-object="text" data-key="4959"><span data-slate-leaf="true" data-offset-key="4959:0" data-first-offset="true"><span data-slate-string="true">接下来，我们来看一看翻转操作。</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4960"><span data-slate-object="text" data-key="4961"><span data-slate-leaf="true" data-offset-key="4961:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="4962"><span data-slate-leaf="true" data-offset-key="4962:0" data-first-offset="true"><span data-slate-string="true"> 提供了两种翻转操作，分别是：以某一概率随机水平翻转图像和以某一概率随机垂直翻转图像。我们分别来看它们的定义。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4963"><span data-slate-object="text" data-key="4964"><span data-slate-leaf="true" data-offset-key="4964:0" data-first-offset="true"><span data-slate-string="true">以概率 p 随机水平翻转图像，定义如下：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="4965"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4966"><span data-slate-object="text" data-key="4967"><span data-slate-leaf="true" data-offset-key="4967:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.RandomHorizontalFlip(p=0.5)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4968"><span data-slate-object="text" data-key="4969"><span data-slate-leaf="true" data-offset-key="4969:0" data-first-offset="true"><span data-slate-string="true">以概率 p 随机垂直翻转图像，定义如下：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="4970"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4971"><span data-slate-object="text" data-key="4972"><span data-slate-leaf="true" data-offset-key="4972:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.RandomVerticalFlip(p=0.5)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4973"><span data-slate-object="text" data-key="4974"><span data-slate-leaf="true" data-offset-key="4974:0" data-first-offset="true"><span data-slate-string="true">其中，p 表示随机翻转的概率值，默认为 0.5。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4975"><span data-slate-object="text" data-key="4976"><span data-slate-leaf="true" data-offset-key="4976:0" data-first-offset="true"><span data-slate-string="true">这里的随机翻转，是为数据增强提供方便。如果想要必须执行翻转操作的话，将 p 设置为 1 即可。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4977"><span data-slate-object="text" data-key="4978"><span data-slate-leaf="true" data-offset-key="4978:0" data-first-offset="true"><span data-slate-string="true">以极客时间的 LOGO 图片为例，图片翻转的代码如下。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4979"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4980"><span data-slate-object="text" data-key="4981"><span data-slate-leaf="true" data-offset-key="4981:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4982"><span data-slate-leaf="true" data-offset-key="4982:0" data-first-offset="true"><span data-slate-string="true"> PIL </span></span></span><span data-slate-object="text" data-key="4983"><span data-slate-leaf="true" data-offset-key="4983:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4984"><span data-slate-leaf="true" data-offset-key="4984:0" data-first-offset="true"><span data-slate-string="true"> Image</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4985"><span data-slate-object="text" data-key="4986"><span data-slate-leaf="true" data-offset-key="4986:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4987"><span data-slate-leaf="true" data-offset-key="4987:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="4988"><span data-slate-leaf="true" data-offset-key="4988:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4989"><span data-slate-leaf="true" data-offset-key="4989:0" data-first-offset="true"><span data-slate-string="true"> transforms </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4990"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4991"><span data-slate-object="text" data-key="4992"><span data-slate-leaf="true" data-offset-key="4992:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 定义翻转操作</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4993"><span data-slate-object="text" data-key="4994"><span data-slate-leaf="true" data-offset-key="4994:0" data-first-offset="true"><span data-slate-string="true">h_flip_oper = transforms.RandomHorizontalFlip(p=</span></span></span><span data-slate-object="text" data-key="4995"><span data-slate-leaf="true" data-offset-key="4995:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="4996"><span data-slate-leaf="true" data-offset-key="4996:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4997"><span data-slate-object="text" data-key="4998"><span data-slate-leaf="true" data-offset-key="4998:0" data-first-offset="true"><span data-slate-string="true">v_flip_oper = transforms.RandomVerticalFlip(p=</span></span></span><span data-slate-object="text" data-key="4999"><span data-slate-leaf="true" data-offset-key="4999:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="5000"><span data-slate-leaf="true" data-offset-key="5000:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5001"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5002"><span data-slate-object="text" data-key="5003"><span data-slate-leaf="true" data-offset-key="5003:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 原图</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5004"><span data-slate-object="text" data-key="5005"><span data-slate-leaf="true" data-offset-key="5005:0" data-first-offset="true"><span data-slate-string="true">orig_img = Image.</span></span></span><span data-slate-object="text" data-key="5006"><span data-slate-leaf="true" data-offset-key="5006:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">open</span></span></span></span><span data-slate-object="text" data-key="5007"><span data-slate-leaf="true" data-offset-key="5007:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="5008"><span data-slate-leaf="true" data-offset-key="5008:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'jk.jpg'</span></span></span></span><span data-slate-object="text" data-key="5009"><span data-slate-leaf="true" data-offset-key="5009:0" data-first-offset="true"><span data-slate-string="true">) </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5010"><span data-slate-object="text" data-key="5011"><span data-slate-leaf="true" data-offset-key="5011:0" data-first-offset="true"><span data-slate-string="true">display(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5012"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5013"><span data-slate-object="text" data-key="5014"><span data-slate-leaf="true" data-offset-key="5014:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 水平翻转</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5015"><span data-slate-object="text" data-key="5016"><span data-slate-leaf="true" data-offset-key="5016:0" data-first-offset="true"><span data-slate-string="true">img1 = h_flip_oper(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5017"><span data-slate-object="text" data-key="5018"><span data-slate-leaf="true" data-offset-key="5018:0" data-first-offset="true"><span data-slate-string="true">display(img1)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5019"><span data-slate-object="text" data-key="5020"><span data-slate-leaf="true" data-offset-key="5020:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 垂直翻转</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5021"><span data-slate-object="text" data-key="5022"><span data-slate-leaf="true" data-offset-key="5022:0" data-first-offset="true"><span data-slate-string="true">img2 = v_flip_oper(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5023"><span data-slate-object="text" data-key="5024"><span data-slate-leaf="true" data-offset-key="5024:0" data-first-offset="true"><span data-slate-string="true">display(img2)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5025"><span data-slate-object="text" data-key="5026"><span data-slate-leaf="true" data-offset-key="5026:0" data-first-offset="true"><span data-slate-string="true">翻转效果如下表所示。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="5027"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/0d/84/0dc2543bb7bdfyy7803c353f2030f184.jpg?wh=1386x675"></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="5028" id="sr-toc-7"><span data-slate-object="text" data-key="5029"><span data-slate-leaf="true" data-offset-key="5029:0" data-first-offset="true"><span data-slate-string="true">只对 Tensor 进行变换</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="5030"><span data-slate-object="text" data-key="5031"><span data-slate-leaf="true" data-offset-key="5031:0" data-first-offset="true"><span data-slate-string="true">目前版本的 Torchvision（v0.10.0）对各种图像变换操作已经基本同时支持 PIL Image 和 Tensor 类型了，因此只针对 Tensor 的变换操作很少，只有 4 个，分别是 LinearTransformation（线性变换）、Normalize（标准化）、RandomErasing（随机擦除）、ConvertImageDtype（格式转换）。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5032"><span data-slate-object="text" data-key="5033"><span data-slate-leaf="true" data-offset-key="5033:0" data-first-offset="true"><span data-slate-string="true">这里我们重点来看最常用的一个操作：标准化，其他 3 个你可以查阅官方文档。</span></span></span></div><h4 data-slate-type="heading" data-slate-object="block" data-key="5034" id="sr-toc-8"><span data-slate-object="text" data-key="5035"><span data-slate-leaf="true" data-offset-key="5035:0" data-first-offset="true"><span data-slate-string="true">标准化</span></span></span></h4><div data-slate-type="paragraph" data-slate-object="block" data-key="5036"><span data-slate-object="text" data-key="5037"><span data-slate-leaf="true" data-offset-key="5037:0" data-first-offset="true"><span data-slate-string="true">标准化是指每一个数据点减去所在通道的平均值，再除以所在通道的标准差，数学的计算公式如下：</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="5038"><span><span><span aria-hidden="true"><span><span></span><span>o</span><span>u</span><span>t</span><span>p</span><span>u</span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>(</span><span>i</span><span>n</span><span>p</span><span>u</span><span>t</span><span></span><span>−</span><span></span></span><span><span></span><span>m</span><span>e</span><span>a</span><span>n</span><span>)</span><span>/</span><span>s</span><span>t</span><span>d</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5040"><span data-slate-object="text" data-key="5041"><span data-slate-leaf="true" data-offset-key="5041:0" data-first-offset="true"><span data-slate-string="true">而对图像进行标准化，就是对图像的每个通道利用均值和标准差进行正则化。这样做的目的，是</span></span></span><span data-slate-object="text" data-key="5042"><span data-slate-leaf="true" data-offset-key="5042:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">为了保证数据集中所有的图像分布都相似，这样在训练的时候更容易收敛，既加快了训练速度，也提高了训练效果</span></span></span></span><span data-slate-object="text" data-key="5043"><span data-slate-leaf="true" data-offset-key="5043:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5044"><span data-slate-object="text" data-key="5045"><span data-slate-leaf="true" data-offset-key="5045:0" data-first-offset="true"><span data-slate-string="true">让我来解释一下：首先，标准化是一个常规做法，可以理解为无脑进行标准化后再训练的效果，大概率要好于不进行标准化。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5046"><span data-slate-object="text" data-key="5047"><span data-slate-leaf="true" data-offset-key="5047:0" data-first-offset="true"><span data-slate-string="true">我把极客时间的 LOGO 读入后，所有像素都减去 50，获得下图。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="5048"><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/3c/a1/3c3f30cee39ec09cc08fa91b4925e3a1.png?wh=640x234"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5049"><span data-slate-object="text" data-key="5050"><span data-slate-leaf="true" data-offset-key="5050:0" data-first-offset="true"><span data-slate-string="true">对于我们人来说是可以分辨出，这也是极客时间的 LOGO。但是计算机（也就是卷积神经网络）就不一定能分辨出来了，因为卷积神经网络是通过图像的像素进行提取特征的，这两张图片像素的数值都不一样，凭什么还让神经网络认为是一张图片？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5051"><span data-slate-object="text" data-key="5052"><span data-slate-leaf="true" data-offset-key="5052:0" data-first-offset="true"><span data-slate-string="true">而标准化后的数据就会避免这一问题，标准化后会将数据映射到同一区间中，一个类别的图片虽说有的像素值可能有差异，但是它们分布都是类似的分布。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5053"><span data-slate-type="code" data-slate-object="inline" data-key="5054"><span data-slate-object="text" data-key="5055"><span data-slate-leaf="true" data-offset-key="5055:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="5056"><span data-slate-leaf="true" data-offset-key="5056:0" data-first-offset="true"><span data-slate-string="true"> 提供了对 Tensor 进行标准化的函数，定义如下。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="5057"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="5058"><span data-slate-object="text" data-key="5059"><span data-slate-leaf="true" data-offset-key="5059:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.Normalize(mean, std, inplace=</span></span></span><span data-slate-object="text" data-key="5060"><span data-slate-leaf="true" data-offset-key="5060:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">False</span></span></span></span><span data-slate-object="text" data-key="5061"><span data-slate-leaf="true" data-offset-key="5061:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5062"><span data-slate-object="text" data-key="5063"><span data-slate-leaf="true" data-offset-key="5063:0" data-first-offset="true"><span data-slate-string="true">其中，每个参数的含义如下所示：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="5064"><div data-slate-type="list-line" data-slate-object="block" data-key="5065"><span data-slate-object="text" data-key="5066"><span data-slate-leaf="true" data-offset-key="5066:0" data-first-offset="true"><span data-slate-string="true">mean：表示各通道的均值；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="5067"><span data-slate-object="text" data-key="5068"><span data-slate-leaf="true" data-offset-key="5068:0" data-first-offset="true"><span data-slate-string="true">std：表示各通道的标准差；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="5069"><span data-slate-object="text" data-key="5070"><span data-slate-leaf="true" data-offset-key="5070:0" data-first-offset="true"><span data-slate-string="true">inplace：表示是否原地操作，默认为否。</span></span></span></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5071"><span data-slate-object="text" data-key="5072"><span data-slate-leaf="true" data-offset-key="5072:0" data-first-offset="true"><span data-slate-string="true">以极客时间的 LOGO 图片为例，我们来看看以 (R, G, B) 均值和标准差均为 (0.5, 0.5, 0.5) 来标准化图片后，是什么效果。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="5073"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div><div data-code-line-number="18"></div><div data-code-line-number="19"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="5074"><span data-slate-object="text" data-key="5075"><span data-slate-leaf="true" data-offset-key="5075:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="5076"><span data-slate-leaf="true" data-offset-key="5076:0" data-first-offset="true"><span data-slate-string="true"> PIL </span></span></span><span data-slate-object="text" data-key="5077"><span data-slate-leaf="true" data-offset-key="5077:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="5078"><span data-slate-leaf="true" data-offset-key="5078:0" data-first-offset="true"><span data-slate-string="true"> Image</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5079"><span data-slate-object="text" data-key="5080"><span data-slate-leaf="true" data-offset-key="5080:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="5081"><span data-slate-leaf="true" data-offset-key="5081:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="5082"><span data-slate-leaf="true" data-offset-key="5082:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="5083"><span data-slate-leaf="true" data-offset-key="5083:0" data-first-offset="true"><span data-slate-string="true"> transforms </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5084"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5085"><span data-slate-object="text" data-key="5086"><span data-slate-leaf="true" data-offset-key="5086:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 定义标准化操作</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5087"><span data-slate-object="text" data-key="5088"><span data-slate-leaf="true" data-offset-key="5088:0" data-first-offset="true"><span data-slate-string="true">norm_oper = transforms.Normalize((</span></span></span><span data-slate-object="text" data-key="5089"><span data-slate-leaf="true" data-offset-key="5089:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5090"><span data-slate-leaf="true" data-offset-key="5090:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5091"><span data-slate-leaf="true" data-offset-key="5091:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5092"><span data-slate-leaf="true" data-offset-key="5092:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5093"><span data-slate-leaf="true" data-offset-key="5093:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5094"><span data-slate-leaf="true" data-offset-key="5094:0" data-first-offset="true"><span data-slate-string="true">), (</span></span></span><span data-slate-object="text" data-key="5095"><span data-slate-leaf="true" data-offset-key="5095:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5096"><span data-slate-leaf="true" data-offset-key="5096:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5097"><span data-slate-leaf="true" data-offset-key="5097:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5098"><span data-slate-leaf="true" data-offset-key="5098:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5099"><span data-slate-leaf="true" data-offset-key="5099:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5100"><span data-slate-leaf="true" data-offset-key="5100:0" data-first-offset="true"><span data-slate-string="true">))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5101"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5102"><span data-slate-object="text" data-key="5103"><span data-slate-leaf="true" data-offset-key="5103:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 原图</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5104"><span data-slate-object="text" data-key="5105"><span data-slate-leaf="true" data-offset-key="5105:0" data-first-offset="true"><span data-slate-string="true">orig_img = Image.</span></span></span><span data-slate-object="text" data-key="5106"><span data-slate-leaf="true" data-offset-key="5106:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">open</span></span></span></span><span data-slate-object="text" data-key="5107"><span data-slate-leaf="true" data-offset-key="5107:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="5108"><span data-slate-leaf="true" data-offset-key="5108:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'jk.jpg'</span></span></span></span><span data-slate-object="text" data-key="5109"><span data-slate-leaf="true" data-offset-key="5109:0" data-first-offset="true"><span data-slate-string="true">) </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5110"><span data-slate-object="text" data-key="5111"><span data-slate-leaf="true" data-offset-key="5111:0" data-first-offset="true"><span data-slate-string="true">display(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5112"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5113"><span data-slate-object="text" data-key="5114"><span data-slate-leaf="true" data-offset-key="5114:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 图像转化为 Tensor</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5115"><span data-slate-object="text" data-key="5116"><span data-slate-leaf="true" data-offset-key="5116:0" data-first-offset="true"><span data-slate-string="true">img_tensor = transforms.ToTensor()(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5117"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5118"><span data-slate-object="text" data-key="5119"><span data-slate-leaf="true" data-offset-key="5119:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 标准化</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5120"><span data-slate-object="text" data-key="5121"><span data-slate-leaf="true" data-offset-key="5121:0" data-first-offset="true"><span data-slate-string="true">tensor_norm = norm_oper(img_tensor)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5122"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5123"><span data-slate-object="text" data-key="5124"><span data-slate-leaf="true" data-offset-key="5124:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># Tensor 转化为图像</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5125"><span data-slate-object="text" data-key="5126"><span data-slate-leaf="true" data-offset-key="5126:0" data-first-offset="true"><span data-slate-string="true">img_norm = transforms.ToPILImage()(tensor_norm)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5127"><span data-slate-object="text" data-key="5128"><span data-slate-leaf="true" data-offset-key="5128:0" data-first-offset="true"><span data-slate-string="true">display(img_norm)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5129"><span data-slate-object="text" data-key="5130"><span data-slate-leaf="true" data-offset-key="5130:0" data-first-offset="true"><span data-slate-string="true">上面代码的过程是，首先定义了均值和标准差均为 (0.5, 0.5, 0.5) 的标准化操作，然后将原图转化为 Tensor，接着对 Tensor 进行标准化，最后再将 Tensor 转化为图像输出。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5131"><span data-slate-object="text" data-key="5132"><span data-slate-leaf="true" data-offset-key="5132:0" data-first-offset="true"><span data-slate-string="true">标准化的效果如下表所示。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="5133"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/f5/05/f58f3662e60501e02b31b12fa9f4e905.jpg?wh=1244x515"></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="5134" id="sr-toc-9"><span data-slate-object="text" data-key="5135"><span data-slate-leaf="true" data-offset-key="5135:0" data-first-offset="true"><span data-slate-string="true">变换的组合</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="5136"><span data-slate-object="text" data-key="5137"><span data-slate-leaf="true" data-offset-key="5137:0" data-first-offset="true"><span data-slate-string="true">其实前面介绍过的所有操作都可以用 Compose 类组合起来，进行连续操作。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5138"><span data-slate-object="text" data-key="5139"><span data-slate-leaf="true" data-offset-key="5139:0" data-first-offset="true"><span data-slate-string="true">Compose 类是将多个变换组合到一起，它的定义如下。</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="5140"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="5141"><span data-slate-object="text" data-key="5142"><span data-slate-leaf="true" data-offset-key="5142:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms.Compose(transforms)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5143"><span data-slate-object="text" data-key="5144"><span data-slate-leaf="true" data-offset-key="5144:0" data-first-offset="true"><span data-slate-string="true">其中，transforms 是一个 Transform 对象的列表，表示要组合的变换列表。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5145"><span data-slate-object="text" data-key="5146"><span data-slate-leaf="true" data-offset-key="5146:0" data-first-offset="true"><span data-slate-string="true">我们还是结合例子动手试试，如果我们想要将图片变为 200*200 像素大小，并且随机裁切成 80 像素的正方形。那么我们可以组合 Resize 和 RandomCrop 变换，具体代码如下所示。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="5147"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="5148"><span data-slate-object="text" data-key="5149"><span data-slate-leaf="true" data-offset-key="5149:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="5150"><span data-slate-leaf="true" data-offset-key="5150:0" data-first-offset="true"><span data-slate-string="true"> PIL </span></span></span><span data-slate-object="text" data-key="5151"><span data-slate-leaf="true" data-offset-key="5151:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="5152"><span data-slate-leaf="true" data-offset-key="5152:0" data-first-offset="true"><span data-slate-string="true"> Image</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5153"><span data-slate-object="text" data-key="5154"><span data-slate-leaf="true" data-offset-key="5154:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="5155"><span data-slate-leaf="true" data-offset-key="5155:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="5156"><span data-slate-leaf="true" data-offset-key="5156:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="5157"><span data-slate-leaf="true" data-offset-key="5157:0" data-first-offset="true"><span data-slate-string="true"> transforms </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5158"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5159"><span data-slate-object="text" data-key="5160"><span data-slate-leaf="true" data-offset-key="5160:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 原图</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5161"><span data-slate-object="text" data-key="5162"><span data-slate-leaf="true" data-offset-key="5162:0" data-first-offset="true"><span data-slate-string="true">orig_img = Image.</span></span></span><span data-slate-object="text" data-key="5163"><span data-slate-leaf="true" data-offset-key="5163:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">open</span></span></span></span><span data-slate-object="text" data-key="5164"><span data-slate-leaf="true" data-offset-key="5164:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="5165"><span data-slate-leaf="true" data-offset-key="5165:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'jk.jpg'</span></span></span></span><span data-slate-object="text" data-key="5166"><span data-slate-leaf="true" data-offset-key="5166:0" data-first-offset="true"><span data-slate-string="true">) </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5167"><span data-slate-object="text" data-key="5168"><span data-slate-leaf="true" data-offset-key="5168:0" data-first-offset="true"><span data-slate-string="true">display(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5169"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5170"><span data-slate-object="text" data-key="5171"><span data-slate-leaf="true" data-offset-key="5171:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 定义组合操作</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5172"><span data-slate-object="text" data-key="5173"><span data-slate-leaf="true" data-offset-key="5173:0" data-first-offset="true"><span data-slate-string="true">composed = transforms.Compose([transforms.Resize((</span></span></span><span data-slate-object="text" data-key="5174"><span data-slate-leaf="true" data-offset-key="5174:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">200</span></span></span></span><span data-slate-object="text" data-key="5175"><span data-slate-leaf="true" data-offset-key="5175:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5176"><span data-slate-leaf="true" data-offset-key="5176:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">200</span></span></span></span><span data-slate-object="text" data-key="5177"><span data-slate-leaf="true" data-offset-key="5177:0" data-first-offset="true"><span data-slate-string="true">)),</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5178"><span data-slate-object="text" data-key="5179"><span data-slate-leaf="true" data-offset-key="5179:0" data-first-offset="true"><span data-slate-string="true">                               transforms.RandomCrop(</span></span></span><span data-slate-object="text" data-key="5180"><span data-slate-leaf="true" data-offset-key="5180:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">80</span></span></span></span><span data-slate-object="text" data-key="5181"><span data-slate-leaf="true" data-offset-key="5181:0" data-first-offset="true"><span data-slate-string="true">)])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5182"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5183"><span data-slate-object="text" data-key="5184"><span data-slate-leaf="true" data-offset-key="5184:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 组合操作后的图</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5185"><span data-slate-object="text" data-key="5186"><span data-slate-leaf="true" data-offset-key="5186:0" data-first-offset="true"><span data-slate-string="true">img = composed(orig_img)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5187"><span data-slate-object="text" data-key="5188"><span data-slate-leaf="true" data-offset-key="5188:0" data-first-offset="true"><span data-slate-string="true">display(img)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5189"><span data-slate-object="text" data-key="5190"><span data-slate-leaf="true" data-offset-key="5190:0" data-first-offset="true"><span data-slate-string="true">运行的结果如下表所示，也推荐你动手试试看。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="5191"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/6b/c1/6b3ce280815cff443734c9b8180fc6c1.jpg?wh=1046x505"></div></div><h2 data-slate-type="heading" data-slate-object="block" data-key="5192" id="sr-toc-10"><span data-slate-object="text" data-key="5193"><span data-slate-leaf="true" data-offset-key="5193:0" data-first-offset="true"><span data-slate-string="true">结合 datasets 使用</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="5194"><span data-slate-object="text" data-key="5195"><span data-slate-leaf="true" data-offset-key="5195:0" data-first-offset="true"><span data-slate-string="true">Compose 类是未来我们在实际项目中经常要使用到的类，结合</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="5196"><span data-slate-object="text" data-key="5197"><span data-slate-leaf="true" data-offset-key="5197:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="5198"><span data-slate-leaf="true" data-offset-key="5198:0" data-first-offset="true"><span data-slate-string="true"> 包，就可以在读取数据集的时候做图像变换与数据增强操作。下面让我们一起来看一看。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5199"><span data-slate-object="text" data-key="5200"><span data-slate-leaf="true" data-offset-key="5200:0" data-first-offset="true"><span data-slate-string="true">还记得</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="5201"><span data-slate-object="text" data-key="5202"><span data-slate-leaf="true" data-offset-key="5202:0" data-first-offset="true"><span data-slate-string="true">上一节课</span></span></span></a><span data-slate-object="text" data-key="5203"><span data-slate-leaf="true" data-offset-key="5203:0" data-first-offset="true"><span data-slate-string="true">中，在利用</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="5204"><span data-slate-object="text" data-key="5205"><span data-slate-leaf="true" data-offset-key="5205:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="5206"><span data-slate-leaf="true" data-offset-key="5206:0" data-first-offset="true"><span data-slate-string="true"> 读取 MNIST 数据集时，有一个参数 “transform” 吗？它就是用于对图像进行预处理操作的，例如数据增强、归一化、旋转或缩放等。这里的 “transform” 就可以接收一个</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="5207"><span data-slate-object="text" data-key="5208"><span data-slate-leaf="true" data-offset-key="5208:0" data-first-offset="true"><span data-slate-string="true"> torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="5209"><span data-slate-leaf="true" data-offset-key="5209:0" data-first-offset="true"><span data-slate-string="true"> 操作或者由 Compose 类所定义的操作组合。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5210"><span data-slate-object="text" data-key="5211"><span data-slate-leaf="true" data-offset-key="5211:0" data-first-offset="true"><span data-slate-string="true">上节课中，我们在读取 MNIST 数据集时，直接读取出来的图像数据是 PIL.Image.Image 类型的。但是遇到要训练手写数字识别模型这类的情况，模型接收的数据类型是 Tensor，而不是 PIL 对象。这时候，我们就可以利用 “transform” 参数，使数据在读取的同时做类型转换，这样读取出的数据直接就可以是 Tensor 类型了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5212"><span data-slate-object="text" data-key="5213"><span data-slate-leaf="true" data-offset-key="5213:0" data-first-offset="true"><span data-slate-string="true">不只是数据类型的转换，我们还可以增加归一化等数据增强的操作，只需要使用上面介绍过的 Compose 类进行组合即可。这样，在读取数据的同时，我们也就完成了数据预处理、数据增强等一系列操作。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5214"><span data-slate-object="text" data-key="5215"><span data-slate-leaf="true" data-offset-key="5215:0" data-first-offset="true"><span data-slate-string="true">我们还是以读取 MNIST 数据集为例，看下如何在读取数据的同时，完成数据预处理等操作。具体代码如下。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="5216"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div><div data-code-line-number="18"></div><div data-code-line-number="19"></div><div data-code-line-number="20"></div><div data-code-line-number="21"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="5217"><span data-slate-object="text" data-key="5218"><span data-slate-leaf="true" data-offset-key="5218:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="5219"><span data-slate-leaf="true" data-offset-key="5219:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="5220"><span data-slate-leaf="true" data-offset-key="5220:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="5221"><span data-slate-leaf="true" data-offset-key="5221:0" data-first-offset="true"><span data-slate-string="true"> transforms</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5222"><span data-slate-object="text" data-key="5223"><span data-slate-leaf="true" data-offset-key="5223:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="5224"><span data-slate-leaf="true" data-offset-key="5224:0" data-first-offset="true"><span data-slate-string="true"> torchvision </span></span></span><span data-slate-object="text" data-key="5225"><span data-slate-leaf="true" data-offset-key="5225:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="5226"><span data-slate-leaf="true" data-offset-key="5226:0" data-first-offset="true"><span data-slate-string="true"> datasets</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5227"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5228"><span data-slate-object="text" data-key="5229"><span data-slate-leaf="true" data-offset-key="5229:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 定义一个 transform</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5230"><span data-slate-object="text" data-key="5231"><span data-slate-leaf="true" data-offset-key="5231:0" data-first-offset="true"><span data-slate-string="true">my_transform = transforms.Compose([transforms.ToTensor(),</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5232"><span data-slate-object="text" data-key="5233"><span data-slate-leaf="true" data-offset-key="5233:0" data-first-offset="true"><span data-slate-string="true">                                   transforms.Normalize((</span></span></span><span data-slate-object="text" data-key="5234"><span data-slate-leaf="true" data-offset-key="5234:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5235"><span data-slate-leaf="true" data-offset-key="5235:0" data-first-offset="true"><span data-slate-string="true">), (</span></span></span><span data-slate-object="text" data-key="5236"><span data-slate-leaf="true" data-offset-key="5236:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.5</span></span></span></span><span data-slate-object="text" data-key="5237"><span data-slate-leaf="true" data-offset-key="5237:0" data-first-offset="true"><span data-slate-string="true">))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5238"><span data-slate-object="text" data-key="5239"><span data-slate-leaf="true" data-offset-key="5239:0" data-first-offset="true"><span data-slate-string="true">                                  ])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5240"><span data-slate-object="text" data-key="5241"><span data-slate-leaf="true" data-offset-key="5241:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 读取 MNIST 数据集 同时做数据变换</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5242"><span data-slate-object="text" data-key="5243"><span data-slate-leaf="true" data-offset-key="5243:0" data-first-offset="true"><span data-slate-string="true">mnist_dataset = datasets.MNIST(root=</span></span></span><span data-slate-object="text" data-key="5244"><span data-slate-leaf="true" data-offset-key="5244:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'./data'</span></span></span></span><span data-slate-object="text" data-key="5245"><span data-slate-leaf="true" data-offset-key="5245:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5246"><span data-slate-object="text" data-key="5247"><span data-slate-leaf="true" data-offset-key="5247:0" data-first-offset="true"><span data-slate-string="true">                               train=</span></span></span><span data-slate-object="text" data-key="5248"><span data-slate-leaf="true" data-offset-key="5248:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">False</span></span></span></span><span data-slate-object="text" data-key="5249"><span data-slate-leaf="true" data-offset-key="5249:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5250"><span data-slate-object="text" data-key="5251"><span data-slate-leaf="true" data-offset-key="5251:0" data-first-offset="true"><span data-slate-string="true">                               transform=my_transform,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5252"><span data-slate-object="text" data-key="5253"><span data-slate-leaf="true" data-offset-key="5253:0" data-first-offset="true"><span data-slate-string="true">                               target_transform=</span></span></span><span data-slate-object="text" data-key="5254"><span data-slate-leaf="true" data-offset-key="5254:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="5255"><span data-slate-leaf="true" data-offset-key="5255:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5256"><span data-slate-object="text" data-key="5257"><span data-slate-leaf="true" data-offset-key="5257:0" data-first-offset="true"><span data-slate-string="true">                               download=</span></span></span><span data-slate-object="text" data-key="5258"><span data-slate-leaf="true" data-offset-key="5258:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">True</span></span></span></span><span data-slate-object="text" data-key="5259"><span data-slate-leaf="true" data-offset-key="5259:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5260"></div><div data-slate-type="code-line" data-slate-object="block" data-key="5261"><span data-slate-object="text" data-key="5262"><span data-slate-leaf="true" data-offset-key="5262:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 查看变换后的数据类型</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5263"><span data-slate-object="text" data-key="5264"><span data-slate-leaf="true" data-offset-key="5264:0" data-first-offset="true"><span data-slate-string="true">item = mnist_dataset.__getitem__(</span></span></span><span data-slate-object="text" data-key="5265"><span data-slate-leaf="true" data-offset-key="5265:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="5266"><span data-slate-leaf="true" data-offset-key="5266:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5267"><span data-slate-object="text" data-key="5268"><span data-slate-leaf="true" data-offset-key="5268:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="5269"><span data-slate-leaf="true" data-offset-key="5269:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="5270"><span data-slate-leaf="true" data-offset-key="5270:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">type</span></span></span></span><span data-slate-object="text" data-key="5271"><span data-slate-leaf="true" data-offset-key="5271:0" data-first-offset="true"><span data-slate-string="true">(item[</span></span></span><span data-slate-object="text" data-key="5272"><span data-slate-leaf="true" data-offset-key="5272:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="5273"><span data-slate-leaf="true" data-offset-key="5273:0" data-first-offset="true"><span data-slate-string="true">]))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5274"><span data-slate-object="text" data-key="5275"><span data-slate-leaf="true" data-offset-key="5275:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5276"><span data-slate-object="text" data-key="5277"><span data-slate-leaf="true" data-offset-key="5277:0" data-first-offset="true"><span data-slate-string="true">输出：</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5278"><span data-slate-object="text" data-key="5279"><span data-slate-leaf="true" data-offset-key="5279:0" data-first-offset="true"><span data-slate-string="true">&lt;class 'torch.Tensor'&gt;</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5280"><span data-slate-object="text" data-key="5281"><span data-slate-leaf="true" data-offset-key="5281:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5282"><span data-slate-object="text" data-key="5283"><span data-slate-leaf="true" data-offset-key="5283:0" data-first-offset="true"><span data-slate-string="true">当然，MNIST 数据集非常简单，根本不进行任何处理直接读入的话，效果也非常好，但是它确实适合学习来使用，你可以在利用它进行各种尝试。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5284"><span data-slate-object="text" data-key="5285"><span data-slate-leaf="true" data-offset-key="5285:0" data-first-offset="true"><span data-slate-string="true">我们下面先来看看，在图像分类实战中使用的 transform，可以感受一下实际使用的 transforms 是什么样子：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="5286"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="5287"><span data-slate-object="text" data-key="5288"><span data-slate-leaf="true" data-offset-key="5288:0" data-first-offset="true"><span data-slate-string="true">transform = transforms.Compose([</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5289"><span data-slate-object="text" data-key="5290"><span data-slate-leaf="true" data-offset-key="5290:0" data-first-offset="true"><span data-slate-string="true">    transforms.RandomResizedCrop(dest_image_size),</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5291"><span data-slate-object="text" data-key="5292"><span data-slate-leaf="true" data-offset-key="5292:0" data-first-offset="true"><span data-slate-string="true">    transforms.RandomHorizontalFlip(),</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5293"><span data-slate-object="text" data-key="5294"><span data-slate-leaf="true" data-offset-key="5294:0" data-first-offset="true"><span data-slate-string="true">    transforms.ToTensor(),</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5295"><span data-slate-object="text" data-key="5296"><span data-slate-leaf="true" data-offset-key="5296:0" data-first-offset="true"><span data-slate-string="true">    transforms.Normalize(mean=[</span></span></span><span data-slate-object="text" data-key="5297"><span data-slate-leaf="true" data-offset-key="5297:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.485</span></span></span></span><span data-slate-object="text" data-key="5298"><span data-slate-leaf="true" data-offset-key="5298:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5299"><span data-slate-leaf="true" data-offset-key="5299:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.456</span></span></span></span><span data-slate-object="text" data-key="5300"><span data-slate-leaf="true" data-offset-key="5300:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5301"><span data-slate-leaf="true" data-offset-key="5301:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.406</span></span></span></span><span data-slate-object="text" data-key="5302"><span data-slate-leaf="true" data-offset-key="5302:0" data-first-offset="true"><span data-slate-string="true">], std=[</span></span></span><span data-slate-object="text" data-key="5303"><span data-slate-leaf="true" data-offset-key="5303:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.229</span></span></span></span><span data-slate-object="text" data-key="5304"><span data-slate-leaf="true" data-offset-key="5304:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5305"><span data-slate-leaf="true" data-offset-key="5305:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.224</span></span></span></span><span data-slate-object="text" data-key="5306"><span data-slate-leaf="true" data-offset-key="5306:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="5307"><span data-slate-leaf="true" data-offset-key="5307:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.225</span></span></span></span><span data-slate-object="text" data-key="5308"><span data-slate-leaf="true" data-offset-key="5308:0" data-first-offset="true"><span data-slate-string="true">])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="5309"><span data-slate-object="text" data-key="5310"><span data-slate-leaf="true" data-offset-key="5310:0" data-first-offset="true"><span data-slate-string="true">    ])</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5311"><span data-slate-object="text" data-key="5312"><span data-slate-leaf="true" data-offset-key="5312:0" data-first-offset="true"><span data-slate-string="true">这也是我在项目中使用的 transform。数据增强的方法有很多，不过根据我的经验来看，并不是用的越多，效果越好。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="5313" id="sr-toc-11"><span data-slate-object="text" data-key="5314"><span data-slate-leaf="true" data-offset-key="5314:0" data-first-offset="true"><span data-slate-string="true">小结</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="5315"><span data-slate-object="text" data-key="5316"><span data-slate-leaf="true" data-offset-key="5316:0" data-first-offset="true"><span data-slate-string="true">恭喜你完成了这节课的学习，我来给你做个总结。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5317"><span data-slate-object="text" data-key="5318"><span data-slate-leaf="true" data-offset-key="5318:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">今天的重点内容就是</span></span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="5319"><span data-slate-object="text" data-key="5320"><span data-slate-leaf="true" data-offset-key="5320:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true"> torchvision.transforms</span></span></span></span></span><span data-slate-object="text" data-key="5321"><span data-slate-leaf="true" data-offset-key="5321:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true"> 工具的使用。包括常用的图像处理操作，以及如何与</span></span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="5322"><span data-slate-object="text" data-key="5323"><span data-slate-leaf="true" data-offset-key="5323:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true"> torchvision.datasets</span></span></span></span></span><span data-slate-object="text" data-key="5324"><span data-slate-leaf="true" data-offset-key="5324:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true"> 结合使用</span></span></span></span><span data-slate-object="text" data-key="5325"><span data-slate-leaf="true" data-offset-key="5325:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5326"><span data-slate-object="text" data-key="5327"><span data-slate-leaf="true" data-offset-key="5327:0" data-first-offset="true"><span data-slate-string="true">常用的图像处理操作包括数据类型转换、图像尺寸变化、剪裁、翻转、标准化等等。Compose 类还可以将多个变换操作组合成一个 Transform 对象的列表。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5328"><span data-slate-type="code" data-slate-object="inline" data-key="5329"><span data-slate-object="text" data-key="5330"><span data-slate-leaf="true" data-offset-key="5330:0" data-first-offset="true"><span data-slate-string="true">torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="5331"><span data-slate-leaf="true" data-offset-key="5331:0" data-first-offset="true"><span data-slate-string="true"> 与</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="5332"><span data-slate-object="text" data-key="5333"><span data-slate-leaf="true" data-offset-key="5333:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="5334"><span data-slate-leaf="true" data-offset-key="5334:0" data-first-offset="true"><span data-slate-string="true"> 结合使用，可以在数据加载的同时进行一系列图像变换与数据增强操作，不仅能够直接将数据送入模型训练，还可以加快模型收敛速度，让模型更好地学习到数据特征。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5335"><span data-slate-object="text" data-key="5336"><span data-slate-leaf="true" data-offset-key="5336:0" data-first-offset="true"><span data-slate-string="true">当然，我们在实际的项目中会有自己的数据，而不会使用 torchvision.datasets 中提供的公开数据集，我们今天讲的</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="5337"><span data-slate-object="text" data-key="5338"><span data-slate-leaf="true" data-offset-key="5338:0" data-first-offset="true"><span data-slate-string="true"> torchvision.transforms</span></span></span></span><span data-slate-object="text" data-key="5339"><span data-slate-leaf="true" data-offset-key="5339:0" data-first-offset="true"><span data-slate-string="true"> 同样可以在我们自定义的数据集中使用，关于这一点，我会在图像分类的实战中继续讲解。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5340"><span data-slate-object="text" data-key="5341"><span data-slate-leaf="true" data-offset-key="5341:0" data-first-offset="true"><span data-slate-string="true">下节课中，我们会介绍 Torchvision 中其他有趣的功能。包括经典网络模型的实例化与其他有用的函数。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="5342" id="sr-toc-12"><span data-slate-object="text" data-key="5343"><span data-slate-leaf="true" data-offset-key="5343:0" data-first-offset="true"><span data-slate-string="true">每课一练</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="5344"><span data-slate-object="text" data-key="5345"><span data-slate-leaf="true" data-offset-key="5345:0" data-first-offset="true"><span data-slate-string="true">Torchvision 中 transforms 模块的作用是什么？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5346"><span data-slate-object="text" data-key="5347"><span data-slate-leaf="true" data-offset-key="5347:0" data-first-offset="true"><span data-slate-string="true">欢迎你在留言区跟我交流讨论，也欢迎你把这节课分享给自己的朋友，和他一起尝试一下 Torchvision 的各种功能。</span></span></span></div></div></div></div><div><div></div><div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><textarea placeholder="将学到的知识总结成笔记，方便日后快速查找及复习"></textarea></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div><div><div>确认放弃笔记？</div><div>放弃后所记笔记将不保留。</div></div><div><div>新功能上线，你的历史笔记已初始化为私密笔记，是否一键批量公开？</div><div>批量公开的笔记不会为你同步至部落</div></div><div></div></div><div><div><div>公开</div><div>同步至部落</div></div><div>取消</div><div>完成</div></div><div><span>0/2000</span></div></div><div><div><span>划线</span></div><div></div><div></div><div></div><div><span>笔记</span></div><div></div><div><span>复制</span></div></div></div><div><div><div><span></span></div><p><a href="javascript:void(0);">给文章提建议</a></p></div></div><div><span>©</span> 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 </div></div><div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div><div>Geek__653581f21177</div></div><div><textarea placeholder="由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。" rows="16"></textarea></div><div><div>Ctrl + Enter 发表</div><div>0/2000 字符</div><div>提交留言</div></div></div><div><h2 id="sr-toc-13">精选留言 (14)</h2><ul><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/3a/d2/cbd2c882.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Yuhan</span></div></div><div>老师您好，感觉应该注明一下 display 函数的来源，是 Ipython.display 里面的 display 函数吗？</div><div><p>作者回复：你好，Yuhan，感谢你的留言。
display 的来源是：
from IPython.display import display
在 jupyter 中可以直接调用无需 import。^^</p></div><div><div>2021-10-25</div><div><div><i></i><span>5</span></div><div><i></i><span>7</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/29/45/64/ab1fada2.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 上岸吧，Adagio</span></div></div><div>老师您好，请问

img1 = transforms.ToTensor ()(img)
img2 = transforms.ToPILImage ()(img1)

是怎么使用的呢？
transforms.ToTensor 是一个类，为什么不把 img 当做参数传给这个类做初始化呢？
transforms.ToTensor () 是创建一个对象吗？为什么后面又直接传入了 (img) 参数呢？
不太懂这一块的细节，请老师帮忙解答下～
</div><div><p>作者回复: Hi，感谢你的提问。
transforms.ToTensor ()  相当于创建了一个 ToTensor 的实例。
transforms.ToTensor ()(img)  是执行了 ToTensor 中的__call__方法（如下链接）。
https://github.com/pytorch/vision/blob/main/torchvision/transforms/transforms.py#L123
这部分属于 Python 的知识，详细的内容你可以看看 Python 中__call__的作用。简单来说__call__的作用是使实例能够像函数一样被调用。
transforms.ToPILImage () 同理。^^</p></div><div><div>2021-12-01</div><div><div><i></i></div><div><i></i><span>5</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132"></div></div><div><div><div><span>vcjmhg</span></div></div><div>Torchvision 中 transforms 模块的作用：封装了常用的图像操作，例随机切割、旋转、数据类型转换、tensor 与 numpy 和 PIL Image 的互换等。</div><div><p>作者回复：你好，谢谢留言。完美👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻。：）加油～</p></div><div><div>2021-10-27</div><div><div><i></i></div><div><i></i><span>4</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2b/5e/f9/96896116.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 天凉好个秋</span></div></div><div>老师你好，在使用 Resize 的时候，出现以下 warning:

UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.

在之前的回答中给的解决方案的第二条：将 Image.BICUBIC 替换为 InterpolationMode.BICUBIC，这个是在哪儿替换？transforms.py 的源代码中也没有相关代码</div><div><p>作者回复: Hi,
是 resize 中的 interpolation 参数。
例如，torchvision.transforms.Resize ((128, 128),  interpolation=InterpolationMode.BICUBIC）。
这个参数接收 int 也可以，就是当 int 的时候，就会报这个 warning。

</p></div><div><div>2021-12-18</div><div><div><i></i></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/account/avatar/00/19/62/09/7fd0634a.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 汤火火火</span></div></div><div>老师您好，我想问一下，在训练时对图像做了标准化，那测试的时候需要对测试图像做标准化吗？</div><div><p>作者回复：你好，汤火火火，感谢留言。
需要，预测时数据做的预处理（标准化之类的）操作要与训练时做的预处理操作一毛一样。</p></div><div><div>2022-01-20</div><div><div><i></i><span>3</span></div><div><i></i><span>2</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 亚林</span></div></div><div>Torchvision 中 transforms 模块的作用图像数据的预处理。怎么标准化，这些标准化参数是如何确定的类？</div><div><p>作者回复：你好，亚林
是说标准化的参数如何确定的是吧。
通常来说如果使用其他人的模型做微调的话，就要与原作者的数据处理方式一致，例如后面的图像分类中讲的 EfficientNet。我想这也是大部分会遇到的情况。
如果是完全自己重新训练的话，可以参考一些 ImageNet 上的预处理方式，其实也就那几种，减均值，除以标准差之类的。</p></div><div><div>2022-05-12</div><div><div><i></i></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2b/8c/c4/9fbe78cf.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 快快🔥</span></div></div><div>老师，我想问下，在 transform.dataset () 中进行 transforms 的转换操作，是会将原图像数据覆盖掉吗，还是产生新的转换后的数据。</div><div><p>作者回复: hi，你好。感谢留言。输入给模型的数据是转换后的数据。原始图像不会变。</p></div><div><div>2021-11-28</div><div><div><i></i></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>John (易筋)</span></div></div><div>加上逗号解决：too many indices for tensor of dimension 0
The problem is that the mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values:


# 定义一个 transform
my_transform = transforms.Compose ([transforms.ToTensor (),
                                   transforms.Normalize ((0.5,), (0.5,))

ref: https://stackoverflow.com/questions/56745486/pytorch-dataloader-indexerror-too-many-indices-for-tensor-of-dimension-0</div><div><p>作者回复: 👍🏻^^</p></div><div><div>2022-07-29</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>John (易筋)</span></div></div><div>老师，请教 执行报错
my_transform = transforms.Compose ([transforms.ToTensor (),
                                   transforms.Normalize ((0.5), (0.5))
                                  ])
mnist_dataset = datasets.MNIST (root='./data',
                               train=False,
                               transform=my_transform,
                               target_transform=None,
                               download=True)
item = mnist_dataset.__getitem__(0)
print (type (item [0]))

---------
IndexError                                Traceback (most recent call last)
&lt;ipython-input-1-bc3a8de1cbd4&gt; in &lt;module&gt;
     14 
     15 # 查看变换后的数据类型
---&gt; 16 item = mnist_dataset.__getitem__(0)
     17 print (type (item [0]))

~/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py in __getitem__(self, index)
     93 
     94         if self.transform is not None:
---&gt; 95             img = self.transform (img)
     96 
     97         if self.target_transform is not None:

~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py in __call__(self, img)
     58     def __call__(self, img):
     59         for t in self.transforms:
---&gt; 60             img = t (img)
     61         return img
     62 

~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py in __call__(self, tensor)
    161             Tensor: Normalized Tensor image.
    162         """
--&gt; 163         return F.normalize (tensor, self.mean, self.std, self.inplace)
    164 
    165     def __repr__(self):

~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py in normalize (tensor, mean, std, inplace)
    206     mean = torch.tensor (mean, dtype=torch.float32)
    207     std = torch.tensor (std, dtype=torch.float32)
--&gt; 208     tensor.sub_(mean [:, None, None]).div_(std [:, None, None])
    209     return tensor
    210 

IndexError: too many indices for tensor of dimension 0
</div><div><div>2022-07-29</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div></div><div><div><div><span>Geek_b454ca</span></div></div><div>老师您好，Torchvision 中有 transform 这些可以对数据进行标准化的函数，如果不是要处理图像数据，在 pytorch 中是不是也有类似的对数据进行标准化等 transform 操作的函数呢？</div><div><p>作者回复：你好，你说的是行列二维表那种数据吗？
似乎是没有，你可以查查。^^</p></div><div><div>2022-03-24</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/29/5d/3f/ad1fed4a.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>黑暗骑士</span></div></div><div>老师您好，
这节课我们对于数据本身进行了一系列操作，请问相应的标签如何处理呢？是不是会自动匹配？</div><div><p>作者回复：嗯嗯，是的。标签没有变。
原始数据是 (image, target) 这样的形式，只是对 image 进行了变换，而不是新增一些数据。</p></div><div><div>2022-03-05</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/14/0f/53/92a50f01.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>徐洲更</span></div></div><div>老师您好，对于 torchvision 提供的 datasets, 可以应用我们定义的 transforms.Compose, 在读取时同时做数据变换。 那么对于我们自己的图像数据集，是不是只能定义一个函数，一边读取成 tensor，然后一边处理？</div><div><p>作者回复：你好，徐洲更，感谢你的留言。我们自己定义的数据集也可以使用 transforms.Compose 对数据进行变换.
在图像分类 (下) 中，就会用到.</p></div><div><div>2021-11-30</div><div><div><i></i><span>2</span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/8d/8a/ec29ca4a.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>马克图布</span></div></div><div>老师，在使用 Resize 的时候，出现以下 warning:

UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.

这个是可以直接忽略的吗？</div><div><p>作者回复：你好，马克图布，谢谢你的留言。
warning 可以忽略。
这主要是由于 pillow 包 / Image 包插值模式造成的。
解决方案：
1. 导入 from torchvision.transforms import InterpolationMode
2. 将 Image.BICUBIC 替换为 InterpolationMode.BICUBIC</p></div><div><div>2021-11-06</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/e2/21/3bb82a79.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>栗白</span></div></div><div>是图像的预处理操作。</div><div><p>作者回复：你好，。👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻👍🏻正确 ^^。
包含常用的图像操作，例如随机切割、旋转、Tensor 与 Numpy 和 PIL Image 的数据类型转换等。</p></div><div><div>2021-10-26</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li></ul><div> 收起评论<span></span></div></div></sr-rd-content>
                            <toc-bg><toc style="width: initial;overflow: auto!important;"class="simpread-font simpread-theme-root" data-reactid=".m"><outline class="toc-level-h1" data-reactid=".m.0" style="width: 175px;"><active data-reactid=".m.0.0" ></active><a class="toc-outline-theme-github" href="#sr-toc-0" data-reactid=".m.0.1"><span data-reactid=".m.0.1.0"> 07 | Torchvision（中）：数据增强，让数据更加多样性</span></a></outline><outline class="toc-level-h2" data-reactid=".m.1" style="width: 165px;"><active data-reactid=".m.1.0"></active><a class="toc-outline-theme-github" href="#sr-toc-1" data-reactid=".m.1.1"><span data-reactid=".m.1.1.0">图像处理工具之 torchvision.transforms</span></a></outline><outline class="toc-level-h3" data-reactid=".m.2" style="width: 155px;"><active data-reactid=".m.2.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-2" data-reactid=".m.2.1"><span data-reactid=".m.2.1.0">数据类型转换</span></a></outline><outline class="toc-level-h3" data-reactid=".m.3" style="width: 155px;"><active data-reactid=".m.3.0"></active><a class="toc-outline-theme-github" href="#sr-toc-3" data-reactid=".m.3.1"><span data-reactid=".m.3.1.0">对 PIL.Image 和 Tensor 进行变换</span></a></outline><outline class="toc-level-h4" data-reactid=".m.4" style="width: 145px;"><active data-reactid=".m.4.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-4" data-reactid=".m.4.1"><span data-reactid=".m.4.1.0">Resize</span></a></outline><outline class="toc-level-h4" data-reactid=".m.5" style="width: 145px;"><active data-reactid=".m.5.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-5" data-reactid=".m.5.1"><span data-reactid=".m.5.1.0">剪裁</span></a></outline><outline class="toc-level-h4" data-reactid=".m.6" style="width: 145px;"><active data-reactid=".m.6.0"></active><a class="toc-outline-theme-github" href="#sr-toc-6" data-reactid=".m.6.1"><span data-reactid=".m.6.1.0">翻转</span></a></outline><outline class="toc-level-h3" data-reactid=".m.7" style="width: 155px;"><active data-reactid=".m.7.0"></active><a class="toc-outline-theme-github" href="#sr-toc-7" data-reactid=".m.7.1"><span data-reactid=".m.7.1.0">只对 Tensor 进行变换</span></a></outline><outline class="toc-level-h4" data-reactid=".m.8" style="width: 145px;"><active data-reactid=".m.8.0"></active><a class="toc-outline-theme-github" href="#sr-toc-8" data-reactid=".m.8.1"><span data-reactid=".m.8.1.0">标准化</span></a></outline><outline class="toc-level-h3" data-reactid=".m.9" style="width: 155px;"><active data-reactid=".m.9.0"></active><a class="toc-outline-theme-github" href="#sr-toc-9" data-reactid=".m.9.1"><span data-reactid=".m.9.1.0">变换的组合</span></a></outline><outline class="toc-level-h2" data-reactid=".m.a" style="width: 165px;"><active data-reactid=".m.a.0"></active><a class="toc-outline-theme-github" href="#sr-toc-10" data-reactid=".m.a.1"><span data-reactid=".m.a.1.0">结合 datasets 使用</span></a></outline><outline class="toc-level-h2" data-reactid=".m.b" style="width: 165px;"><active data-reactid=".m.b.0"></active><a class="toc-outline-theme-github" href="#sr-toc-11" data-reactid=".m.b.1"><span data-reactid=".m.b.1.0">小结</span></a></outline><outline class="toc-level-h2" data-reactid=".m.c" style="width: 165px;"><active data-reactid=".m.c.0"></active><a class="toc-outline-theme-github" href="#sr-toc-12" data-reactid=".m.c.1"><span data-reactid=".m.c.1.0">每课一练</span></a></outline><outline class="toc-level-h2" data-reactid=".m.d" style="width: 165px;"><active data-reactid=".m.d.0"></active><a class="toc-outline-theme-github" href="#sr-toc-13" data-reactid=".m.d.1"><span data-reactid=".m.d.1.0">精选留言 (14)</span></a></outline></toc></toc-bg>
                            <sr-rd-footer>
                                <sr-rd-footer-group>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                </sr-rd-footer-group>
                                <sr-rd-footer-copywrite>
                                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://time.geekbang.org/column/article/429826" target="_blank">原文地址 </a></div>
                                </sr-rd-footer-copywrite>
                            </sr-rd-footer>
                        </sr-read>
                    </body>
                </html>