
                <html lang="en" class="simpread-font simpread-theme-root" style=''>
                    <head>
                        <meta charset="utf-8">
                        <meta http-equiv="content-type" content="text/html; charset=UTF-8;charset=utf-8">
                        <meta http-equiv="X-UA-Compatible" content="IE=Edge">
                        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
                        <meta name="author" content="Kenshin"/>
                        <meta name="description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展" />
                        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, 简悦, 简阅, read mode, reading mode, reader view, firefox, firefox addon, userscript, safari, opera, tampermonkey"/>
                        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:title" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <meta property="og:type" content="website">
                        <meta property="og:local" content="zh_CN"/>
                        <meta property="og:url" content="http://ksria.com/simpread"/>
                        <meta property="og:image" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:image:type" content="image/png"/>
                        <meta property="og:image:width" content="960"/>
                        <meta property="og:image:height" content="355"/>
                        <meta property="og:site_name" content="http://ksria.com/simpread"/>
                        <meta property="og:description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <style type="text/css">.simpread-font{font:300 16px/1.8 -apple-system,PingFang SC,Microsoft Yahei,Lantinghei SC,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#333;text-rendering:optimizelegibility;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased}.simpread-hidden{display:none}.simpread-read-root{display:-webkit-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;margin:0;top:-1000px;left:0;width:100%;z-index:2147483646;overflow-x:hidden;opacity:0;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}.simpread-read-root-show{top:0}.simpread-read-root-hide{top:1000px}sr-read{display:-webkit-flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-flow:column nowrap;flex-flow:column;margin:20px 20%;min-width:400px;min-height:400px;text-align:center}read-process{position:fixed;top:0;left:0;height:3px;width:100%;background-color:#64b5f6;-webkit-transition:width 2s;transition:width 2s;z-index:20000}sr-rd-content-error{display:block;position:relative;margin:0;margin-bottom:30px;padding:25px;background-color:rgba(0,0,0,.05)}sr-rd-footer{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column;font-size:14px}sr-rd-footer,sr-rd-footer-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}sr-rd-footer-group{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-rd-footer-line{width:100%;border-top:1px solid #e0e0e0}sr-rd-footer-text{min-width:150px}sr-rd-footer-copywrite{margin:10px 0 0;color:inherit}sr-rd-footer-copywrite abbr{-webkit-font-feature-settings:normal;font-feature-settings:normal;font-variant:normal;text-decoration:none}sr-rd-footer-copywrite .second{margin:10px 0}sr-rd-footer-copywrite .third a:hover{border:none!important}sr-rd-footer-copywrite .third a:first-child{margin-right:50px}sr-rd-footer-copywrite .sr-icon{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:33px;height:33px;opacity:.8;-webkit-transition:opacity .5s ease;transition:opacity .5s ease;cursor:pointer}sr-rd-footer-copywrite .sr-icon:hover{opacity:1}sr-rd-footer-copywrite a,sr-rd-footer-copywrite a:link,sr-rd-footer-copywrite a:visited{margin:0;padding:0;color:inherit;background-color:transparent;font-size:inherit!important;line-height:normal;text-decoration:none;vertical-align:baseline;vertical-align:initial;border:none!important;box-sizing:border-box}sr-rd-footer-copywrite a:focus,sr-rd-footer-copywrite a:hover,sr-rd-footer a:active{color:inherit;text-decoration:none;border-bottom:1px dotted!important}.simpread-blocks{text-decoration:none!important}.simpread-blocks *{margin:0}.simpread-blocks a{padding:0;text-decoration:none!important}.simpread-blocks img{margin:0;padding:0;border:0;background:transparent;box-shadow:none}.simpread-focus-root{display:block;position:fixed;top:0;left:0;right:0;bottom:0;background-color:hsla(0,0%,92%,.9);z-index:2147483645;opacity:0;-webkit-transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms;transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms}.simpread-focus-highlight{position:relative;box-shadow:0 0 0 20px #fff;background-color:#fff;overflow:visible;z-index:2147483646}.sr-controlbar-bg sr-rd-crlbar,.sr-controlbar-bg sr-rd-crlbar fab{z-index:2147483647}sr-rd-crlbar.controlbar{position:fixed;right:0;bottom:0;width:100px;height:100%;opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}sr-rd-crlbar.controlbar:hover{opacity:1}sr-rd-crlbar fap *{box-sizing:border-box}@media (max-height:620px){fab{zoom:.8}}@media (max-height:783px){dialog-gp dialog-content{max-height:580px}dialog-gp dialog-footer{border-top:1px solid #e0e0e0}}.simpread-highlight-selector{outline:3px dashed #1976d2!important;cursor:pointer!important}.simpread-highlight-controlbar,.simpread-highlight-selector{background-color:#fafafa!important;opacity:.8!important;-webkit-transition:opacity .5s ease!important;transition:opacity .5s ease!important}.simpread-highlight-controlbar{position:relative!important;border:3px dashed #1976d2!important}simpread-highlight,sr-snapshot-ctlbar{position:fixed;top:0;left:0;right:0;padding:15px;height:50px;background-color:rgba(50,50,50,.9);box-shadow:0 2px 5px rgba(0,0,0,.26);box-sizing:border-box;z-index:2147483640}simpread-highlight,sr-highlight-ctl,sr-snapshot-ctlbar{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-highlight-ctl{margin:0 5px;width:50px;height:20px;color:#fff;background-color:#1976d2;border-radius:4px;box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12);cursor:pointer}toc-bg{position:fixed;left:0;top:0;width:50px;height:200px;font-size:medium}toc-bg:hover{z-index:3}.toc-bg-hidden{opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}.toc-bg-hidden:hover{opacity:1;z-index:3}.toc-bg-hidden:hover toc{width:180px}toc *{all:unset}toc{position:fixed;left:0;top:100px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;padding:10px;width:0;max-width:200px;max-height:500px;overflow-x:hidden;overflow-y:hidden;cursor:pointer;border:1px solid hsla(0,0%,62%,.22);-webkit-transition:width .5s;transition:width .5s}toc:hover{overflow-y:auto}toc.mini:hover{width:200px!important}toc::-webkit-scrollbar{width:3px}toc::-webkit-scrollbar-thumb{border-radius:10px;background-color:hsla(36,2%,54%,.5)}toc outline{position:relative;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;padding:2px 0;min-height:21px;line-height:21px;text-align:left}toc outline a,toc outline a:active,toc outline a:focus,toc outline a:visited{display:block;width:100%;color:inherit;font-size:11px;text-decoration:none!important;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}toc outline a:hover{font-weight:700!important}toc outline a.toc-outline-theme-dark,toc outline a.toc-outline-theme-night{color:#fff!important}.toc-level-h1{padding-left:5px}.toc-level-h2{padding-left:15px}.toc-level-h3{padding-left:25px}.toc-level-h4{padding-left:35px}.toc-outline-active{border-left:2px solid #f44336}toc outline active{position:absolute;left:0;top:0;bottom:0;padding:0 0 0 3px;border-left:2px solid #e8e8e8}sr-kbd{background:-webkit-gradient(linear,0 0,0 100%,from(#fff785),to(#ffc542));border:1px solid #e3be23;-o-border-image:none;border-image:none;-o-border-image:initial;border-image:initial;position:absolute;left:0;padding:1px 3px 0;font-size:11px!important;font-weight:700;box-shadow:0 3px 7px 0 rgba(0,0,0,.3);overflow:hidden;border-radius:3px}.sr-kbd-a{position:relative}kbd-mapping{position:fixed;left:5px;bottom:5px;-ms-flex-flow:row;flex-flow:row;width:250px;height:500px;background-color:#fff;border:1px solid hsla(0,0%,62%,.22);box-shadow:0 2px 5px rgba(0,0,0,.26);border-radius:3px}kbd-mapping,kbd-maps{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}kbd-maps{margin:40px 0 20px;width:100%;overflow-x:auto}kbd-maps::-webkit-scrollbar-thumb{background-clip:padding-box;border-radius:10px;border:2px solid transparent;background-color:rgba(85,85,85,.55)}kbd-maps::-webkit-scrollbar{width:10px;-webkit-transition:width .7s cubic-bezier(.4,0,.2,1);transition:width .7s cubic-bezier(.4,0,.2,1)}kbd-mapping kbd-map-title{position:absolute;margin:5px 0;width:100%;font-size:14px;font-weight:700}kbd-maps-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}kbd-maps-title{margin:5px 0;padding-left:53px;font-size:12px;font-weight:700}kbd-map kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fafbfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}kbd-map kbd-name{display:inline-block;text-align:right;width:50px}kbd-map kbd-desc{padding-left:3px}sharecard-bg{position:fixed;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,.4);z-index:2147483647}sharecard{max-width:450px;background-color:#64b5f6}sharecard,sharecard-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-head{margin:25px;color:#fff;border-radius:10px;box-shadow:0 2px 6px 0 rgba(0,0,0,.2),0 25px 50px 0 rgba(0,0,0,.15)}sharecard-card{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-card,sharecard-top{display:-webkit-box;display:-ms-flexbox;display:flex}sharecard-top{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:65px;background-color:#fff;color:#878787;font-size:25px;font-weight:500;border-top-left-radius:10px;border-top-right-radius:10px}sharecard-top span.logos{display:block;width:48px;height:48px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAMAAABg3Am1AAABU1BMVEUAAAAnNJMnNZI3Q5onNJInNJMnNJInNJMnNJI8SJ0tOZY/S55EUKAoNJI6RpwoNJNIU6InNJInNJImNJI7SJwmNJJ2fLUiMJFKVaNCTJ9faK1HUaJOWKVSXaUnNJNYY6pye7cmM5JXYKhwebMjMI8mL4719fW9vb0oNZP/UlLz8/QqN5TAwMAnNJPv7+/Pz8/q6+/p6enNzc3Kysry8vMsOJXc3env7/LU1uXo29vR0dHOzs7ExMTwjo73bW37XV3Aj1TCYELl5u3n5+fW2Obn6O7f4OrZ2+g0QJkxPpgvO5bh4uvS1OTP0ePCwsJQW6ZLVqTs7fHd3d3V1dXqv79VX6lET6A1TIxXUIBSgHxWQnpelHf+WVnopkXqbC7j5Ozi4uLDw8NGUaFATJ9SgH3r6+vGyd7BxNva2trX19ejqM2gpczHx8dze7Zha67Z2dlTgH1aXQeSAAAAJnRSTlMA6ff+497Y8NL+/fv49P379sqab/BeOiX06tzVy8m/tKqpalA7G6oKj0EAAAJlSURBVEjHndNXWxpBFIDhcS2ICRLAkt4Dx4WhLk0E6R0MYoIISrWX5P9f5cwSIRC2+T1czMV5n2FnZwn2eWONUqCAv3H2Uf5Ra1hx4+0WEXtDQW0fCPYJ1EffEfIV4CSROAE4jsePoTFsNmTJF/IeIHF2lgCIn57GodlqDWXBK7IwBYatVlMWFAildPKX7I3m74Z9fsCiQChoimoFQAz04Ad2gH1n9fv9n9hgMNDr9euLWD6fLxQKxaLfb7dTSlahbFVdEPwIQtrAihZQgyKCtCagbQe3xh0QFMgy5MR11+ewYY5/qlZ7vT2xu93ULKjbFLpiUxnIIwjgKmVTLDUFXMrAi2NJWCRLIthTBo4xyOLKpwyqU6CuDCI41hFBCVdOhyLw4FgJ1skCAiyl9BSHbCorgo6VJXTru5hrVCQS8Yr5xLzX59YJSFpVFwD9U0BGC3hGdFpATgRupTGe9R9I1b1ePBvXKDyvq/O/44LT4/E4BUbSCAwj8Evq6HlnOBprx6JhJz8Gktc7xeaP9ndY+0coQvCccFBD4JW60UIY50ciLOAODAQRVOeCHm4Q3Xks6uRDY+CQ+AR4T2wMYh6+jMCIQOp78CFoj0H7EQgIuhI3dGaHCrwgADwCPjJvA372GRigCJg49FUdk3D87pq3zp4SA5zc1Zh9DxfwkpjgUg5Mv+lbeE3McC8Lpu7SA3wk2xzcqL2tN5DfIsQC8HB7UamUy6FQOpTO5QKBQDZbKnWSyUzGjdWCwaDA8+7Le4BNgm3qQGWchYh9s5hNq6wVbBlbwhZYOp3OYOA4zmgEypnM2zj8ByIdedKrH8vDAAAAAElFTkSuQmCC");zoom:.8}sharecard-content{padding:15px;max-height:500px;font-size:20px;text-align:justify;background-color:#2196f3;overflow-x:hidden;overflow-y:auto}sharecard-via{padding:10px;font-size:10px;background-color:#2196f3}sharecard-footer{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:100px;background-color:#fff;color:#878787;font-size:15px;font-weight:500;border-bottom-left-radius:10px;border-bottom-right-radius:10px}sharecard-footer,sharecard-footer div{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sharecard-footer span.qrcode{display:block;width:100px;height:100px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,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")}sharecard-control{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 19px;height:80px;background-color:#fff}simpread-snapshot{width:100%;height:100%;cursor:move;z-index:2147483645}simpread-snapshot,sr-mask{position:fixed;left:0;top:0}sr-mask{background-color:rgba(0,0,0,.1)}.simpread-feedback,.simpread-urlscheme{position:fixed;right:20px;bottom:20px;z-index:2147483646}simpread-feedback,simpread-urlscheme{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;padding:20px 20px 0;width:500px;color:rgba(51,51,51,.87);background-color:#fff;border-radius:3px;box-shadow:0 0 2px rgba(0,0,0,.12),0 2px 2px rgba(0,0,0,.26);overflow:hidden;-webkit-transform-origin:bottom;transform-origin:bottom;-webkit-transition:all .6s ease;transition:all .6s ease}simpread-feedback *,simpread-urlscheme *{font-size:12px!important;box-sizing:border-box}simpread-feedback.active,simpread-urlscheme.active{-webkit-animation-name:srFadeInUp;animation-name:srFadeInUp;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback.hide,simpread-urlscheme.hide{-webkit-animation-name:srFadeInDown;animation-name:srFadeInDown;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback sr-fb-label,simpread-urlscheme sr-urls-label{width:100%}simpread-feedback sr-fb-head,simpread-urlscheme sr-urls-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:5px;width:100%}simpread-feedback sr-fb-content,simpread-urlscheme sr-urls-content{margin-bottom:5px;width:100%}simpread-feedback sr-urls-footer,simpread-urlscheme sr-urls-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-fb-a,simpread-urlscheme sr-urls-a{color:#2163f7;cursor:pointer}simpread-feedback text-field-state,simpread-urlscheme text-field-state{border-top:none rgba(34,101,247,.8)!important;border-left:none rgba(34,101,247,.8)!important;border-right:none rgba(34,101,247,.8)!important;border-bottom:2px solid rgba(34,101,247,.8)!important}simpread-feedback switch,simpread-urlscheme switch{margin-top:0!important}@-webkit-keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@-webkit-keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}@keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}simpread-feedback sr-fb-head{font-weight:700}simpread-feedback sr-fb-content{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column}simpread-feedback sr-fb-content,simpread-feedback sr-fb-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}simpread-feedback sr-fb-footer{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-close{position:absolute;right:20px;cursor:pointer;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s;z-index:200}simpread-feedback sr-close:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin-top:10px}simpread-feedback sr-stars i{margin-right:10px;cursor:pointer}simpread-feedback sr-stars i svg{-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}simpread-feedback sr-stars i svg:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars i.active svg{-webkit-transform:rotate(0) scale(1);transform:rotate(0) scale(1)}simpread-feedback sr-emojis{display:block;height:100px;overflow:hidden}simpread-feedback sr-emoji{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:.3s;transition:.3s}simpread-feedback sr-emoji>svg{margin:15px 0;width:70px;height:70px;-ms-flex-negative:0;flex-shrink:0}simpread-feedback sr-stars-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin:10px 0 20px}</style>
                        <style type="text/css">.simpread-theme-root{font-size:62.5%!important}sr-rd-content,sr-rd-desc,sr-rd-title{width:100%}sr-rd-title{display:-webkit-box;margin:1em 0 .5em;overflow:hidden;text-overflow:ellipsis;text-rendering:optimizelegibility;-webkit-line-clamp:3;-webkit-box-orient:vertical}sr-rd-content{text-align:left;word-break:break-word}sr-rd-desc{text-align:justify;line-height:2.4;margin:0 0 1.2em;box-sizing:border-box}sr-rd-content{font-size:25.6px;font-size:1.6rem;line-height:1.6}sr-rd-content h1,sr-rd-content h1 *,sr-rd-content h2,sr-rd-content h2 *,sr-rd-content h3,sr-rd-content h3 *,sr-rd-content h4,sr-rd-content h4 *,sr-rd-content h5,sr-rd-content h5 *,sr-rd-content h6,sr-rd-content h6 *{word-break:break-all}sr-rd-content div,sr-rd-content p{display:block;float:inherit;line-height:1.6;font-size:25.6px;font-size:1.6rem}sr-rd-content div,sr-rd-content p,sr-rd-content pre,sr-rd-content sr-blockquote{margin:0 0 1.2em;word-break:break-word}sr-rd-content a{padding:0 5px;vertical-align:baseline;vertical-align:initial}sr-rd-content a,sr-rd-content a:link{color:inherit;font-size:inherit;font-weight:inherit;border:none}sr-rd-content a:hover{background:transparent}sr-rd-content img{margin:10px;padding:5px;max-width:100%;background:#fff;border:1px solid #bbb;box-shadow:1px 1px 3px #d4d4d4}sr-rd-content figcaption{text-align:center;font-size:14px}sr-rd-content sr-blockquote{display:block;position:relative;padding:15px 25px;text-align:left;line-height:inherit}sr-rd-content sr-blockquote:before{position:absolute}sr-rd-content sr-blockquote *{margin:0;font-size:inherit}sr-rd-content table{width:100%;margin:0 0 1.2em;word-break:keep-all;word-break:normal;overflow:auto;border:none}sr-rd-content table td,sr-rd-content table th{border:none}sr-rd-content ul{margin:0 0 1.2em;margin-left:1.3em;padding:0;list-style:disc}sr-rd-content ol{list-style:decimal;margin:0;padding:0}sr-rd-content ol li,sr-rd-content ul li{font-size:inherit;list-style:disc;margin:0 0 1.2em}sr-rd-content ol li{list-style:decimal;margin-left:1.3em}sr-rd-content ol li *,sr-rd-content ul li *{margin:0;text-align:left;text-align:initial}sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em}sr-rd-content li ul{list-style:circle}sr-rd-content pre{font-family:Consolas,Monaco,Andale Mono,Source Code Pro,Liberation Mono,Courier,monospace;display:block;padding:15px;line-height:1.5;word-break:break-all;word-wrap:break-word;white-space:pre;overflow:auto}sr-rd-content pre,sr-rd-content pre *,sr-rd-content pre div{font-size:17.6px;font-size:1.1rem}sr-rd-content li pre code,sr-rd-content p pre code,sr-rd-content pre{background-color:transparent;border:none}sr-rd-content pre code{margin:0;padding:0}sr-rd-content pre code,sr-rd-content pre code *{font-size:17.6px;font-size:1.1rem}sr-rd-content pre p{margin:0;padding:0;color:inherit;font-size:inherit;line-height:inherit}sr-rd-content li code,sr-rd-content p code{margin:0 4px;padding:2px 4px;font-size:17.6px;font-size:1.1rem}sr-rd-content mark{margin:0 5px;padding:2px;background:#fffdd1;border-bottom:1px solid #ffedce}.sr-rd-content-img{width:90%;height:auto}.sr-rd-content-img-load{width:48px;height:48px;margin:0;padding:0;border-style:none;border-width:0;background-repeat:no-repeat;background-image:url(data:image/gif;base64,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)}.sr-rd-content-center{text-align:center;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;-webkit-box-orient:vertical}.sr-rd-content-center-small{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.sr-rd-content-center-small img{margin:0;padding:0;border:0;box-shadow:none}img.simpread-img-broken{cursor:pointer}.sr-rd-content-nobeautify{margin:0;padding:0;border:0;box-shadow:0 0 0}sr-rd-mult{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin:0 0 16px;padding:16px 0 24px;width:100%;background-color:#fff;border-radius:4px;box-shadow:0 1px 2px 0 rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}sr-rd-mult:hover{-webkit-transition:all .45s 0ms;transition:all .45s 0ms;box-shadow:1px 1px 8px rgba(0,0,0,.16)}sr-rd-mult sr-rd-mult-content{padding:0 16px;overflow:auto}sr-rd-mult sr-rd-mult-avatar,sr-rd-mult sr-rd-mult-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sr-rd-mult sr-rd-mult-avatar{-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 15px}sr-rd-mult sr-rd-mult-avatar span{display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;max-width:75px;overflow:hidden;text-overflow:ellipsis;text-align:left;font-size:16px;font-size:1rem}sr-rd-mult sr-rd-mult-avatar img{margin-bottom:0;max-width:50px;max-height:50px;width:50px;height:50px;border-radius:50%}sr-rd-mult sr-rd-mult-content img{max-width:80%}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center{margin:0}sr-page{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;width:100%}</style>
                        <style type="text/css">sr-rd-theme-github{display:none}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{position:relative;margin-top:1em;margin-bottom:1pc;font-weight:700;line-height:1.4;text-align:left;color:#363636}sr-rd-content h1{padding-bottom:.3em;font-size:57.6px;font-size:3.6rem;line-height:1.2}sr-rd-content h2{padding-bottom:.3em;font-size:44.8px;font-size:2.8rem;line-height:1.225}sr-rd-content h3{font-size:38.4px;font-size:2.4rem;line-height:1.43}sr-rd-content h4{font-size:32px;font-size:2rem}sr-rd-content h5,sr-rd-content h6{font-size:25.6px;font-size:1.6rem}sr-rd-content h6{color:#777}sr-rd-content ol,sr-rd-content ul{list-style-type:disc;padding:0;padding-left:2em}sr-rd-content ol ol,sr-rd-content ul ol{list-style-type:lower-roman}sr-rd-content ol ol ol,sr-rd-content ol ul ol,sr-rd-content ul ol ol,sr-rd-content ul ul ol{list-style-type:lower-alpha}sr-rd-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all}sr-rd-content table th{font-weight:700}sr-rd-content table td,sr-rd-content table th{padding:6px 13px;border:1px solid #ddd}sr-rd-content table tr{background-color:#fff;border-top:1px solid #ccc}sr-rd-content table tr:nth-child(2n){background-color:#f8f8f8}sr-rd-content sr-blockquote{border-left:4px solid #ddd}.simpread-theme-root{background-color:#fff;color:#333}sr-rd-title{font-family:PT Sans,SF UI Display,\.PingFang SC,PingFang SC,Neue Haas Grotesk Text Pro,Arial Nova,Segoe UI,Microsoft YaHei,Microsoft JhengHei,Helvetica Neue,Source Han Sans SC,Noto Sans CJK SC,Source Han Sans CN,Noto Sans SC,Source Han Sans TC,Noto Sans CJK TC,Hiragino Sans GB,sans-serif;font-size:54.4px;font-size:3.4rem;font-weight:700;line-height:1.3}sr-rd-desc{position:relative;margin:0;margin-bottom:30px;padding:25px;padding-left:56px;font-size:28.8px;font-size:1.8rem;color:#777;background-color:rgba(0,0,0,.05);box-sizing:border-box}sr-rd-desc:before{content:"\201C";position:absolute;top:-28px;left:16px;font-size:80px;font-family:Arial;color:rgba(0,0,0,.15)}sr-rd-content,sr-rd-content *,sr-rd-content div,sr-rd-content p{color:#363636;font-weight:400;line-height:1.8}sr-rd-content b *,sr-rd-content strong,sr-rd-content strong * sr-rd-content b{-webkit-animation:none 0s ease 0s 1 normal none running;animation:none 0s ease 0s 1 normal none running;-webkit-backface-visibility:visible;backface-visibility:visible;background:transparent none repeat 0 0/auto auto padding-box border-box scroll;border:medium none currentColor;border-collapse:separate;-o-border-image:none;border-image:none;border-radius:0;border-spacing:0;bottom:auto;box-shadow:none;box-sizing:content-box;caption-side:top;clear:none;clip:auto;color:#000;-webkit-columns:auto;-moz-columns:auto;columns:auto;-webkit-column-count:auto;-moz-column-count:auto;column-count:auto;-webkit-column-fill:balance;-moz-column-fill:balance;column-fill:balance;-webkit-column-gap:normal;-moz-column-gap:normal;column-gap:normal;-webkit-column-rule:medium none currentColor;-moz-column-rule:medium none currentColor;column-rule:medium none currentColor;-webkit-column-span:1;-moz-column-span:1;column-span:1;-webkit-column-width:auto;-moz-column-width:auto;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;direction:ltr;display:inline;empty-cells:show;float:none;font-family:serif;font-size:medium;font-style:normal;font-variant:normal;font-weight:400;font-stretch:normal;line-height:normal;height:auto;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;left:auto;letter-spacing:normal;list-style:disc outside none;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;opacity:1;orphans:2;outline:medium none invert;overflow:visible;overflow-x:visible;overflow-y:visible;padding:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;-webkit-perspective:none;perspective:none;-webkit-perspective-origin:50% 50%;perspective-origin:50% 50%;position:static;right:auto;-moz-tab-size:8;-o-tab-size:8;tab-size:8;table-layout:auto;text-align:left;text-align-last:auto;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;top:auto;-webkit-transform:none;transform:none;-webkit-transform-origin:50% 50% 0;transform-origin:50% 50% 0;-webkit-transform-style:flat;transform-style:flat;-webkit-transition:none 0s ease 0s;transition:none 0s ease 0s;unicode-bidi:normal;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;word-spacing:normal;z-index:auto;all:initial}sr-rd-content a,sr-rd-content a:link{color:#4183c4;text-decoration:none}sr-rd-content a:active,sr-rd-content a:focus,sr-rd-content a:hover{color:#4183c4;text-decoration:underline}sr-rd-content pre{background-color:#f7f7f7;border-radius:3px}sr-rd-content li code,sr-rd-content p code{background-color:rgba(0,0,0,.04);border-radius:3px}.simpread-multi-root{background:#f8f9fa}</style>
                        <style type="text/css"></style>
                        <style type="text/css">@media (pointer:coarse){sr-read{margin:20px 5%!important;min-width:0!important;max-width:90%!important}sr-rd-title{margin-top:0;font-size:2.7rem}sr-rd-content sr-blockquote,sr-rd-desc{margin:10 0!important;padding:0 0 0 10px!important;width:90%;font-size:1.8rem;font-style:normal;line-height:1.7;text-align:justify}sr-rd-content{font-size:1.75rem;font-weight:300}sr-rd-content figure{margin:0;padding:0;text-align:center}sr-rd-content a,sr-rd-content a:link,sr-rd-content li code,sr-rd-content p code{font-size:inherit}sr-rd-footer{margin-top:20px}sr-blockquote,sr-blockquote *{margin:5px!important;padding:5px!important}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6,sr-rd-title{font-family:PingFang SC,Verdana,Helvetica Neue,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;font-weight:100;line-height:1.35}sr-rd-content-h1,sr-rd-content-h2,sr-rd-content-h3,sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}sr-rd-content-h1,sr-rd-content h1{font-size:1.8em}sr-rd-content-h2,sr-rd-content h2{font-size:1.6em}sr-rd-content-h3,sr-rd-content h3{font-size:1.4em}sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{font-size:1.2em}sr-rd-content-ul,sr-rd-content ul{margin-left:1.3em!important;list-style:disc}sr-rd-content-ol,sr-rd-content ol{list-style:decimal;margin-left:1.9em!important}sr-rd-content-ol ol,sr-rd-content-ol ul,sr-rd-content-ul ol,sr-rd-content-ul ul,sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em!important}sr-rd-content img{margin:0;padding:0;border:0;max-width:100%!important;height:auto;box-shadow:0 20px 20px -10px rgba(0,0,0,.1)}sr-rd-mult{min-width:0;background-color:#fff;box-shadow:0 1px 6px rgba(32,33,36,.28);border-radius:8px}sr-rd-mult sr-rd-mult-avatar div{margin:0}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center-small{margin:7px 0!important}sr-rd-mult sr-rd-mult-avatar span{display:block}sr-rd-mult sr-rd-mult-content{padding-left:0}@media only screen and (max-device-width:1024px){.simpread-theme-root,html.simpread-theme-root{font-size:80%!important}sr-rd-mult sr-rd-mult-avatar img{width:50px;height:50px;min-width:50px;min-height:50px}toc-bg toc{width:10px!important}toc-bg:hover toc{width:auto!important}}@media only screen and (max-device-width:414px){.simpread-theme-root,html.simpread-theme-root{font-size:70%!important}sr-rd-mult sr-rd-mult-avatar img{width:30px;height:30px;min-width:30px;min-height:30px}}@media only screen and (max-device-width:320px){.simpread-theme-root,html.simpread-theme-root{font-size:90%!important}sr-rd-content p{margin-bottom:.5em}}}</style>
                        <style type="text/css">undefinedsr-rd-content *, sr-rd-content p, sr-rd-content div {}sr-rd-content pre code, sr-rd-content pre code * {}sr-rd-desc {}sr-rd-content pre {}sr-rd-title {}</style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css">sr-rd-content *, sr-rd-content p, sr-rd-content div {
        font-size: 15px;
    }

    .annote-perview, .annote-perview * {
        color: rgb(85, 85, 85);
        font-weight: 400;
        line-height: 1.8;
    }</style>
                        
                        
                        <script>setTimeout(()=>{const e=location.hash.replace("#id=","");let t,a=!1;const n=t=>{for(let n of t){let t;if((t=e.length>6?n.getAttribute("data-id"):n.getAttribute("data-idx"))==e){n.scrollIntoView({behavior:"smooth",block:"start",inline:"nearest"}),a=!0;break}}};e&&(0==(t=document.getElementsByClassName("sr-unread-card")).length&&(t=document.getElementsByTagName("sr-annote")),n(t),a||n(t=document.getElementsByClassName("sr-annote")))},500);</script>
                        <script>document.addEventListener("DOMContentLoaded",function(){if("localhost"==location.hostname){const t=document.getElementsByTagName("img");for(let o of t){const t=o.src;t.startsWith("http")&&(o.src=location.origin+"/proxy?url="+t)}}},!1);</script>
                        <style>toc a {font-size: inherit!important;font-weight: 300!important;}</style><script>setTimeout(()=>{const max=document.getElementsByTagName('sr-annote-note-tip').length;for(let i=0;i<max;i++){const target=document.getElementsByTagName('sr-annote-note-tip')[i],value=target.dataset.value;value&&(target.innerText=value)}},1000);</script><title>简悦 | 29 | 归一化和标准化：各种特征如何综合才是最合理的？</title>
                    </head>
                    <body>
                        <sr-read style='font-family: "LXGW WenKai Screen";'>
                            <sr-rd-title>29 | 归一化和标准化：各种特征如何综合才是最合理的？</sr-rd-title>
                    <sr-rd-desc style="margin: 0;padding-top: 0;padding-bottom: 0;font-style: normal;font-size: 18px;">如果你只想当一个普通的程序员，那么数学对你来说，并不重要。但是如果你想做一个顶级程序员，梦想着改变世界，那么数学对你来说就很重要了。</sr-rd-desc>
                    <sr-rd-content><h1 id="sr-toc-0">29 | 归一化和标准化：各种特征如何综合才是最合理的？</h1><div><span>黄申</span> <span> 2019-02-20</span></div><div><div><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/1c/6b/1c1e66992ed3408ad9a2a9d39af1d66b.jpg"></div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADEAAAABCAYAAAB35kaxAAAAAXNSR0IArs4c6QAAAChJREFUGFdjfPfu3X8GKBAUFASz3r9/DxNiQBbDxcamn1yzSLEDZi8A2agny86FR+IAAAAASUVORK5CYII="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAABCAYAAAA8TpVcAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFCYtjkAcT9D8ti7hUOAAAAAElFTkSuQmCC"></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD0AAAABCAYAAABt2qY/AAAAAXNSR0IArs4c6QAAACdJREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULy2PQQK0YLewiZCQDhUS3LBhDf1QAAAABJRU5ErkJggg=="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAABCAYAAAA4u0VhAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULyAF6lD8tbqYWOAAAAAElFTkSuQmCC"></div></div></div><div><div><div></div></div><div><div><div><div><div><div>00:00</div></div><div></div></div></div><a href="javascript:;"> 1.0x <i><span></span></i></a></div><div><span>讲述：黄申</span><span>大小：11.28M</span><span> 时长：12:21</span></div></div><audio title="29 | 归一化和标准化：各种特征如何综合才是最合理的？" src="https://res001.geekbang.org//media/audio/a7/af/a7f5d5780fee0ca744917215d407f2af/ld/ld.m3u8"></audio></div><div><div><div><div data-slate-editor="true" data-key="9916" autocorrect="off" spellcheck="false" data-gramm="false"><div data-slate-type="paragraph" data-slate-object="block" data-key="9917"><span data-slate-object="text" data-key="9918"><span data-slate-leaf="true" data-offset-key="9918:0" data-first-offset="true"><span data-slate-string="true">你好，我是黄申，今天我来说说特征值的变换。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="9919"><span data-slate-object="text" data-key="9920"><span data-slate-leaf="true" data-offset-key="9920:0" data-first-offset="true"><span data-slate-string="true">上一节我讲了如何在众多的特征中，选取更有价值的特征，以提升模型的效率。特征选择是特征工程中的重要步骤，但不是全部。今天，我来说说特征工程中的另一块内容，数值变换。也就是说，我们可以使用统计中的数据分布，对连续型的数值特征进行转换，让多个特征的结合更有效。具体怎么理解呢？我下面就来详细讲一讲。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="9921" id="sr-toc-1"><span data-slate-object="text" data-key="9922"><span data-slate-leaf="true" data-offset-key="9922:0" data-first-offset="true"><span data-slate-string="true">为什么需要特征变换？</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="9923"><span data-slate-object="text" data-key="9924"><span data-slate-leaf="true" data-offset-key="9924:0" data-first-offset="true"><span data-slate-string="true">我们在很多机器学习算法中都会使用特征变换。我使用其中一种算法线性回归作为例子，来解释为什么要进行数值型特征的变换。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="9925"><span data-slate-object="text" data-key="9926"><span data-slate-leaf="true" data-offset-key="9926:0" data-first-offset="true"><span data-slate-string="true">我们之前介绍的监督式学习会根据某个样本的一系列特征，最后判定它应该属于哪个分类，并给出一个离散的分类标签。除此之外，还有一类监督式学习算法，会根据一系列的特征输入，给出连续的预测值。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="9927"><span data-slate-object="text" data-key="9928"><span data-slate-leaf="true" data-offset-key="9928:0" data-first-offset="true"><span data-slate-string="true">举个例子，房地产市场可以根据销售的历史数据，预估待售楼盘在未来的销售情况。如果只是预估卖得 “好” 还是 “不好”，那么这个粒度明显就太粗了。如果我们能做到预估这些房屋的售价，那么这个事情就变得有价值了。想要达成这个预测目的的过程，就需要最基本的</span></span></span><span data-slate-object="text" data-key="9929"><span data-slate-leaf="true" data-offset-key="9929:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">因变量连续回归分析</span></span></span></span><span data-slate-object="text" data-key="9930"><span data-slate-leaf="true" data-offset-key="9930:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="9931"><span data-slate-object="text" data-key="9932"><span data-slate-leaf="true" data-offset-key="9932:0" data-first-offset="true"><span data-slate-string="true">因变量连续回归的训练和预测，和分类的相应流程大体类似，不过具体采用的技术有一些不同。它采用的是研究一个或多个随机变量 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9933"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9935"><span data-slate-leaf="true" data-offset-key="9935:0" data-first-offset="true"><span data-slate-string="true">，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9936"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9938"><span data-slate-leaf="true" data-offset-key="9938:0" data-first-offset="true"><span data-slate-string="true">，…，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9939"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>i</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9941"><span data-slate-leaf="true" data-offset-key="9941:0" data-first-offset="true"><span data-slate-string="true"> 与另一些变量 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9942"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9944"><span data-slate-leaf="true" data-offset-key="9944:0" data-first-offset="true"><span data-slate-string="true">，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9945"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9947"><span data-slate-leaf="true" data-offset-key="9947:0" data-first-offset="true"><span data-slate-string="true">，…，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9948"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>k</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9950"><span data-slate-leaf="true" data-offset-key="9950:0" data-first-offset="true"><span data-slate-string="true"> 之间关系的统计方法，又称</span></span></span><span data-slate-object="text" data-key="9951"><span data-slate-leaf="true" data-offset-key="9951:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">多重回归分析</span></span></span></span><span data-slate-object="text" data-key="9952"><span data-slate-leaf="true" data-offset-key="9952:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="9953"><span data-slate-object="text" data-key="9954"><span data-slate-leaf="true" data-offset-key="9954:0" data-first-offset="true"><span data-slate-string="true">我们将 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9955"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9957"><span data-slate-leaf="true" data-offset-key="9957:0" data-first-offset="true"><span data-slate-string="true">，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9958"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9960"><span data-slate-leaf="true" data-offset-key="9960:0" data-first-offset="true"><span data-slate-string="true">，…，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9961"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>i</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9963"><span data-slate-leaf="true" data-offset-key="9963:0" data-first-offset="true"><span data-slate-string="true"> 称为因变量，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9964"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9966"><span data-slate-leaf="true" data-offset-key="9966:0" data-first-offset="true"><span data-slate-string="true">，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9967"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9969"><span data-slate-leaf="true" data-offset-key="9969:0" data-first-offset="true"><span data-slate-string="true">，…，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9970"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>k</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9972"><span data-slate-leaf="true" data-offset-key="9972:0" data-first-offset="true"><span data-slate-string="true"> 称为自变量。通常情况下，因变量的值可以分解为两部分，一部分是受自变量影响的，即表示为自变量相关的函数，其中函数形式已知，可能是线性也可能是非线性函数，但包含一些未知参数；另一部分是由于其他未被考虑的因素和随机性的影响，即随机误差。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="9973"><span data-slate-object="text" data-key="9974"><span data-slate-leaf="true" data-offset-key="9974:0" data-first-offset="true"><span data-slate-string="true">如果因变量和自变量为线性关系时，就称为</span></span></span><span data-slate-object="text" data-key="9975"><span data-slate-leaf="true" data-offset-key="9975:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">线性回归模型</span></span></span></span><span data-slate-object="text" data-key="9976"><span data-slate-leaf="true" data-offset-key="9976:0" data-first-offset="true"><span data-slate-string="true">；如果因变量和自变量为非线性关系，则称为</span></span></span><span data-slate-object="text" data-key="9977"><span data-slate-leaf="true" data-offset-key="9977:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">非线性回归分析模型</span></span></span></span><span data-slate-object="text" data-key="9978"><span data-slate-leaf="true" data-offset-key="9978:0" data-first-offset="true"><span data-slate-string="true">。今天我们要说的是回归中常用的多元线性回归，它的基本形式是：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="9979"><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/13/70/1350fcaad0a241fae13896bf85fa4d70.png?wh=526*64"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="9980"><span data-slate-object="text" data-key="9981"><span data-slate-leaf="true" data-offset-key="9981:0" data-first-offset="true"><span data-slate-string="true">其中，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9982"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9984"><span data-slate-leaf="true" data-offset-key="9984:0" data-first-offset="true"><span data-slate-string="true">，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9985"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9987"><span data-slate-leaf="true" data-offset-key="9987:0" data-first-offset="true"><span data-slate-string="true">，…，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9988"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>n</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9990"><span data-slate-leaf="true" data-offset-key="9990:0" data-first-offset="true"><span data-slate-string="true"> 是自变量，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9991"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>y</span></span></span></span></span></span><span data-slate-object="text" data-key="9993"><span data-slate-leaf="true" data-offset-key="9993:0" data-first-offset="true"><span data-slate-string="true"> 是因变量，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9994"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>ε</span></span></span></span></span></span><span data-slate-object="text" data-key="9996"><span data-slate-leaf="true" data-offset-key="9996:0" data-first-offset="true"><span data-slate-string="true"> 是随机误差，通常假定随机误差的均值为 0。而 w0 是截距，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="9997"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="9999"><span data-slate-leaf="true" data-offset-key="9999:0" data-first-offset="true"><span data-slate-string="true">，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10000"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="10002"><span data-slate-leaf="true" data-offset-key="10002:0" data-first-offset="true"><span data-slate-string="true">，…，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10003"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>n</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="10005"><span data-slate-leaf="true" data-offset-key="10005:0" data-first-offset="true"><span data-slate-string="true"> 是每个自变量的系数，表示每个自变量对最终结果的影响是正面还是负面，以及影响的程度。如果某个系数大于 0，表示对应的自变量对结果是正面影响，这个自变量越大，结果就越大。否则就是负面影响，这个自变量越大，结果就越小。而系数的绝对值表示了影响程度的大小，如果绝对值趋于 0，表示基本没有影响。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10006"><span data-slate-object="text" data-key="10007"><span data-slate-leaf="true" data-offset-key="10007:0" data-first-offset="true"><span data-slate-string="true">线性回归也是统计概率中常用的算法。不过它的实现通常会涉及很多线性代数的知识，所以下一个模块的时候，我会再详细介绍这个算法。这一节，你只需要知道线性回归所要达到的目标，以及怎么使用它就可以了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10008"><span data-slate-object="text" data-key="10009"><span data-slate-leaf="true" data-offset-key="10009:0" data-first-offset="true"><span data-slate-string="true">线性回归和其他算法相比，有很强的可解释性。我们可以通过回归后为每个自变量确定的系数，来判断哪些自变量对最终的因变量影响更大。可是，在正式开始线性回归分析之前，还有一个问题，那就是不同字段的数据没有可比性。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10010"><span data-slate-object="text" data-key="10011"><span data-slate-leaf="true" data-offset-key="10011:0" data-first-offset="true"><span data-slate-string="true">比如，房屋的面积和建造的年份，它们分别代表了不同的含义，也有不一样的取值范围。在线性回归中，如果直接将没有可比性的数字型特征线性加和，那么模型最终的解释肯定会受影响。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10012"><span data-slate-object="text" data-key="10013"><span data-slate-leaf="true" data-offset-key="10013:0" data-first-offset="true"><span data-slate-string="true">这里我用 Boston Housing 数据集对房价数据进行回归分析，这个数据来自 70 年代美国波士顿周边地区的房价，是用于机器学习的经典数据集，你可以在 Kaggle 的网站（</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="10014"><span data-slate-object="text" data-key="10015"><span data-slate-leaf="true" data-offset-key="10015:0" data-first-offset="true"><span data-slate-string="true">https://www.kaggle.com/c/boston-housing#description</span></span></span></a><span data-slate-object="text" data-key="10016"><span data-slate-leaf="true" data-offset-key="10016:0" data-first-offset="true"><span data-slate-string="true">）下载到它。这个数据一共有 14 个特征或者说自变量，而有 1 个目标值或者说因变量。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10017"><span data-slate-object="text" data-key="10018"><span data-slate-leaf="true" data-offset-key="10018:0" data-first-offset="true"><span data-slate-string="true">这里，我只使用其中的 train.csv。使用一小段 Python 代码，我们就能很快的得到一个线性回归的结果。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="10019"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="10020"><span data-slate-object="text" data-key="10021"><span data-slate-leaf="true" data-offset-key="10021:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="10022"><span data-slate-leaf="true" data-offset-key="10022:0" data-first-offset="true"><span data-slate-string="true"> pandas </span></span></span><span data-slate-object="text" data-key="10023"><span data-slate-leaf="true" data-offset-key="10023:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">as</span></span></span></span><span data-slate-object="text" data-key="10024"><span data-slate-leaf="true" data-offset-key="10024:0" data-first-offset="true"><span data-slate-string="true"> pd</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10025"><span data-slate-object="text" data-key="10026"><span data-slate-leaf="true" data-offset-key="10026:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="10027"><span data-slate-leaf="true" data-offset-key="10027:0" data-first-offset="true"><span data-slate-string="true"> sklearn.linear_model </span></span></span><span data-slate-object="text" data-key="10028"><span data-slate-leaf="true" data-offset-key="10028:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="10029"><span data-slate-leaf="true" data-offset-key="10029:0" data-first-offset="true"><span data-slate-string="true"> LinearRegression</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10030"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10031"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10032"><span data-slate-object="text" data-key="10033"><span data-slate-leaf="true" data-offset-key="10033:0" data-first-offset="true"><span data-slate-string="true">df = pd.read_csv(</span></span></span><span data-slate-object="text" data-key="10034"><span data-slate-leaf="true" data-offset-key="10034:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">"/Users/shenhuang/Data/boston-housing/train.csv"</span></span></span></span><span data-slate-object="text" data-key="10035"><span data-slate-leaf="true" data-offset-key="10035:0" data-first-offset="true"><span data-slate-string="true">)       </span></span></span><span data-slate-object="text" data-key="10036"><span data-slate-leaf="true" data-offset-key="10036:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#读取 Boston Housing 中的 train.csv</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10037"><span data-slate-object="text" data-key="10038"><span data-slate-leaf="true" data-offset-key="10038:0" data-first-offset="true"><span data-slate-string="true">df_features = df.drop([</span></span></span><span data-slate-object="text" data-key="10039"><span data-slate-leaf="true" data-offset-key="10039:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'medv'</span></span></span></span><span data-slate-object="text" data-key="10040"><span data-slate-leaf="true" data-offset-key="10040:0" data-first-offset="true"><span data-slate-string="true">], axis=</span></span></span><span data-slate-object="text" data-key="10041"><span data-slate-leaf="true" data-offset-key="10041:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="10042"><span data-slate-leaf="true" data-offset-key="10042:0" data-first-offset="true"><span data-slate-string="true">)     </span></span></span><span data-slate-object="text" data-key="10043"><span data-slate-leaf="true" data-offset-key="10043:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#Dataframe 中除了最后一列，其余列都是特征，或者说自变量</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10044"><span data-slate-object="text" data-key="10045"><span data-slate-leaf="true" data-offset-key="10045:0" data-first-offset="true"><span data-slate-string="true">df_targets = df[</span></span></span><span data-slate-object="text" data-key="10046"><span data-slate-leaf="true" data-offset-key="10046:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'medv'</span></span></span></span><span data-slate-object="text" data-key="10047"><span data-slate-leaf="true" data-offset-key="10047:0" data-first-offset="true"><span data-slate-string="true">]         </span></span></span><span data-slate-object="text" data-key="10048"><span data-slate-leaf="true" data-offset-key="10048:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#Dataframe 最后一列是目标变量，或者说因变量</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10049"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10050"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10051"><span data-slate-object="text" data-key="10052"><span data-slate-leaf="true" data-offset-key="10052:0" data-first-offset="true"><span data-slate-string="true">regression = LinearRegression().fit(df_features, df_targets)        </span></span></span><span data-slate-object="text" data-key="10053"><span data-slate-leaf="true" data-offset-key="10053:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#使用特征和目标数据，拟合线性回归模型</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10054"><span data-slate-object="text" data-key="10055"><span data-slate-leaf="true" data-offset-key="10055:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="10056"><span data-slate-leaf="true" data-offset-key="10056:0" data-first-offset="true"><span data-slate-string="true">(regression.score(df_features, df_targets))    </span></span></span><span data-slate-object="text" data-key="10057"><span data-slate-leaf="true" data-offset-key="10057:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#拟合程度的好坏</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10058"><span data-slate-object="text" data-key="10059"><span data-slate-leaf="true" data-offset-key="10059:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="10060"><span data-slate-leaf="true" data-offset-key="10060:0" data-first-offset="true"><span data-slate-string="true">(regression.coef_)            </span></span></span><span data-slate-object="text" data-key="10061"><span data-slate-leaf="true" data-offset-key="10061:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#各个特征所对应的系</span></span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10062"><span data-slate-object="text" data-key="10063"><span data-slate-leaf="true" data-offset-key="10063:0" data-first-offset="true"><span data-slate-string="true">使用上述代码之前，请确保你已经按照了 Python 中的 sklearn 和 pandas 包。运行这段代码，你可以得到如下的结果：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="10064"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="10065"><span data-slate-object="text" data-key="10066"><span data-slate-leaf="true" data-offset-key="10066:0" data-first-offset="true"><span data-slate-string="true">0.735578647853312</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10067"><span data-slate-object="text" data-key="10068"><span data-slate-leaf="true" data-offset-key="10068:0" data-first-offset="true"><span data-slate-string="true">[-4.54789253e-03 -5.17062363e-02  4.93344687e-02  5.34084254e-02</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10069"><span data-slate-object="text" data-key="10070"><span data-slate-leaf="true" data-offset-key="10070:0" data-first-offset="true"><span data-slate-string="true">  3.78011391e+00 -1.54106687e+01  3.87910457e+00 -9.51042267e-03</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10071"><span data-slate-object="text" data-key="10072"><span data-slate-leaf="true" data-offset-key="10072:0" data-first-offset="true"><span data-slate-string="true"> -1.60411361e+00  3.61780090e-01 -1.14966409e-02 -8.48538613e-01</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10073"><span data-slate-object="text" data-key="10074"><span data-slate-leaf="true" data-offset-key="10074:0" data-first-offset="true"><span data-slate-string="true">  1.18853164e-02 -6.01842329e-01]</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10075"><span data-slate-object="text" data-key="10076"><span data-slate-leaf="true" data-offset-key="10076:0" data-first-offset="true"><span data-slate-string="true">因为不是所有的数据都是可以使用线性回归模型来表示，所以我们需要使用 regression.score 函数，来看拟合的程度。如果完美拟合，这个函数就会输出 1；如果拟合效果很差，这个函数的输出可能就是一个负数。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10077"><span data-slate-object="text" data-key="10078"><span data-slate-leaf="true" data-offset-key="10078:0" data-first-offset="true"><span data-slate-string="true">这里 regression.score 函数的输出大约为 0.74，接近于 1.0。它表示这个数据集使用线性模型拟合的效果还是不错的。如果你还是不理解，不用担心，具体的我们会在线性代数部分详细解答。这里你可以简单的理解为，0.74 仅仅表示我们可以使用线性回归来解决 Boston Housing 这个问题。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10079"><span data-slate-object="text" data-key="10080"><span data-slate-leaf="true" data-offset-key="10080:0" data-first-offset="true"><span data-slate-string="true">这里，你更需要关注的是每个特征所对应的权重，因为它们可以帮助我们解释哪个特征对最终房价的中位值有更大的影响。参看 train.csv 中的数据，你会发现最主要的两个正相关特征是 nox（系数为 3.78011391e+00）和 age（系数为 3.87910457e+00）。其中 nox 表示空气污染浓度，age 表示老房子占比，也就是说空气污染越多、房龄越高，房价中位数越高，这好像不太合乎常理。我们再来看看最主要的负相关特征 rm（系数为 -1.54106687e+01），也就是房间数量。房间数量越多，房价中位数越低，越不合理。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10081"><span data-slate-object="text" data-key="10082"><span data-slate-leaf="true" data-offset-key="10082:0" data-first-offset="true"><span data-slate-string="true">造成这些现象最重要的原因是，不同类型的特征值没有转换到同一个可比较的范围内，所以线性回归后所得到的系数不具有可比性，因此我们无法直接对这些权重加以解释。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="10083" id="sr-toc-2"><span data-slate-object="text" data-key="10084"><span data-slate-leaf="true" data-offset-key="10084:0" data-first-offset="true"><span data-slate-string="true">两种常见的特征变换方法</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="10085"><span data-slate-object="text" data-key="10086"><span data-slate-leaf="true" data-offset-key="10086:0" data-first-offset="true"><span data-slate-string="true">该怎么解决这个问题呢？我们就需要对特征值进行转换。今天我介绍两种最常见的变换方法：归一化和标准化。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="10087" id="sr-toc-3"><span data-slate-object="text" data-key="10088"><span data-slate-leaf="true" data-offset-key="10088:0" data-first-offset="true"><span data-slate-string="true">归一化</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="10089"><span data-slate-object="text" data-key="10090"><span data-slate-leaf="true" data-offset-key="10090:0" data-first-offset="true"><span data-slate-string="true">我们先来看最常用的方法，</span></span></span><span data-slate-object="text" data-key="10091"><span data-slate-leaf="true" data-offset-key="10091:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">归一化</span></span></span></span><span data-slate-object="text" data-key="10092"><span data-slate-leaf="true" data-offset-key="10092:0" data-first-offset="true"><span data-slate-string="true">（Normalization）。它其实就是获取原始数据的最大值和最小值，然后把原始值线性变换到 [0,1] 之间，具体的变换函数为：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="10093"><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/0f/1e/0ff408fa0e7a547d2a874a76e39cc31e.png?wh=312*112"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10094"><span data-slate-object="text" data-key="10095"><span data-slate-leaf="true" data-offset-key="10095:0" data-first-offset="true"><span data-slate-string="true">其中 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10096"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>x</span></span></span></span></span></span><span data-slate-object="text" data-key="10098"><span data-slate-leaf="true" data-offset-key="10098:0" data-first-offset="true"><span data-slate-string="true"> 是原始值，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10099"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>m</span><span>a</span><span>x</span></span></span></span></span></span><span data-slate-object="text" data-key="10101"><span data-slate-leaf="true" data-offset-key="10101:0" data-first-offset="true"><span data-slate-string="true"> 为样本数据的最大值，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10102"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>m</span><span>i</span><span>n</span></span></span></span></span></span><span data-slate-object="text" data-key="10104"><span data-slate-leaf="true" data-offset-key="10104:0" data-first-offset="true"><span data-slate-string="true"> 为样本数据的最小值，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10105"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>x</span><span>’</span></span></span></span></span></span><span data-slate-object="text" data-key="10107"><span data-slate-leaf="true" data-offset-key="10107:0" data-first-offset="true"><span data-slate-string="true"> 是变换后的值。这种方法有个不足最大值与最小值非常容易受噪音数据的影响。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10108"><span data-slate-object="text" data-key="10109"><span data-slate-leaf="true" data-offset-key="10109:0" data-first-offset="true"><span data-slate-string="true">这里面需要注意的是，“归一化” 这个词在不同的领域的含义可能不同。这里我们特指基于最大和最小值的变换。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10110"><span data-slate-object="text" data-key="10111"><span data-slate-leaf="true" data-offset-key="10111:0" data-first-offset="true"><span data-slate-string="true">接下来，我们来看看在 Python 中如何实现归一化，以及归一化对回归后系数的影响。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="10112"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="10113"><span data-slate-object="text" data-key="10114"><span data-slate-leaf="true" data-offset-key="10114:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="10115"><span data-slate-leaf="true" data-offset-key="10115:0" data-first-offset="true"><span data-slate-string="true"> sklearn.preprocessing </span></span></span><span data-slate-object="text" data-key="10116"><span data-slate-leaf="true" data-offset-key="10116:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="10117"><span data-slate-leaf="true" data-offset-key="10117:0" data-first-offset="true"><span data-slate-string="true"> StandardScaler</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10118"><span data-slate-object="text" data-key="10119"><span data-slate-leaf="true" data-offset-key="10119:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="10120"><span data-slate-leaf="true" data-offset-key="10120:0" data-first-offset="true"><span data-slate-string="true"> sklearn.preprocessing </span></span></span><span data-slate-object="text" data-key="10121"><span data-slate-leaf="true" data-offset-key="10121:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="10122"><span data-slate-leaf="true" data-offset-key="10122:0" data-first-offset="true"><span data-slate-string="true"> MinMaxScaler</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10123"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10124"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10125"><span data-slate-object="text" data-key="10126"><span data-slate-leaf="true" data-offset-key="10126:0" data-first-offset="true"><span data-slate-string="true">minMaxScaler = MinMaxScaler()       </span></span></span><span data-slate-object="text" data-key="10127"><span data-slate-leaf="true" data-offset-key="10127:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#基于 min 和 max 值的归一化</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10128"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10129"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10130"><span data-slate-object="text" data-key="10131"><span data-slate-leaf="true" data-offset-key="10131:0" data-first-offset="true"><span data-slate-string="true">df_normalized = minMaxScaler.fit_transform(df)  </span></span></span><span data-slate-object="text" data-key="10132"><span data-slate-leaf="true" data-offset-key="10132:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#对原始数据进行归一化，包括特征值和目标变量</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10133"><span data-slate-object="text" data-key="10134"><span data-slate-leaf="true" data-offset-key="10134:0" data-first-offset="true"><span data-slate-string="true">df_features_normalized = df_normalized[:, </span></span></span><span data-slate-object="text" data-key="10135"><span data-slate-leaf="true" data-offset-key="10135:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="10136"><span data-slate-leaf="true" data-offset-key="10136:0" data-first-offset="true"><span data-slate-string="true">:-</span></span></span><span data-slate-object="text" data-key="10137"><span data-slate-leaf="true" data-offset-key="10137:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="10138"><span data-slate-leaf="true" data-offset-key="10138:0" data-first-offset="true"><span data-slate-string="true">] </span></span></span><span data-slate-object="text" data-key="10139"><span data-slate-leaf="true" data-offset-key="10139:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#获取归一化之后的特征值</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10140"><span data-slate-object="text" data-key="10141"><span data-slate-leaf="true" data-offset-key="10141:0" data-first-offset="true"><span data-slate-string="true">df_targets_normalized = df_normalized[:, -</span></span></span><span data-slate-object="text" data-key="10142"><span data-slate-leaf="true" data-offset-key="10142:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="10143"><span data-slate-leaf="true" data-offset-key="10143:0" data-first-offset="true"><span data-slate-string="true">]    </span></span></span><span data-slate-object="text" data-key="10144"><span data-slate-leaf="true" data-offset-key="10144:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#获取归一化之后的目标值</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10145"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10146"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10147"><span data-slate-object="text" data-key="10148"><span data-slate-leaf="true" data-offset-key="10148:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#再次进行线性回归</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10149"><span data-slate-object="text" data-key="10150"><span data-slate-leaf="true" data-offset-key="10150:0" data-first-offset="true"><span data-slate-string="true">regression_normalized = LinearRegression().fit(df_features_normalized, df_targets_normalized)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10151"><span data-slate-object="text" data-key="10152"><span data-slate-leaf="true" data-offset-key="10152:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="10153"><span data-slate-leaf="true" data-offset-key="10153:0" data-first-offset="true"><span data-slate-string="true">(regression_normalized.score(df_features_normalized, df_targets_normalized))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10154"><span data-slate-object="text" data-key="10155"><span data-slate-leaf="true" data-offset-key="10155:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="10156"><span data-slate-leaf="true" data-offset-key="10156:0" data-first-offset="true"><span data-slate-string="true">(regression_normalized.coef</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10157"><span data-slate-object="text" data-key="10158"><span data-slate-leaf="true" data-offset-key="10158:0" data-first-offset="true"><span data-slate-string="true">其中，df 还是之前加载的 dataframe。运行这段代码，你可以得到如下结果：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="10159"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="10160"><span data-slate-object="text" data-key="10161"><span data-slate-leaf="true" data-offset-key="10161:0" data-first-offset="true"><span data-slate-string="true">0.7355786478533118</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10162"><span data-slate-object="text" data-key="10163"><span data-slate-leaf="true" data-offset-key="10163:0" data-first-offset="true"><span data-slate-string="true">[-0.05103746 -0.08448544  0.10963215  0.03204506  0.08400253 -0.16643522</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10164"><span data-slate-object="text" data-key="10165"><span data-slate-leaf="true" data-offset-key="10165:0" data-first-offset="true"><span data-slate-string="true">  0.4451488  -0.01986622 -0.34152292  0.18490982 -0.13361651 -0.16216516</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10166"><span data-slate-object="text" data-key="10167"><span data-slate-leaf="true" data-offset-key="10167:0" data-first-offset="true"><span data-slate-string="true">  0.10390408 -0.48468369]</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10168"><span data-slate-object="text" data-key="10169"><span data-slate-leaf="true" data-offset-key="10169:0" data-first-offset="true"><span data-slate-string="true">你可以看到，表示拟合程度的分数没有变，但是每个特征对应的系数或者说权重，发生了比较大的变化。仔细观察一下，你会发现，这次最主要的正相关特征是 age（0.4451488）和 tax（0.18490982），也就是老房子占比和房产税的税率，其中至少房产税的税率是比较合理的，因为高房价的地区普遍税率也比较高。而最主要的负相关特征是 rad（-0.34152292）和 lstat（-0.48468369），rad 表示高速交通的便利程度，它的值越大表示离高速越远，房价中位数越低。而 lstat 表示低收入人群的占比，这个值越大房价中位数越低，这两点都是合理的。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="10170" id="sr-toc-4"><span data-slate-object="text" data-key="10171"><span data-slate-leaf="true" data-offset-key="10171:0" data-first-offset="true"><span data-slate-string="true">标准化</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="10172"><span data-slate-object="text" data-key="10173"><span data-slate-leaf="true" data-offset-key="10173:0" data-first-offset="true"><span data-slate-string="true">另一种常见的方法是基于正态分布的 z 分数（z-score）标准化（Standardization）。该方法假设数据呈现标准正态分布。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10174"><span data-slate-object="text" data-key="10175"><span data-slate-leaf="true" data-offset-key="10175:0" data-first-offset="true"><span data-slate-string="true">什么是标准正态分布呢？我们之前介绍过，正态分布是连续随机变量概率分布的一种。在现实生活中，大量随机现象的数据分布都近似于正态分布。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10176"><span data-slate-object="text" data-key="10177"><span data-slate-leaf="true" data-offset-key="10177:0" data-first-offset="true"><span data-slate-string="true">我这里再快速回顾一下这种分布的特点。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10178"><span data-slate-object="text" data-key="10179"><span data-slate-leaf="true" data-offset-key="10179:0" data-first-offset="true"><span data-slate-string="true">它以经过平均数的垂线为轴，左右对称展开，中间点最高，然后逐渐向两侧下降，分布曲线和 x 轴组成的面积为 1，表示不同事件出现的概率和为 1。平均数和标准差是正态分布的关键参数，它们会决定分布的具体形态。而标准正态分布是正态分布的一种，平均数为 0，标准差为 1。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10180"><span data-slate-object="text" data-key="10181"><span data-slate-leaf="true" data-offset-key="10181:0" data-first-offset="true"><span data-slate-string="true">理解了什么是标准正态分布，我们来看看 z 分数这个方法是如何运作的。实际上，z 分数标准化是利用标准正态分布的特点，计算一个给定分数距离平均数有多少个标准差。它的具体转换公式如下：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="10182"><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/af/01/af7092087da728c5c36819cf2ae68f01.png?wh=236*110"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10183"><span data-slate-object="text" data-key="10184"><span data-slate-leaf="true" data-offset-key="10184:0" data-first-offset="true"><span data-slate-string="true">其中 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10185"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>x</span></span></span></span></span></span><span data-slate-object="text" data-key="10187"><span data-slate-leaf="true" data-offset-key="10187:0" data-first-offset="true"><span data-slate-string="true"> 为原始值，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10188"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>u</span></span></span></span></span></span><span data-slate-object="text" data-key="10190"><span data-slate-leaf="true" data-offset-key="10190:0" data-first-offset="true"><span data-slate-string="true"> 为均值，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10191"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>σ</span></span></span></span></span></span><span data-slate-object="text" data-key="10193"><span data-slate-leaf="true" data-offset-key="10193:0" data-first-offset="true"><span data-slate-string="true"> 为标准差，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="10194"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>x</span><span>’</span></span></span></span></span></span><span data-slate-object="text" data-key="10196"><span data-slate-leaf="true" data-offset-key="10196:0" data-first-offset="true"><span data-slate-string="true"> 是变换后的值。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10197"><span data-slate-object="text" data-key="10198"><span data-slate-leaf="true" data-offset-key="10198:0" data-first-offset="true"><span data-slate-string="true">经过 z 分数的转换，高于平均数的分数会得到一个正的标准分，而低于平均数的分数会得到一个负的标准分数。更重要的是，转换后的数据是符合标准正态分布的。你通过理论或者具体的数值来推导一下，就会发现转换后的数据均值为 0，标准差为 1。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10199"><span data-slate-object="text" data-key="10200"><span data-slate-leaf="true" data-offset-key="10200:0" data-first-offset="true"><span data-slate-string="true">和归一化相比，z 分数这样的标准化不容易受到噪音数据的影响，并且保留了各维特征对目标函数的影响权重。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10201"><span data-slate-object="text" data-key="10202"><span data-slate-leaf="true" data-offset-key="10202:0" data-first-offset="true"><span data-slate-string="true">下面我们来看看，在 Python 中如何实现标准化，以及标准化对回归后系数的影响。</span></span></span></div><div data-code-language="bash" data-slate-type="pre" data-slate-object="block" data-key="10203"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="10204"><span data-slate-object="text" data-key="10205"><span data-slate-leaf="true" data-offset-key="10205:0" data-first-offset="true"><span data-slate-string="true">standardScaler = StandardScaler()    </span></span></span><span data-slate-object="text" data-key="10206"><span data-slate-leaf="true" data-offset-key="10206:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#基于 Z 分数的标准化</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10207"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10208"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10209"><span data-slate-object="text" data-key="10210"><span data-slate-leaf="true" data-offset-key="10210:0" data-first-offset="true"><span data-slate-string="true">standardScaler.fit(</span></span></span><span data-slate-object="text" data-key="10211"><span data-slate-leaf="true" data-offset-key="10211:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">df</span></span></span></span><span data-slate-object="text" data-key="10212"><span data-slate-leaf="true" data-offset-key="10212:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10213"><span data-slate-object="text" data-key="10214"><span data-slate-leaf="true" data-offset-key="10214:0" data-first-offset="true"><span data-slate-string="true">df_standardized = standardScaler.transform(</span></span></span><span data-slate-object="text" data-key="10215"><span data-slate-leaf="true" data-offset-key="10215:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">df</span></span></span></span><span data-slate-object="text" data-key="10216"><span data-slate-leaf="true" data-offset-key="10216:0" data-first-offset="true"><span data-slate-string="true">)  </span></span></span><span data-slate-object="text" data-key="10217"><span data-slate-leaf="true" data-offset-key="10217:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#对原始数据进行标准化，包括特征值和目标变量</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10218"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10219"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10220"><span data-slate-object="text" data-key="10221"><span data-slate-leaf="true" data-offset-key="10221:0" data-first-offset="true"><span data-slate-string="true">df_features_standardized = df_standardized[:, 0:-1] </span></span></span><span data-slate-object="text" data-key="10222"><span data-slate-leaf="true" data-offset-key="10222:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#获取标准化之后的特征值</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10223"><span data-slate-object="text" data-key="10224"><span data-slate-leaf="true" data-offset-key="10224:0" data-first-offset="true"><span data-slate-string="true">df_targets_standardized = df_standardized[:, -1]    </span></span></span><span data-slate-object="text" data-key="10225"><span data-slate-leaf="true" data-offset-key="10225:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#获取标准化之后的特征值</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10226"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10227"></div><div data-slate-type="code-line" data-slate-object="block" data-key="10228"><span data-slate-object="text" data-key="10229"><span data-slate-leaf="true" data-offset-key="10229:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">#再次进行线性回归</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10230"><span data-slate-object="text" data-key="10231"><span data-slate-leaf="true" data-offset-key="10231:0" data-first-offset="true"><span data-slate-string="true">regression_standardized = LinearRegression().fit(df_features_standardized, df_targets_standardized)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10232"><span data-slate-object="text" data-key="10233"><span data-slate-leaf="true" data-offset-key="10233:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="10234"><span data-slate-leaf="true" data-offset-key="10234:0" data-first-offset="true"><span data-slate-string="true">(regression_standardized.score(df_features_standardized, df_targets_standardized))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10235"><span data-slate-object="text" data-key="10236"><span data-slate-leaf="true" data-offset-key="10236:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="10237"><span data-slate-leaf="true" data-offset-key="10237:0" data-first-offset="true"><span data-slate-string="true">(regression_standardized.coef</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10238"><span data-slate-object="text" data-key="10239"><span data-slate-leaf="true" data-offset-key="10239:0" data-first-offset="true"><span data-slate-string="true">其中，df 还是之前加载的 dataframe。运行这段代码，这次你得到的结果如下：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="10240"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="10241"><span data-slate-object="text" data-key="10242"><span data-slate-leaf="true" data-offset-key="10242:0" data-first-offset="true"><span data-slate-string="true">0.7355786478533118</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10243"><span data-slate-object="text" data-key="10244"><span data-slate-leaf="true" data-offset-key="10244:0" data-first-offset="true"><span data-slate-string="true">[-0.07330367 -0.04144107  0.12194378  0.04074345  0.09805446 -0.19311408</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10245"><span data-slate-object="text" data-key="10246"><span data-slate-leaf="true" data-offset-key="10246:0" data-first-offset="true"><span data-slate-string="true">  0.29767387 -0.02916672 -0.34642803  0.34477088 -0.21410757 -0.19904179</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="10247"><span data-slate-object="text" data-key="10248"><span data-slate-leaf="true" data-offset-key="10248:0" data-first-offset="true"><span data-slate-string="true">  0.11218058 -0.46369483]</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10249"><span data-slate-object="text" data-key="10250"><span data-slate-leaf="true" data-offset-key="10250:0" data-first-offset="true"><span data-slate-string="true">表示拟合程度的分数仍然没有变。再次对比不同特征所对应的系数，你会发现这次最主要的正相关特征还是 age（0.29767387）和 tax（0.34477088），但是相比之前，明显房产税的税率占了更高的权重，更加合理。而最主要的负相关特征还是 rad（-0.34152292）和 lstat（-0.48468369），这两点都是合理的。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="10251" id="sr-toc-5"><span data-slate-object="text" data-key="10252"><span data-slate-leaf="true" data-offset-key="10252:0" data-first-offset="true"><span data-slate-string="true">总结</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="10253"><span data-slate-object="text" data-key="10254"><span data-slate-leaf="true" data-offset-key="10254:0" data-first-offset="true"><span data-slate-string="true">今天我介绍了在机器学习领域里，如何使用统计里的数据分布来进行特征值的转换。这里，我帮你梳理了几个要点，便于你的记忆。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10255"><span data-slate-object="text" data-key="10256"><span data-slate-leaf="true" data-offset-key="10256:0" data-first-offset="true"><span data-slate-string="true">第一点，为什么有时候需要转换特征值？因为不同类型的特征取值范围不同，分布也不同，相互之间没有可比性。因此在线性回归中，通过这些原始值分析得到的权重，并不能代表每个特征实际的重要性。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10257"><span data-slate-object="text" data-key="10258"><span data-slate-leaf="true" data-offset-key="10258:0" data-first-offset="true"><span data-slate-string="true">第二点，如何使用归一化进行特征值转换？这里的归一化是指使用特征取值范围中的最大值和最小值，把原始值转换为 0 到 1 之间的值。这样处理的好处在于简单易行，便于理解。不过，它的缺点也很明显，由于只考虑了最大最小值，因此很容易受到异常数据点的干扰。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10259"><span data-slate-object="text" data-key="10260"><span data-slate-leaf="true" data-offset-key="10260:0" data-first-offset="true"><span data-slate-string="true">第三点，如何使用标准化进行转换？经过标准化处理之后，每种特征的取值都会变成一个标准正态分布，以 0 为均值，1 为标准差。和归一化相比，标准化使用了数据是正态分布的假设，不容易受到过大或过小值的干扰。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10261"><span data-slate-object="text" data-key="10262"><span data-slate-leaf="true" data-offset-key="10262:0" data-first-offset="true"><span data-slate-string="true">掌握了上面几个点，你就能很好的理解这一节的内容了。在实际的数据分析或者是统计建模的项目中，对于数值型的特征要保持敏感，看到它们的时候都要考虑一下，是不是需要进行特征值的转换？这样就能避免由于多种特征的不同分布而产生的误导性结论。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="10263" id="sr-toc-6"><span data-slate-object="text" data-key="10264"><span data-slate-leaf="true" data-offset-key="10264:0" data-first-offset="true"><span data-slate-string="true">思考题</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="10265"><span data-slate-object="text" data-key="10266"><span data-slate-leaf="true" data-offset-key="10266:0" data-first-offset="true"><span data-slate-string="true">今天我们使用了三种方式处理 Boston Housing 的数据，并训练出三种线性回归的模型。请尝试使用这些模型的 predict 方法，对 test.csv 数据进行预测，看看每种模型的预测效果。（提示：如果你在 train.csv 上使用了某种特征值的转换，那么相应的 test.csv 数据也需要经过同样的处理。）</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="10267"><span data-slate-object="text" data-key="10268"><span data-slate-leaf="true" data-offset-key="10268:0" data-first-offset="true"><span data-slate-string="true">欢迎留言和我分享，也欢迎你在留言区写下今天的学习笔记。你也可以把今天的内容分享给你的好友，和他一起在实战中重新理解数学。</span></span></span></div></div></div></div><div><div></div><div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><textarea placeholder="将学到的知识总结成笔记，方便日后快速查找及复习"></textarea></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div><div><div>确认放弃笔记？</div><div>放弃后所记笔记将不保留。</div></div><div><div>新功能上线，你的历史笔记已初始化为私密笔记，是否一键批量公开？</div><div>批量公开的笔记不会为你同步至部落</div></div><div></div></div><div><div><div>公开</div><div>同步至部落</div></div><div>取消</div><div>完成</div></div><div><span>0/2000</span></div></div><div><div><span>划线</span></div><div></div><div></div><div></div><div><span>笔记</span></div><div></div><div><span>复制</span></div></div></div><div><div><div><span></span></div><p><a href="javascript:void(0);">给文章提建议</a></p></div></div><div><span>©</span> 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 </div></div><div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div><div>Geek__653581f21177</div></div><div><textarea placeholder="由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。" rows="16"></textarea></div><div><div>Ctrl + Enter 发表</div><div>0/2000 字符</div><div>提交留言</div></div></div><div><h2 id="sr-toc-7">精选留言 (15)</h2><ul><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/69/4d/81c44f45.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>拉欧</span></div></div><div>标准化和归一化未必能提高模型的准确度，但是会提高可解释性，是不是这个意思？</div><div><p>作者回复：是的。因为有些机器学习算法内部会根据输入数据自动调整值，所以对于算法效果而言，标准化和归一化不一定是必须的。</p></div><div><div>2019-02-20</div><div><div><i></i></div><div><i></i><span>8</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/14/6a/8e/7b6ea886.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Joe</span></div></div><div>之前做机器学习算法的时候，采用特征缩放处理特征，能有效提高学习收敛效果。公式：x’=(x-x_mean)/(xmax-xmin)。不是单纯的归一，也保留了不同类别 x 之间的权重。</div><div><p>作者回复：也是一种可尝试的方法👍</p></div><div><div>2019-02-27</div><div><div><i></i><span>2</span></div><div><i></i><span>6</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/15/ad/50/3cb818e8.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 灰太狼</span></div></div><div>归一化和标准化在使用中分别适合什么场景呢</div><div><p>作者回复：这是个好问题，最主要是和数据分布有关系。如果数据采样的分布接近于正态分布，建议 Z 分数标准化，让不同的数据组可比，否则建议归一化，将不同的数据统一到同样的区间便于处理</p></div><div><div>2020-03-28</div><div><div><i></i><span>2</span></div><div><i></i><span>5</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 骑行的掌柜 J</span></div></div><div>黄老师终于讲了理论后 上代码了 😂不过黄老师 我还了解到有种叫 PCA 降维的方法 他跟标准化之间有联系吗？是需要先标准话再 PCA 降维？谢谢</div><div><p>作者回复：巧了，我们之后会讲解 PCA。虽然标准化不是 PCA 的必备预处理，但是通常我们还是会先进行标准化，再进行 PCA 降维。这是为了让不同的特征具有可比性，同时加速算法求解时的收敛速度</p></div><div><div>2020-06-11</div><div><div><i></i></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div></div><div><div><div><span>Paul Shan</span></div></div><div>归一化是按比例变化到［0,1］的区间里。
标准化是假设分布为正态分布，将数据变换为均值为 0, 方差为 1 的正态分布。
将所有数据按照统一尺度处理，有利于比较模型中的权重大小。
</div><div><div>2019-09-13</div><div><div><i></i><span></span></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/10/57/1adfd4f7.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 追梦</span></div></div><div>老师，这如果是部署到线上模型，这些预处理应该怎么变化呢</div><div><p>作者回复：好问题，我想你说的线上模型是指某些机器学习中的 predict 或者叫 scoring，就是指针对新的数据，进行分类或者回归的预测。可以根据线下训练数据的平均值和标准差来，如果新的数据远远超出了训练数据的均值和标准，可以看做 outlier，根据合理的数值限制其范围</p></div><div><div>2020-01-12</div><div><div><i></i></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/1d/32/005c7ba4.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 大熊</span></div></div><div>以前用归一的时候都没考虑噪音的影响，今天 get 到了，nice</div><div><p>作者回复：很高兴对你有帮助</p></div><div><div>2019-05-23</div><div><div><i></i></div><div><i></i><span>2</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>qinggeouye</span></div></div><div>思考题：

"""
测试数据集 test.csv
测试数据的目标值 submission_example.csv
"""df_test = pd.read_csv ("/Users/qinggeouye/Desktop/GeekTime/MathematicProgrammer/29_featureTrans/test.csv")
expected_test = pd.read_csv ("/Users/qinggeouye/Desktop/GeekTime/MathematicProgrammer/29_featureTrans"
                            "/submission_example.csv")['medv']

# 归一化 预测结果
minMaxScaler_test = MinMaxScaler ()
df_test_normalized = minMaxScaler_test.fit_transform (df_test.astype (dtype=float))
df_test_features_normalized = df_test_normalized [:, :]
predicted_normalized = regression_normalized.predict (df_test_features_normalized)
print ("归一化预测结果与实际值的均方根误差：% s" % np.sqrt (np.mean ((predicted_normalized - expected_test) ** 2)))

# 标准化 预测结果
standardScaler_test = StandardScaler ()
standardScaler_test.fit (df_test.astype (dtype=float))
df_test_standardized = standardScaler_test.transform (df_test.astype (dtype=float))
df_test_features_standardized = df_test_standardized [:, :]
predicted_standardized = regression_standardized.predict (df_test_features_standardized)
print ("标准化预测结果与实际值的均方根误差：% s" % np.sqrt (np.mean ((predicted_standardized - expected_test) ** 2)))

# 预测结果，两种特征转换预测结果相差无几，但与实际值相差较大
归一化预测结果与实际值的均方根误差：22.40003520184502
标准化预测结果与实际值的均方根误差：22.785218713879576</div><div><p>作者回复：确实，线性拟合程度不太好</p></div><div><div>2019-03-10</div><div><div><i></i></div><div><i></i><span>2</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKia6PQiaF3N9KvzbloVvicY9fQz3vs8C82ykfOTgNeMqpRAJxCICQgpIMFFTtQ2DrHej7IeFlcG9tdQ/132"></div></div><div><div><div><span>Geek_a50e46</span></div></div><div>老师，那是不是标准化就没有缺点了？是不是可以完全用标准化替代归一化了呢？</div><div><p>作者回复：也不一定，如果样本量小的时候，可能归一化就够了。</p></div><div><div>2020-02-07</div><div><div><i></i></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/15/5b/6f/113e24e6.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 阿信</span></div></div><div>特征值处理，能加快收敛速度、降噪、标准化输出，这种好理解。但为什么会影响分析结果</div><div><p>作者回复：这要看具体的处理方式和模型，从处理方式的角度来看，有的时候特征工程可能会去掉一些不重要的特征，就会提升或者降低准确度。从模型的角度而言，有些比如线性回归模型需要量化地解释每个特征的重要程度，那么需要把不同特征统一化</p></div><div><div>2019-07-05</div><div><div><i></i></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/21/d9/5d/dd0eb7e0.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 春节十二响</span></div></div><div>我对特征标准化的理解是，初始的特征数据不是纯数字，而是有量纲的，直接进行运算会搞出类似 5m+6kg 这样逻辑意义错误的操作。所以特征标准化实现的第一个效果是去量纲，把特征变成纯数字；第二个效果就是把不同特征投射到相近的数量级上，好做比较，也避免一些算法需要计算距离时，某个特征占得权重过大</div><div><p>作者回复：对，量纲的转换也是必要的</p></div><div><div>2021-04-07</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>A 君</span></div></div><div>权重原来指的是衡量自变量对因变量产生正影响还负影响，权重的绝对值越大，表示该自变量对因变量的影响也越大。</div><div><p>作者回复：是的</p></div><div><div>2020-07-26</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>郭俊杰</span></div></div><div>讲的很明白，thanks.</div><div><p>作者回复：很高兴对你有价值</p></div><div><div>2020-05-21</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>罗耀龙 @坐忘</span><span><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/20/30/2012c563b22c76a7f1f97c22c3ddf830.png"></div></span></div></div><div>茶艺师学编程

今天讲了特征变换的其中两种操作，一个是归一法，另一个是 Z 分数标准化（基于正态分布）。

我试着这么理解：

前者是把自变量变换在 [0,1] 之间，后者则是把自变量按照距离 “平均值” 的远近重新 “排位”。

我感觉归一法就好像是对一张图片进行拉伸操作。而 Z 分数标准化，就是在放着铁粉的纸下面放上一根磁铁，轻轻抖动几下，看着原本散落的铁粉在磁铁的作用下排列出 “磁感线” 的图案。

…… 不知道我这么理解对不对，请大家指点。</div><div><div>2020-04-21</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/13/5c/02/e7af1750.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>teddytyy</span></div></div><div>为啥 age 一直是正相关特征？</div><div><p>作者回复：这点确实有点反常识，可能有些潜在的因素并未被发掘。例如老房子都在好地段，而新房多数建在偏远的地方，所以有时数据本身并不能说明一切，还需要人的理解，进行合理的解释</p></div><div><div>2019-12-19</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li></ul><div> 收起评论<span></span></div></div></sr-rd-content>
                            <toc-bg><toc style="width: initial;overflow: auto!important;"class="simpread-font simpread-theme-root" data-reactid=".2k"><outline class="toc-level-h1" data-reactid=".2k.0" style="width: 175px;"><active data-reactid=".2k.0.0" ></active><a class="toc-outline-theme-github" href="#sr-toc-0" data-reactid=".2k.0.1"><span data-reactid=".2k.0.1.0">29 | 归一化和标准化：各种特征如何综合才是最合理的？</span></a></outline><outline class="toc-level-h2" data-reactid=".2k.1" style="width: 165px;"><active data-reactid=".2k.1.0"></active><a class="toc-outline-theme-github" href="#sr-toc-1" data-reactid=".2k.1.1"><span data-reactid=".2k.1.1.0">为什么需要特征变换？</span></a></outline><outline class="toc-level-h2" data-reactid=".2k.2" style="width: 165px;"><active data-reactid=".2k.2.0"></active><a class="toc-outline-theme-github" href="#sr-toc-2" data-reactid=".2k.2.1"><span data-reactid=".2k.2.1.0">两种常见的特征变换方法</span></a></outline><outline class="toc-level-h3" data-reactid=".2k.3" style="width: 155px;"><active data-reactid=".2k.3.0"></active><a class="toc-outline-theme-github" href="#sr-toc-3" data-reactid=".2k.3.1"><span data-reactid=".2k.3.1.0">归一化</span></a></outline><outline class="toc-level-h3" data-reactid=".2k.4" style="width: 155px;"><active data-reactid=".2k.4.0"></active><a class="toc-outline-theme-github" href="#sr-toc-4" data-reactid=".2k.4.1"><span data-reactid=".2k.4.1.0">标准化</span></a></outline><outline class="toc-level-h2" data-reactid=".2k.5" style="width: 165px;"><active data-reactid=".2k.5.0"></active><a class="toc-outline-theme-github" href="#sr-toc-5" data-reactid=".2k.5.1"><span data-reactid=".2k.5.1.0">总结</span></a></outline><outline class="toc-level-h2" data-reactid=".2k.6" style="width: 165px;"><active data-reactid=".2k.6.0"></active><a class="toc-outline-theme-github" href="#sr-toc-6" data-reactid=".2k.6.1"><span data-reactid=".2k.6.1.0">思考题</span></a></outline><outline class="toc-level-h2" data-reactid=".2k.7" style="width: 165px;"><active data-reactid=".2k.7.0"></active><a class="toc-outline-theme-github" href="#sr-toc-7" data-reactid=".2k.7.1"><span data-reactid=".2k.7.1.0">精选留言 (15)</span></a></outline></toc></toc-bg>
                            <sr-rd-footer>
                                <sr-rd-footer-group>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                </sr-rd-footer-group>
                                <sr-rd-footer-copywrite>
                                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://time.geekbang.org/column/article/82661" target="_blank">原文地址 </a></div>
                                </sr-rd-footer-copywrite>
                            </sr-rd-footer>
                        </sr-read>
                    </body>
                </html>