
                <html lang="en" class="simpread-font simpread-theme-root" style=''>
                    <head>
                        <meta charset="utf-8">
                        <meta http-equiv="content-type" content="text/html; charset=UTF-8;charset=utf-8">
                        <meta http-equiv="X-UA-Compatible" content="IE=Edge">
                        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
                        <meta name="author" content="Kenshin"/>
                        <meta name="description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展" />
                        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, 简悦, 简阅, read mode, reading mode, reader view, firefox, firefox addon, userscript, safari, opera, tampermonkey"/>
                        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:title" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <meta property="og:type" content="website">
                        <meta property="og:local" content="zh_CN"/>
                        <meta property="og:url" content="http://ksria.com/simpread"/>
                        <meta property="og:image" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:image:type" content="image/png"/>
                        <meta property="og:image:width" content="960"/>
                        <meta property="og:image:height" content="355"/>
                        <meta property="og:site_name" content="http://ksria.com/simpread"/>
                        <meta property="og:description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <style type="text/css">.simpread-font{font:300 16px/1.8 -apple-system,PingFang SC,Microsoft Yahei,Lantinghei SC,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#333;text-rendering:optimizelegibility;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased}.simpread-hidden{display:none}.simpread-read-root{display:-webkit-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;margin:0;top:-1000px;left:0;width:100%;z-index:2147483646;overflow-x:hidden;opacity:0;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}.simpread-read-root-show{top:0}.simpread-read-root-hide{top:1000px}sr-read{display:-webkit-flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-flow:column nowrap;flex-flow:column;margin:20px 20%;min-width:400px;min-height:400px;text-align:center}read-process{position:fixed;top:0;left:0;height:3px;width:100%;background-color:#64b5f6;-webkit-transition:width 2s;transition:width 2s;z-index:20000}sr-rd-content-error{display:block;position:relative;margin:0;margin-bottom:30px;padding:25px;background-color:rgba(0,0,0,.05)}sr-rd-footer{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column;font-size:14px}sr-rd-footer,sr-rd-footer-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}sr-rd-footer-group{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-rd-footer-line{width:100%;border-top:1px solid #e0e0e0}sr-rd-footer-text{min-width:150px}sr-rd-footer-copywrite{margin:10px 0 0;color:inherit}sr-rd-footer-copywrite abbr{-webkit-font-feature-settings:normal;font-feature-settings:normal;font-variant:normal;text-decoration:none}sr-rd-footer-copywrite .second{margin:10px 0}sr-rd-footer-copywrite .third a:hover{border:none!important}sr-rd-footer-copywrite .third a:first-child{margin-right:50px}sr-rd-footer-copywrite .sr-icon{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:33px;height:33px;opacity:.8;-webkit-transition:opacity .5s ease;transition:opacity .5s ease;cursor:pointer}sr-rd-footer-copywrite .sr-icon:hover{opacity:1}sr-rd-footer-copywrite a,sr-rd-footer-copywrite a:link,sr-rd-footer-copywrite a:visited{margin:0;padding:0;color:inherit;background-color:transparent;font-size:inherit!important;line-height:normal;text-decoration:none;vertical-align:baseline;vertical-align:initial;border:none!important;box-sizing:border-box}sr-rd-footer-copywrite a:focus,sr-rd-footer-copywrite a:hover,sr-rd-footer a:active{color:inherit;text-decoration:none;border-bottom:1px dotted!important}.simpread-blocks{text-decoration:none!important}.simpread-blocks *{margin:0}.simpread-blocks a{padding:0;text-decoration:none!important}.simpread-blocks img{margin:0;padding:0;border:0;background:transparent;box-shadow:none}.simpread-focus-root{display:block;position:fixed;top:0;left:0;right:0;bottom:0;background-color:hsla(0,0%,92%,.9);z-index:2147483645;opacity:0;-webkit-transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms;transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms}.simpread-focus-highlight{position:relative;box-shadow:0 0 0 20px #fff;background-color:#fff;overflow:visible;z-index:2147483646}.sr-controlbar-bg sr-rd-crlbar,.sr-controlbar-bg sr-rd-crlbar fab{z-index:2147483647}sr-rd-crlbar.controlbar{position:fixed;right:0;bottom:0;width:100px;height:100%;opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}sr-rd-crlbar.controlbar:hover{opacity:1}sr-rd-crlbar fap *{box-sizing:border-box}@media (max-height:620px){fab{zoom:.8}}@media (max-height:783px){dialog-gp dialog-content{max-height:580px}dialog-gp dialog-footer{border-top:1px solid #e0e0e0}}.simpread-highlight-selector{outline:3px dashed #1976d2!important;cursor:pointer!important}.simpread-highlight-controlbar,.simpread-highlight-selector{background-color:#fafafa!important;opacity:.8!important;-webkit-transition:opacity .5s ease!important;transition:opacity .5s ease!important}.simpread-highlight-controlbar{position:relative!important;border:3px dashed #1976d2!important}simpread-highlight,sr-snapshot-ctlbar{position:fixed;top:0;left:0;right:0;padding:15px;height:50px;background-color:rgba(50,50,50,.9);box-shadow:0 2px 5px rgba(0,0,0,.26);box-sizing:border-box;z-index:2147483640}simpread-highlight,sr-highlight-ctl,sr-snapshot-ctlbar{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-highlight-ctl{margin:0 5px;width:50px;height:20px;color:#fff;background-color:#1976d2;border-radius:4px;box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12);cursor:pointer}toc-bg{position:fixed;left:0;top:0;width:50px;height:200px;font-size:medium}toc-bg:hover{z-index:3}.toc-bg-hidden{opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}.toc-bg-hidden:hover{opacity:1;z-index:3}.toc-bg-hidden:hover toc{width:180px}toc *{all:unset}toc{position:fixed;left:0;top:100px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;padding:10px;width:0;max-width:200px;max-height:500px;overflow-x:hidden;overflow-y:hidden;cursor:pointer;border:1px solid hsla(0,0%,62%,.22);-webkit-transition:width .5s;transition:width .5s}toc:hover{overflow-y:auto}toc.mini:hover{width:200px!important}toc::-webkit-scrollbar{width:3px}toc::-webkit-scrollbar-thumb{border-radius:10px;background-color:hsla(36,2%,54%,.5)}toc outline{position:relative;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;padding:2px 0;min-height:21px;line-height:21px;text-align:left}toc outline a,toc outline a:active,toc outline a:focus,toc outline a:visited{display:block;width:100%;color:inherit;font-size:11px;text-decoration:none!important;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}toc outline a:hover{font-weight:700!important}toc outline a.toc-outline-theme-dark,toc outline a.toc-outline-theme-night{color:#fff!important}.toc-level-h1{padding-left:5px}.toc-level-h2{padding-left:15px}.toc-level-h3{padding-left:25px}.toc-level-h4{padding-left:35px}.toc-outline-active{border-left:2px solid #f44336}toc outline active{position:absolute;left:0;top:0;bottom:0;padding:0 0 0 3px;border-left:2px solid #e8e8e8}sr-kbd{background:-webkit-gradient(linear,0 0,0 100%,from(#fff785),to(#ffc542));border:1px solid #e3be23;-o-border-image:none;border-image:none;-o-border-image:initial;border-image:initial;position:absolute;left:0;padding:1px 3px 0;font-size:11px!important;font-weight:700;box-shadow:0 3px 7px 0 rgba(0,0,0,.3);overflow:hidden;border-radius:3px}.sr-kbd-a{position:relative}kbd-mapping{position:fixed;left:5px;bottom:5px;-ms-flex-flow:row;flex-flow:row;width:250px;height:500px;background-color:#fff;border:1px solid hsla(0,0%,62%,.22);box-shadow:0 2px 5px rgba(0,0,0,.26);border-radius:3px}kbd-mapping,kbd-maps{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}kbd-maps{margin:40px 0 20px;width:100%;overflow-x:auto}kbd-maps::-webkit-scrollbar-thumb{background-clip:padding-box;border-radius:10px;border:2px solid transparent;background-color:rgba(85,85,85,.55)}kbd-maps::-webkit-scrollbar{width:10px;-webkit-transition:width .7s cubic-bezier(.4,0,.2,1);transition:width .7s cubic-bezier(.4,0,.2,1)}kbd-mapping kbd-map-title{position:absolute;margin:5px 0;width:100%;font-size:14px;font-weight:700}kbd-maps-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}kbd-maps-title{margin:5px 0;padding-left:53px;font-size:12px;font-weight:700}kbd-map kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fafbfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}kbd-map kbd-name{display:inline-block;text-align:right;width:50px}kbd-map kbd-desc{padding-left:3px}sharecard-bg{position:fixed;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,.4);z-index:2147483647}sharecard{max-width:450px;background-color:#64b5f6}sharecard,sharecard-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-head{margin:25px;color:#fff;border-radius:10px;box-shadow:0 2px 6px 0 rgba(0,0,0,.2),0 25px 50px 0 rgba(0,0,0,.15)}sharecard-card{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-card,sharecard-top{display:-webkit-box;display:-ms-flexbox;display:flex}sharecard-top{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:65px;background-color:#fff;color:#878787;font-size:25px;font-weight:500;border-top-left-radius:10px;border-top-right-radius:10px}sharecard-top span.logos{display:block;width:48px;height:48px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAMAAABg3Am1AAABU1BMVEUAAAAnNJMnNZI3Q5onNJInNJMnNJInNJMnNJI8SJ0tOZY/S55EUKAoNJI6RpwoNJNIU6InNJInNJImNJI7SJwmNJJ2fLUiMJFKVaNCTJ9faK1HUaJOWKVSXaUnNJNYY6pye7cmM5JXYKhwebMjMI8mL4719fW9vb0oNZP/UlLz8/QqN5TAwMAnNJPv7+/Pz8/q6+/p6enNzc3Kysry8vMsOJXc3env7/LU1uXo29vR0dHOzs7ExMTwjo73bW37XV3Aj1TCYELl5u3n5+fW2Obn6O7f4OrZ2+g0QJkxPpgvO5bh4uvS1OTP0ePCwsJQW6ZLVqTs7fHd3d3V1dXqv79VX6lET6A1TIxXUIBSgHxWQnpelHf+WVnopkXqbC7j5Ozi4uLDw8NGUaFATJ9SgH3r6+vGyd7BxNva2trX19ejqM2gpczHx8dze7Zha67Z2dlTgH1aXQeSAAAAJnRSTlMA6ff+497Y8NL+/fv49P379sqab/BeOiX06tzVy8m/tKqpalA7G6oKj0EAAAJlSURBVEjHndNXWxpBFIDhcS2ICRLAkt4Dx4WhLk0E6R0MYoIISrWX5P9f5cwSIRC2+T1czMV5n2FnZwn2eWONUqCAv3H2Uf5Ra1hx4+0WEXtDQW0fCPYJ1EffEfIV4CSROAE4jsePoTFsNmTJF/IeIHF2lgCIn57GodlqDWXBK7IwBYatVlMWFAildPKX7I3m74Z9fsCiQChoimoFQAz04Ad2gH1n9fv9n9hgMNDr9euLWD6fLxQKxaLfb7dTSlahbFVdEPwIQtrAihZQgyKCtCagbQe3xh0QFMgy5MR11+ewYY5/qlZ7vT2xu93ULKjbFLpiUxnIIwjgKmVTLDUFXMrAi2NJWCRLIthTBo4xyOLKpwyqU6CuDCI41hFBCVdOhyLw4FgJ1skCAiyl9BSHbCorgo6VJXTru5hrVCQS8Yr5xLzX59YJSFpVFwD9U0BGC3hGdFpATgRupTGe9R9I1b1ePBvXKDyvq/O/44LT4/E4BUbSCAwj8Evq6HlnOBprx6JhJz8Gktc7xeaP9ndY+0coQvCccFBD4JW60UIY50ciLOAODAQRVOeCHm4Q3Xks6uRDY+CQ+AR4T2wMYh6+jMCIQOp78CFoj0H7EQgIuhI3dGaHCrwgADwCPjJvA372GRigCJg49FUdk3D87pq3zp4SA5zc1Zh9DxfwkpjgUg5Mv+lbeE3McC8Lpu7SA3wk2xzcqL2tN5DfIsQC8HB7UamUy6FQOpTO5QKBQDZbKnWSyUzGjdWCwaDA8+7Le4BNgm3qQGWchYh9s5hNq6wVbBlbwhZYOp3OYOA4zmgEypnM2zj8ByIdedKrH8vDAAAAAElFTkSuQmCC");zoom:.8}sharecard-content{padding:15px;max-height:500px;font-size:20px;text-align:justify;background-color:#2196f3;overflow-x:hidden;overflow-y:auto}sharecard-via{padding:10px;font-size:10px;background-color:#2196f3}sharecard-footer{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:100px;background-color:#fff;color:#878787;font-size:15px;font-weight:500;border-bottom-left-radius:10px;border-bottom-right-radius:10px}sharecard-footer,sharecard-footer div{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sharecard-footer span.qrcode{display:block;width:100px;height:100px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,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")}sharecard-control{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 19px;height:80px;background-color:#fff}simpread-snapshot{width:100%;height:100%;cursor:move;z-index:2147483645}simpread-snapshot,sr-mask{position:fixed;left:0;top:0}sr-mask{background-color:rgba(0,0,0,.1)}.simpread-feedback,.simpread-urlscheme{position:fixed;right:20px;bottom:20px;z-index:2147483646}simpread-feedback,simpread-urlscheme{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;padding:20px 20px 0;width:500px;color:rgba(51,51,51,.87);background-color:#fff;border-radius:3px;box-shadow:0 0 2px rgba(0,0,0,.12),0 2px 2px rgba(0,0,0,.26);overflow:hidden;-webkit-transform-origin:bottom;transform-origin:bottom;-webkit-transition:all .6s ease;transition:all .6s ease}simpread-feedback *,simpread-urlscheme *{font-size:12px!important;box-sizing:border-box}simpread-feedback.active,simpread-urlscheme.active{-webkit-animation-name:srFadeInUp;animation-name:srFadeInUp;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback.hide,simpread-urlscheme.hide{-webkit-animation-name:srFadeInDown;animation-name:srFadeInDown;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback sr-fb-label,simpread-urlscheme sr-urls-label{width:100%}simpread-feedback sr-fb-head,simpread-urlscheme sr-urls-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:5px;width:100%}simpread-feedback sr-fb-content,simpread-urlscheme sr-urls-content{margin-bottom:5px;width:100%}simpread-feedback sr-urls-footer,simpread-urlscheme sr-urls-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-fb-a,simpread-urlscheme sr-urls-a{color:#2163f7;cursor:pointer}simpread-feedback text-field-state,simpread-urlscheme text-field-state{border-top:none rgba(34,101,247,.8)!important;border-left:none rgba(34,101,247,.8)!important;border-right:none rgba(34,101,247,.8)!important;border-bottom:2px solid rgba(34,101,247,.8)!important}simpread-feedback switch,simpread-urlscheme switch{margin-top:0!important}@-webkit-keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@-webkit-keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}@keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}simpread-feedback sr-fb-head{font-weight:700}simpread-feedback sr-fb-content{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column}simpread-feedback sr-fb-content,simpread-feedback sr-fb-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}simpread-feedback sr-fb-footer{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-close{position:absolute;right:20px;cursor:pointer;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s;z-index:200}simpread-feedback sr-close:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin-top:10px}simpread-feedback sr-stars i{margin-right:10px;cursor:pointer}simpread-feedback sr-stars i svg{-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}simpread-feedback sr-stars i svg:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars i.active svg{-webkit-transform:rotate(0) scale(1);transform:rotate(0) scale(1)}simpread-feedback sr-emojis{display:block;height:100px;overflow:hidden}simpread-feedback sr-emoji{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:.3s;transition:.3s}simpread-feedback sr-emoji>svg{margin:15px 0;width:70px;height:70px;-ms-flex-negative:0;flex-shrink:0}simpread-feedback sr-stars-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin:10px 0 20px}</style>
                        <style type="text/css">.simpread-theme-root{font-size:62.5%!important}sr-rd-content,sr-rd-desc,sr-rd-title{width:100%}sr-rd-title{display:-webkit-box;margin:1em 0 .5em;overflow:hidden;text-overflow:ellipsis;text-rendering:optimizelegibility;-webkit-line-clamp:3;-webkit-box-orient:vertical}sr-rd-content{text-align:left;word-break:break-word}sr-rd-desc{text-align:justify;line-height:2.4;margin:0 0 1.2em;box-sizing:border-box}sr-rd-content{font-size:25.6px;font-size:1.6rem;line-height:1.6}sr-rd-content h1,sr-rd-content h1 *,sr-rd-content h2,sr-rd-content h2 *,sr-rd-content h3,sr-rd-content h3 *,sr-rd-content h4,sr-rd-content h4 *,sr-rd-content h5,sr-rd-content h5 *,sr-rd-content h6,sr-rd-content h6 *{word-break:break-all}sr-rd-content div,sr-rd-content p{display:block;float:inherit;line-height:1.6;font-size:25.6px;font-size:1.6rem}sr-rd-content div,sr-rd-content p,sr-rd-content pre,sr-rd-content sr-blockquote{margin:0 0 1.2em;word-break:break-word}sr-rd-content a{padding:0 5px;vertical-align:baseline;vertical-align:initial}sr-rd-content a,sr-rd-content a:link{color:inherit;font-size:inherit;font-weight:inherit;border:none}sr-rd-content a:hover{background:transparent}sr-rd-content img{margin:10px;padding:5px;max-width:100%;background:#fff;border:1px solid #bbb;box-shadow:1px 1px 3px #d4d4d4}sr-rd-content figcaption{text-align:center;font-size:14px}sr-rd-content sr-blockquote{display:block;position:relative;padding:15px 25px;text-align:left;line-height:inherit}sr-rd-content sr-blockquote:before{position:absolute}sr-rd-content sr-blockquote *{margin:0;font-size:inherit}sr-rd-content table{width:100%;margin:0 0 1.2em;word-break:keep-all;word-break:normal;overflow:auto;border:none}sr-rd-content table td,sr-rd-content table th{border:none}sr-rd-content ul{margin:0 0 1.2em;margin-left:1.3em;padding:0;list-style:disc}sr-rd-content ol{list-style:decimal;margin:0;padding:0}sr-rd-content ol li,sr-rd-content ul li{font-size:inherit;list-style:disc;margin:0 0 1.2em}sr-rd-content ol li{list-style:decimal;margin-left:1.3em}sr-rd-content ol li *,sr-rd-content ul li *{margin:0;text-align:left;text-align:initial}sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em}sr-rd-content li ul{list-style:circle}sr-rd-content pre{font-family:Consolas,Monaco,Andale Mono,Source Code Pro,Liberation Mono,Courier,monospace;display:block;padding:15px;line-height:1.5;word-break:break-all;word-wrap:break-word;white-space:pre;overflow:auto}sr-rd-content pre,sr-rd-content pre *,sr-rd-content pre div{font-size:17.6px;font-size:1.1rem}sr-rd-content li pre code,sr-rd-content p pre code,sr-rd-content pre{background-color:transparent;border:none}sr-rd-content pre code{margin:0;padding:0}sr-rd-content pre code,sr-rd-content pre code *{font-size:17.6px;font-size:1.1rem}sr-rd-content pre p{margin:0;padding:0;color:inherit;font-size:inherit;line-height:inherit}sr-rd-content li code,sr-rd-content p code{margin:0 4px;padding:2px 4px;font-size:17.6px;font-size:1.1rem}sr-rd-content mark{margin:0 5px;padding:2px;background:#fffdd1;border-bottom:1px solid #ffedce}.sr-rd-content-img{width:90%;height:auto}.sr-rd-content-img-load{width:48px;height:48px;margin:0;padding:0;border-style:none;border-width:0;background-repeat:no-repeat;background-image:url(data:image/gif;base64,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)}.sr-rd-content-center{text-align:center;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;-webkit-box-orient:vertical}.sr-rd-content-center-small{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.sr-rd-content-center-small img{margin:0;padding:0;border:0;box-shadow:none}img.simpread-img-broken{cursor:pointer}.sr-rd-content-nobeautify{margin:0;padding:0;border:0;box-shadow:0 0 0}sr-rd-mult{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin:0 0 16px;padding:16px 0 24px;width:100%;background-color:#fff;border-radius:4px;box-shadow:0 1px 2px 0 rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}sr-rd-mult:hover{-webkit-transition:all .45s 0ms;transition:all .45s 0ms;box-shadow:1px 1px 8px rgba(0,0,0,.16)}sr-rd-mult sr-rd-mult-content{padding:0 16px;overflow:auto}sr-rd-mult sr-rd-mult-avatar,sr-rd-mult sr-rd-mult-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sr-rd-mult sr-rd-mult-avatar{-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 15px}sr-rd-mult sr-rd-mult-avatar span{display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;max-width:75px;overflow:hidden;text-overflow:ellipsis;text-align:left;font-size:16px;font-size:1rem}sr-rd-mult sr-rd-mult-avatar img{margin-bottom:0;max-width:50px;max-height:50px;width:50px;height:50px;border-radius:50%}sr-rd-mult sr-rd-mult-content img{max-width:80%}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center{margin:0}sr-page{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;width:100%}</style>
                        <style type="text/css">sr-rd-theme-github{display:none}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{position:relative;margin-top:1em;margin-bottom:1pc;font-weight:700;line-height:1.4;text-align:left;color:#363636}sr-rd-content h1{padding-bottom:.3em;font-size:57.6px;font-size:3.6rem;line-height:1.2}sr-rd-content h2{padding-bottom:.3em;font-size:44.8px;font-size:2.8rem;line-height:1.225}sr-rd-content h3{font-size:38.4px;font-size:2.4rem;line-height:1.43}sr-rd-content h4{font-size:32px;font-size:2rem}sr-rd-content h5,sr-rd-content h6{font-size:25.6px;font-size:1.6rem}sr-rd-content h6{color:#777}sr-rd-content ol,sr-rd-content ul{list-style-type:disc;padding:0;padding-left:2em}sr-rd-content ol ol,sr-rd-content ul ol{list-style-type:lower-roman}sr-rd-content ol ol ol,sr-rd-content ol ul ol,sr-rd-content ul ol ol,sr-rd-content ul ul ol{list-style-type:lower-alpha}sr-rd-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all}sr-rd-content table th{font-weight:700}sr-rd-content table td,sr-rd-content table th{padding:6px 13px;border:1px solid #ddd}sr-rd-content table tr{background-color:#fff;border-top:1px solid #ccc}sr-rd-content table tr:nth-child(2n){background-color:#f8f8f8}sr-rd-content sr-blockquote{border-left:4px solid #ddd}.simpread-theme-root{background-color:#fff;color:#333}sr-rd-title{font-family:PT Sans,SF UI Display,\.PingFang SC,PingFang SC,Neue Haas Grotesk Text Pro,Arial Nova,Segoe UI,Microsoft YaHei,Microsoft JhengHei,Helvetica Neue,Source Han Sans SC,Noto Sans CJK SC,Source Han Sans CN,Noto Sans SC,Source Han Sans TC,Noto Sans CJK TC,Hiragino Sans GB,sans-serif;font-size:54.4px;font-size:3.4rem;font-weight:700;line-height:1.3}sr-rd-desc{position:relative;margin:0;margin-bottom:30px;padding:25px;padding-left:56px;font-size:28.8px;font-size:1.8rem;color:#777;background-color:rgba(0,0,0,.05);box-sizing:border-box}sr-rd-desc:before{content:"\201C";position:absolute;top:-28px;left:16px;font-size:80px;font-family:Arial;color:rgba(0,0,0,.15)}sr-rd-content,sr-rd-content *,sr-rd-content div,sr-rd-content p{color:#363636;font-weight:400;line-height:1.8}sr-rd-content b *,sr-rd-content strong,sr-rd-content strong * sr-rd-content b{-webkit-animation:none 0s ease 0s 1 normal none running;animation:none 0s ease 0s 1 normal none running;-webkit-backface-visibility:visible;backface-visibility:visible;background:transparent none repeat 0 0/auto auto padding-box border-box scroll;border:medium none currentColor;border-collapse:separate;-o-border-image:none;border-image:none;border-radius:0;border-spacing:0;bottom:auto;box-shadow:none;box-sizing:content-box;caption-side:top;clear:none;clip:auto;color:#000;-webkit-columns:auto;-moz-columns:auto;columns:auto;-webkit-column-count:auto;-moz-column-count:auto;column-count:auto;-webkit-column-fill:balance;-moz-column-fill:balance;column-fill:balance;-webkit-column-gap:normal;-moz-column-gap:normal;column-gap:normal;-webkit-column-rule:medium none currentColor;-moz-column-rule:medium none currentColor;column-rule:medium none currentColor;-webkit-column-span:1;-moz-column-span:1;column-span:1;-webkit-column-width:auto;-moz-column-width:auto;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;direction:ltr;display:inline;empty-cells:show;float:none;font-family:serif;font-size:medium;font-style:normal;font-variant:normal;font-weight:400;font-stretch:normal;line-height:normal;height:auto;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;left:auto;letter-spacing:normal;list-style:disc outside none;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;opacity:1;orphans:2;outline:medium none invert;overflow:visible;overflow-x:visible;overflow-y:visible;padding:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;-webkit-perspective:none;perspective:none;-webkit-perspective-origin:50% 50%;perspective-origin:50% 50%;position:static;right:auto;-moz-tab-size:8;-o-tab-size:8;tab-size:8;table-layout:auto;text-align:left;text-align-last:auto;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;top:auto;-webkit-transform:none;transform:none;-webkit-transform-origin:50% 50% 0;transform-origin:50% 50% 0;-webkit-transform-style:flat;transform-style:flat;-webkit-transition:none 0s ease 0s;transition:none 0s ease 0s;unicode-bidi:normal;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;word-spacing:normal;z-index:auto;all:initial}sr-rd-content a,sr-rd-content a:link{color:#4183c4;text-decoration:none}sr-rd-content a:active,sr-rd-content a:focus,sr-rd-content a:hover{color:#4183c4;text-decoration:underline}sr-rd-content pre{background-color:#f7f7f7;border-radius:3px}sr-rd-content li code,sr-rd-content p code{background-color:rgba(0,0,0,.04);border-radius:3px}.simpread-multi-root{background:#f8f9fa}</style>
                        <style type="text/css"></style>
                        <style type="text/css">@media (pointer:coarse){sr-read{margin:20px 5%!important;min-width:0!important;max-width:90%!important}sr-rd-title{margin-top:0;font-size:2.7rem}sr-rd-content sr-blockquote,sr-rd-desc{margin:10 0!important;padding:0 0 0 10px!important;width:90%;font-size:1.8rem;font-style:normal;line-height:1.7;text-align:justify}sr-rd-content{font-size:1.75rem;font-weight:300}sr-rd-content figure{margin:0;padding:0;text-align:center}sr-rd-content a,sr-rd-content a:link,sr-rd-content li code,sr-rd-content p code{font-size:inherit}sr-rd-footer{margin-top:20px}sr-blockquote,sr-blockquote *{margin:5px!important;padding:5px!important}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6,sr-rd-title{font-family:PingFang SC,Verdana,Helvetica Neue,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;font-weight:100;line-height:1.35}sr-rd-content-h1,sr-rd-content-h2,sr-rd-content-h3,sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}sr-rd-content-h1,sr-rd-content h1{font-size:1.8em}sr-rd-content-h2,sr-rd-content h2{font-size:1.6em}sr-rd-content-h3,sr-rd-content h3{font-size:1.4em}sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{font-size:1.2em}sr-rd-content-ul,sr-rd-content ul{margin-left:1.3em!important;list-style:disc}sr-rd-content-ol,sr-rd-content ol{list-style:decimal;margin-left:1.9em!important}sr-rd-content-ol ol,sr-rd-content-ol ul,sr-rd-content-ul ol,sr-rd-content-ul ul,sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em!important}sr-rd-content img{margin:0;padding:0;border:0;max-width:100%!important;height:auto;box-shadow:0 20px 20px -10px rgba(0,0,0,.1)}sr-rd-mult{min-width:0;background-color:#fff;box-shadow:0 1px 6px rgba(32,33,36,.28);border-radius:8px}sr-rd-mult sr-rd-mult-avatar div{margin:0}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center-small{margin:7px 0!important}sr-rd-mult sr-rd-mult-avatar span{display:block}sr-rd-mult sr-rd-mult-content{padding-left:0}@media only screen and (max-device-width:1024px){.simpread-theme-root,html.simpread-theme-root{font-size:80%!important}sr-rd-mult sr-rd-mult-avatar img{width:50px;height:50px;min-width:50px;min-height:50px}toc-bg toc{width:10px!important}toc-bg:hover toc{width:auto!important}}@media only screen and (max-device-width:414px){.simpread-theme-root,html.simpread-theme-root{font-size:70%!important}sr-rd-mult sr-rd-mult-avatar img{width:30px;height:30px;min-width:30px;min-height:30px}}@media only screen and (max-device-width:320px){.simpread-theme-root,html.simpread-theme-root{font-size:90%!important}sr-rd-content p{margin-bottom:.5em}}}</style>
                        <style type="text/css">undefinedsr-rd-content *, sr-rd-content p, sr-rd-content div {}sr-rd-content pre code, sr-rd-content pre code * {}sr-rd-desc {}sr-rd-content pre {}sr-rd-title {}</style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css">sr-rd-content *, sr-rd-content p, sr-rd-content div {
        font-size: 15px;
    }

    .annote-perview, .annote-perview * {
        color: rgb(85, 85, 85);
        font-weight: 400;
        line-height: 1.8;
    }</style>
                        
                        
                        <script>setTimeout(()=>{const e=location.hash.replace("#id=","");let t,a=!1;const n=t=>{for(let n of t){let t;if((t=e.length>6?n.getAttribute("data-id"):n.getAttribute("data-idx"))==e){n.scrollIntoView({behavior:"smooth",block:"start",inline:"nearest"}),a=!0;break}}};e&&(0==(t=document.getElementsByClassName("sr-unread-card")).length&&(t=document.getElementsByTagName("sr-annote")),n(t),a||n(t=document.getElementsByClassName("sr-annote")))},500);</script>
                        <script>document.addEventListener("DOMContentLoaded",function(){if("localhost"==location.hostname){const t=document.getElementsByTagName("img");for(let o of t){const t=o.src;t.startsWith("http")&&(o.src=location.origin+"/proxy?url="+t)}}},!1);</script>
                        <style>toc a {font-size: inherit!important;font-weight: 300!important;}</style><script>setTimeout(()=>{const max=document.getElementsByTagName('sr-annote-note-tip').length;for(let i=0;i<max;i++){const target=document.getElementsByTagName('sr-annote-note-tip')[i],value=target.dataset.value;value&&(target.innerText=value)}},1000);</script><title>简悦 | 17 | 图像分类（上）：图像分类原理与图像分类模型</title>
                    </head>
                    <body>
                        <sr-read style='font-family: "LXGW WenKai Screen";'>
                            <sr-rd-title>17 | 图像分类（上）：图像分类原理与图像分类模型</sr-rd-title>
                    <sr-rd-desc style="margin: 0;padding-top: 0;padding-bottom: 0;font-style: normal;font-size: 18px;">今天我们一起剖析分布式训练的原理，然后一起学习一个分布式训练的实战项目。</sr-rd-desc>
                    <sr-rd-content><h1 id="sr-toc-0">17 | 图像分类（上）：图像分类原理与图像分类模型</h1><div><span>方远</span> <span> 2021-11-19</span></div><div><div><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/e3/5b/e36e57da651a4f4106a8a99c47ae1a5b.jpg"></div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADEAAAABCAYAAAB35kaxAAAAAXNSR0IArs4c6QAAAChJREFUGFdjfPfu3X8GKBAUFASz3r9/DxNiQBbDxcamn1yzSLEDZi8A2agny86FR+IAAAAASUVORK5CYII="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAABCAYAAAA8TpVcAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFCYtjkAcT9D8ti7hUOAAAAAElFTkSuQmCC"></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD0AAAABCAYAAABt2qY/AAAAAXNSR0IArs4c6QAAACdJREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULy2PQQK0YLewiZCQDhUS3LBhDf1QAAAABJRU5ErkJggg=="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAABCAYAAAA4u0VhAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULyAF6lD8tbqYWOAAAAAElFTkSuQmCC"></div></div></div><div><div><div></div></div><div><div><div><div><div><div>00:00</div></div><div></div></div></div><a href="javascript:;"> 1.0x <i><span></span></i></a></div><div><span>讲述：方远</span><span>大小：14.61M</span><span> 时长：16:00</span></div></div><audio title="17 | 图像分类（上）：图像分类原理与图像分类模型" src="https://res001.geekbang.org/media/audio/0a/c4/0a3c1c024ddb27969fea11e399c727c4/ld/ld.m3u8"></audio></div><div><div><div><div data-slate-editor="true" data-key="663" autocorrect="off" spellcheck="false" data-gramm="false"><div data-slate-type="paragraph" data-slate-object="block" data-key="664"><span data-slate-object="text" data-key="665"><span data-slate-leaf="true" data-offset-key="665:0" data-first-offset="true"><span data-slate-string="true">你好，我是方远，欢迎来到图像分类的学习。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="666"><span data-slate-object="text" data-key="667"><span data-slate-leaf="true" data-offset-key="667:0" data-first-offset="true"><span data-slate-string="true">通过前面的学习，我们已经掌握了 PyTorch 有关深度学习的不少知识。为了避免纸上谈兵，我们正式进入实战环节，分别从计算机视觉与自然语言处理这两个落地项目最多的深度学习应用展开，看看业界那些常见深度学习应用都是如何实现的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="668"><span data-slate-object="text" data-key="669"><span data-slate-leaf="true" data-offset-key="669:0" data-first-offset="true"><span data-slate-string="true">完成这个模块的学习以后，我想你不仅仅会巩固之前学习的内容，还会进一步地落实到细分的领域去看待问题、解决问题。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="670"><span data-slate-object="text" data-key="671"><span data-slate-leaf="true" data-offset-key="671:0" data-first-offset="true"><span data-slate-string="true">说到计算机视觉，</span></span></span><span data-slate-object="text" data-key="672"><span data-slate-leaf="true" data-offset-key="672:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">很常见的一种应用方向就是图像分类</span></span></span></span><span data-slate-object="text" data-key="673"><span data-slate-leaf="true" data-offset-key="673:0" data-first-offset="true"><span data-slate-string="true">。关于图像分类，其实离我们并不遥远。你有没有发现，现在很多智能手机，照相的时候都会自动给照片内容打上标签。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="674"><span data-slate-object="text" data-key="675"><span data-slate-leaf="true" data-offset-key="675:0" data-first-offset="true"><span data-slate-string="true">举个例子，你看后面的截图，就是我用手机拍照的时候，手机自动对摄像头的内容进行了识别，打上了 “多云” 这个标签。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="676"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/75/7c/75e6ec9c616da2c5c5907e0d11184d7c.jpeg?wh=1920x886"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="677"><span data-slate-object="text" data-key="678"><span data-slate-leaf="true" data-offset-key="678:0" data-first-offset="true"><span data-slate-string="true">然后你会发现，手机还能根据识别到的内容，为你推荐一些美化的方案。那这是怎么做到的呢？其实这就是卷积神经网络最常用、最广泛且最基本的一个应用：图像分类。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="679"><span data-slate-object="text" data-key="680"><span data-slate-leaf="true" data-offset-key="680:0" data-first-offset="true"><span data-slate-string="true">今天咱们就来一探究竟，看看图像分类到底是怎么一回事。我会用两节课的篇幅，带你学习图像分类。这节课我们先学习理论知识，掌握图像分类原理和常见的卷积神经网络。下节课，我们再基于今天学到的原理，一块完成一个完整的图像分类项目实践。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="681" id="sr-toc-1"><span data-slate-object="text" data-key="682"><span data-slate-leaf="true" data-offset-key="682:0" data-first-offset="true"><span data-slate-string="true">图像分类原理</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="683"><span data-slate-object="text" data-key="684"><span data-slate-leaf="true" data-offset-key="684:0" data-first-offset="true"><span data-slate-string="true">我们还是 “书接上文”，沿用第 3 节课 NumPy 的那个例子。现在线上每天都有大量的图片被上传，老板交代你设计一个模型，把有关极客时间 Logo 的图片自动找出来。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="685"><span data-slate-object="text" data-key="686"><span data-slate-leaf="true" data-offset-key="686:0" data-first-offset="true"><span data-slate-string="true">把这个需求翻译一下就是：建立一个图像分类模型，提供自动识别有极客时间 Logo 图片的功能。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="687"><span data-slate-object="text" data-key="688"><span data-slate-leaf="true" data-offset-key="688:0" data-first-offset="true"><span data-slate-string="true">我们来梳理一下这个模型的功能，我们这个模型会接收一张图片，然后会输出一组概率，分别是该图片为 Logo 的概率与该图片为其他图片的概率，从而通过概率来判断这张图片是 Logo 类还是 Other 类，如下图所示：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="689"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/f4/68/f4b226497cb6aae5e0dcde4f65e46a68.png?wh=1392x604"></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="690" id="sr-toc-2"><span data-slate-object="text" data-key="691"><span data-slate-leaf="true" data-offset-key="691:0" data-first-offset="true"><span data-slate-string="true">感知机</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="692"><span data-slate-object="text" data-key="693"><span data-slate-leaf="true" data-offset-key="693:0" data-first-offset="true"><span data-slate-string="true">我们将上面的模型进一步拆分，看看如何才能获得这样的一组输出。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="694"><span data-slate-object="text" data-key="695"><span data-slate-leaf="true" data-offset-key="695:0" data-first-offset="true"><span data-slate-string="true">其中输入的图片，就是输入 X，将其展开后，可以获得输入 X 为 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="696"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>X</span><span></span><span>=</span><span></span></span><span><span></span><span><span><span>x</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span>…</span><span></span><span>,</span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="698"><span data-slate-leaf="true" data-offset-key="698:0" data-first-offset="true"><span data-slate-string="true">，而模型可以看做有两个节点，每个节点都会有一个输出，分别代表着对输入为 Logo 和 Other 的判断，但这里的输出暂时还不是概率，只是模型输出的一组数值。这一部分内容如下图所示：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="699"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/03/29/0322747253dbbffe80a92004ea12be29.png?wh=1732x660"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="700"><span data-slate-object="text" data-key="701"><span data-slate-leaf="true" data-offset-key="701:0" data-first-offset="true"><span data-slate-string="true">上图这个结构其实就是感知机了，中间绿色的节点叫做神经元，是感知机的最基本组成单元。上图中的感知机只有中间一层（绿色的神经元），如果有多层神经元的话，我们就称之为多层感知机。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="702"><span data-slate-object="text" data-key="703"><span data-slate-leaf="true" data-offset-key="703:0" data-first-offset="true"><span data-slate-string="true">那什么是神经元呢？神经元是关于输入的一个线性变换，每一个输入 x 都会有一个对应的权值，上图中的 y 的计算方式为：</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="704"><span><span><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span></span><span><span></span><span>δ</span><span>(</span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>i</span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>i</span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span>…</span><span></span><span>+</span><span></span></span><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span><span>i</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>n</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span>,</span><span></span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>i</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>,</span><span></span><span>2</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="706"><span data-slate-object="text" data-key="707"><span data-slate-leaf="true" data-offset-key="707:0" data-first-offset="true"><span data-slate-string="true">其中，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="708"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>i</span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>i</span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span>…</span><span></span><span>,</span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>i</span><span>n</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="710"><span data-slate-leaf="true" data-offset-key="710:0" data-first-offset="true"><span data-slate-string="true"> 是神经元的权重，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="711"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="713"><span data-slate-leaf="true" data-offset-key="713:0" data-first-offset="true"><span data-slate-string="true"> 为神经元的偏移项。权重与偏移项都是通过模型学习到的参数。</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="714"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>δ</span></span></span></span></span></span><span data-slate-object="text" data-key="716"><span data-slate-leaf="true" data-offset-key="716:0" data-first-offset="true"><span data-slate-string="true"> 为激活函数，激活函数是一个可选参数。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="717"><span data-slate-object="text" data-key="718"><span data-slate-leaf="true" data-offset-key="718:0" data-first-offset="true"><span data-slate-string="true">那如何将一组数值，也就是 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="719"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="721"><span data-slate-leaf="true" data-offset-key="721:0" data-first-offset="true"><span data-slate-string="true"> 与 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="722"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>2</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="724"><span data-slate-leaf="true" data-offset-key="724:0" data-first-offset="true"><span data-slate-string="true"> 转换为一组对应的概率呢？这个时候 Softmax 函数就要登场了。它的作用就是将一组数值转换为对应的概率，概率和为 1。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="725"><span data-slate-object="text" data-key="726"><span data-slate-leaf="true" data-offset-key="726:0" data-first-offset="true"><span data-slate-string="true">Softmax 的计算公式如下：</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="727"><span><span><span aria-hidden="true"><span><span></span><span>δ</span><span>(</span><span><span>x</span><span><span><span><span><span><span></span><span><span>j</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>∑</span><span><span><span><span><span><span></span><span><span><span>j</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span><span>m</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span>x</span><span><span><span><span><span><span></span><span><span>j</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span>x</span><span><span><span><span><span><span></span><span><span>j</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="729"><span data-slate-object="text" data-key="730"><span data-slate-leaf="true" data-offset-key="730:0" data-first-offset="true"><span data-slate-string="true">请看下面的代码，我们用 Softmax 函数对原始的输入 y 做个转化，将 y 中的数值转化为一组对应的概率：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="731"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="732"><span data-slate-object="text" data-key="733"><span data-slate-leaf="true" data-offset-key="733:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="734"><span data-slate-leaf="true" data-offset-key="734:0" data-first-offset="true"><span data-slate-string="true"> torch</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="735"><span data-slate-object="text" data-key="736"><span data-slate-leaf="true" data-offset-key="736:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="737"><span data-slate-leaf="true" data-offset-key="737:0" data-first-offset="true"><span data-slate-string="true"> torch.nn </span></span></span><span data-slate-object="text" data-key="738"><span data-slate-leaf="true" data-offset-key="738:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">as</span></span></span></span><span data-slate-object="text" data-key="739"><span data-slate-leaf="true" data-offset-key="739:0" data-first-offset="true"><span data-slate-string="true"> nn</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="740"></div><div data-slate-type="code-line" data-slate-object="block" data-key="741"><span data-slate-object="text" data-key="742"><span data-slate-leaf="true" data-offset-key="742:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 2 个神经元的输出 y 的数值为</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="743"><span data-slate-object="text" data-key="744"><span data-slate-leaf="true" data-offset-key="744:0" data-first-offset="true"><span data-slate-string="true">y = torch.randn(</span></span></span><span data-slate-object="text" data-key="745"><span data-slate-leaf="true" data-offset-key="745:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">2</span></span></span></span><span data-slate-object="text" data-key="746"><span data-slate-leaf="true" data-offset-key="746:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="747"><span data-slate-object="text" data-key="748"><span data-slate-leaf="true" data-offset-key="748:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="749"><span data-slate-leaf="true" data-offset-key="749:0" data-first-offset="true"><span data-slate-string="true">(y)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="750"><span data-slate-object="text" data-key="751"><span data-slate-leaf="true" data-offset-key="751:0" data-first-offset="true"><span data-slate-string="true">输出：tensor ([</span></span></span><span data-slate-object="text" data-key="752"><span data-slate-leaf="true" data-offset-key="752:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.2370</span></span></span></span><span data-slate-object="text" data-key="753"><span data-slate-leaf="true" data-offset-key="753:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="754"><span data-slate-leaf="true" data-offset-key="754:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1.7276</span></span></span></span><span data-slate-object="text" data-key="755"><span data-slate-leaf="true" data-offset-key="755:0" data-first-offset="true"><span data-slate-string="true">])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="756"><span data-slate-object="text" data-key="757"><span data-slate-leaf="true" data-offset-key="757:0" data-first-offset="true"><span data-slate-string="true">m = nn.Softmax(dim=</span></span></span><span data-slate-object="text" data-key="758"><span data-slate-leaf="true" data-offset-key="758:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="759"><span data-slate-leaf="true" data-offset-key="759:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="760"><span data-slate-object="text" data-key="761"><span data-slate-leaf="true" data-offset-key="761:0" data-first-offset="true"><span data-slate-string="true">out = m(y)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="762"><span data-slate-object="text" data-key="763"><span data-slate-leaf="true" data-offset-key="763:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="764"><span data-slate-leaf="true" data-offset-key="764:0" data-first-offset="true"><span data-slate-string="true">(out)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="765"><span data-slate-object="text" data-key="766"><span data-slate-leaf="true" data-offset-key="766:0" data-first-offset="true"><span data-slate-string="true">输出：tensor ([</span></span></span><span data-slate-object="text" data-key="767"><span data-slate-leaf="true" data-offset-key="767:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.1838</span></span></span></span><span data-slate-object="text" data-key="768"><span data-slate-leaf="true" data-offset-key="768:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="769"><span data-slate-leaf="true" data-offset-key="769:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.8162</span></span></span></span><span data-slate-object="text" data-key="770"><span data-slate-leaf="true" data-offset-key="770:0" data-first-offset="true"><span data-slate-string="true">])</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="771"><span data-slate-object="text" data-key="772"><span data-slate-leaf="true" data-offset-key="772:0" data-first-offset="true"><span data-slate-string="true">你看，经过 Softmax 之后，原始的输出 y 是不是转换成一组概率，并且概率的和为 1 呢。原始 y 中最大的 y 具有最大的概率。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="773"><span data-slate-object="text" data-key="774"><span data-slate-leaf="true" data-offset-key="774:0" data-first-offset="true"><span data-slate-string="true">当然，Softmax 也不是每一个问题都会使用。我们根据问题的不同可以采用不同的函数，例如，有的时候也会使用 sigmoid 激活函数，sigmoid 激活函数是将 1 个数值转换为 0 到 1 之间的概率。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="775"><span data-slate-object="text" data-key="776"><span data-slate-leaf="true" data-offset-key="776:0" data-first-offset="true"><span data-slate-string="true">现在，我们将上述的过程补充到前面的模型里，如下图所示。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="777"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/92/32/92ec877yy99cd31b5c9c9fc46f78c832.png?wh=1708x608"></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="778" id="sr-toc-3"><span data-slate-object="text" data-key="779"><span data-slate-leaf="true" data-offset-key="779:0" data-first-offset="true"><span data-slate-string="true">全连接层</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="780"><span data-slate-object="text" data-key="781"><span data-slate-leaf="true" data-offset-key="781:0" data-first-offset="true"><span data-slate-string="true">其实，上面那张示意图，就是图像的分类原理了。其中绿色那一层。在卷积神经网络中称为</span></span></span><span data-slate-object="text" data-key="782"><span data-slate-leaf="true" data-offset-key="782:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">全连接层，Full Connection Layer，简称 fc 层。一般都是放在网络的最后端</span></span></span></span><span data-slate-object="text" data-key="783"><span data-slate-leaf="true" data-offset-key="783:0" data-first-offset="true"><span data-slate-string="true">，用来获得最终的输出，也就是各个类别的概率。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="784"><span data-slate-object="text" data-key="785"><span data-slate-leaf="true" data-offset-key="785:0" data-first-offset="true"><span data-slate-string="true">因为全连接层中的神经元的个数是固定的，所以说在有全连接层的网络中，输入图片是必须固定尺寸的。而现实里我们线上收集到的图片会有不同的尺寸，所以需要先把图片尺寸统一起来，PyTorch 才能进一步处理。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="786"><span data-slate-object="text" data-key="787"><span data-slate-leaf="true" data-offset-key="787:0" data-first-offset="true"><span data-slate-string="true">我们假设将前面的输入图片 resize 到 128x128，然后看看全连接层推断的过程在 PyTorch 中是如何实现的。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="788"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="789"><span data-slate-object="text" data-key="790"><span data-slate-leaf="true" data-offset-key="790:0" data-first-offset="true"><span data-slate-string="true">x = torch.randint(</span></span></span><span data-slate-object="text" data-key="791"><span data-slate-leaf="true" data-offset-key="791:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="792"><span data-slate-leaf="true" data-offset-key="792:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="793"><span data-slate-leaf="true" data-offset-key="793:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">255</span></span></span></span><span data-slate-object="text" data-key="794"><span data-slate-leaf="true" data-offset-key="794:0" data-first-offset="true"><span data-slate-string="true">, (</span></span></span><span data-slate-object="text" data-key="795"><span data-slate-leaf="true" data-offset-key="795:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="796"><span data-slate-leaf="true" data-offset-key="796:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="797"><span data-slate-leaf="true" data-offset-key="797:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">128</span></span></span></span><span data-slate-object="text" data-key="798"><span data-slate-leaf="true" data-offset-key="798:0" data-first-offset="true"><span data-slate-string="true">*</span></span></span><span data-slate-object="text" data-key="799"><span data-slate-leaf="true" data-offset-key="799:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">128</span></span></span></span><span data-slate-object="text" data-key="800"><span data-slate-leaf="true" data-offset-key="800:0" data-first-offset="true"><span data-slate-string="true">), dtype=torch.float32)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="801"><span data-slate-object="text" data-key="802"><span data-slate-leaf="true" data-offset-key="802:0" data-first-offset="true"><span data-slate-string="true">fc = nn.Linear(</span></span></span><span data-slate-object="text" data-key="803"><span data-slate-leaf="true" data-offset-key="803:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">128</span></span></span></span><span data-slate-object="text" data-key="804"><span data-slate-leaf="true" data-offset-key="804:0" data-first-offset="true"><span data-slate-string="true">*</span></span></span><span data-slate-object="text" data-key="805"><span data-slate-leaf="true" data-offset-key="805:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">128</span></span></span></span><span data-slate-object="text" data-key="806"><span data-slate-leaf="true" data-offset-key="806:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="807"><span data-slate-leaf="true" data-offset-key="807:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">2</span></span></span></span><span data-slate-object="text" data-key="808"><span data-slate-leaf="true" data-offset-key="808:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="809"><span data-slate-object="text" data-key="810"><span data-slate-leaf="true" data-offset-key="810:0" data-first-offset="true"><span data-slate-string="true">y = fc(x)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="811"><span data-slate-object="text" data-key="812"><span data-slate-leaf="true" data-offset-key="812:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="813"><span data-slate-leaf="true" data-offset-key="813:0" data-first-offset="true"><span data-slate-string="true">(y)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="814"><span data-slate-object="text" data-key="815"><span data-slate-leaf="true" data-offset-key="815:0" data-first-offset="true"><span data-slate-string="true">输出：tensor ([[  </span></span></span><span data-slate-object="text" data-key="816"><span data-slate-leaf="true" data-offset-key="816:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">72.1361</span></span></span></span><span data-slate-object="text" data-key="817"><span data-slate-leaf="true" data-offset-key="817:0" data-first-offset="true"><span data-slate-string="true">, -</span></span></span><span data-slate-object="text" data-key="818"><span data-slate-leaf="true" data-offset-key="818:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">120.3565</span></span></span></span><span data-slate-object="text" data-key="819"><span data-slate-leaf="true" data-offset-key="819:0" data-first-offset="true"><span data-slate-string="true">]], grad_fn=&lt;AddmmBackward&gt;)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="820"><span data-slate-object="text" data-key="821"><span data-slate-leaf="true" data-offset-key="821:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 注意 y 的 shape 是 (1, 2)</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="822"><span data-slate-object="text" data-key="823"><span data-slate-leaf="true" data-offset-key="823:0" data-first-offset="true"><span data-slate-string="true">output = nn.Softmax(dim=</span></span></span><span data-slate-object="text" data-key="824"><span data-slate-leaf="true" data-offset-key="824:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="825"><span data-slate-leaf="true" data-offset-key="825:0" data-first-offset="true"><span data-slate-string="true">)(y)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="826"><span data-slate-object="text" data-key="827"><span data-slate-leaf="true" data-offset-key="827:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="828"><span data-slate-leaf="true" data-offset-key="828:0" data-first-offset="true"><span data-slate-string="true">(output)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="829"><span data-slate-object="text" data-key="830"><span data-slate-leaf="true" data-offset-key="830:0" data-first-offset="true"><span data-slate-string="true">输出：tensor ([[</span></span></span><span data-slate-object="text" data-key="831"><span data-slate-leaf="true" data-offset-key="831:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1.</span></span></span></span><span data-slate-object="text" data-key="832"><span data-slate-leaf="true" data-offset-key="832:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="833"><span data-slate-leaf="true" data-offset-key="833:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.</span></span></span></span><span data-slate-object="text" data-key="834"><span data-slate-leaf="true" data-offset-key="834:0" data-first-offset="true"><span data-slate-string="true">]], grad_fn=&lt;SoftmaxBackward&gt;)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="835"><span data-slate-object="text" data-key="836"><span data-slate-leaf="true" data-offset-key="836:0" data-first-offset="true"><span data-slate-string="true">结合代码不难看出，PyTorch 中全连接层用 nn.Linear 来实现。我们分别看看里面的重要参数有哪些：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="837"><div data-slate-type="list-line" data-slate-object="block" data-key="838"><span data-slate-object="text" data-key="839"><span data-slate-leaf="true" data-offset-key="839:0" data-first-offset="true"><span data-slate-string="true">in_features：输入特征的个数，在本例中为 128x128；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="840"><span data-slate-object="text" data-key="841"><span data-slate-leaf="true" data-offset-key="841:0" data-first-offset="true"><span data-slate-string="true">out_features：输出的特征数，在本例中为 2；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="842"><span data-slate-object="text" data-key="843"><span data-slate-leaf="true" data-offset-key="843:0" data-first-offset="true"><span data-slate-string="true">bias：是否需要偏移项，默认为 True。</span></span></span></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="844"><span data-slate-object="text" data-key="845"><span data-slate-leaf="true" data-offset-key="845:0" data-first-offset="true"><span data-slate-string="true">全连接层的输入，也不是原始图片数据，而是经过多层卷积提取的特征。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="846"><span data-slate-object="text" data-key="847"><span data-slate-leaf="true" data-offset-key="847:0" data-first-offset="true"><span data-slate-string="true">前面我们曾说过，有的网络是可以接收任意尺度的输入的。在上文中的设计中，全连接层的输入 x1 到 xn 是固定的，数目等于最后一层特征图所有元素的数目。如下图所示：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="848"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/af/5b/af7f9971ea5564d93c0a0089d3f5d75b.png?wh=1490x678"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="849"><span data-slate-object="text" data-key="850"><span data-slate-leaf="true" data-offset-key="850:0" data-first-offset="true"><span data-slate-string="true">我们将上述结构稍作调整，就可以接收任意尺度的输入了。只需要在最后的特征图后面加一个全局平均即可，也就是将每个特征图进行求平均，用平均值代替特征图，这样无论输入的尺度是多少，进入全连接层的数据量都是固定的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="851"><span data-slate-object="text" data-key="852"><span data-slate-leaf="true" data-offset-key="852:0" data-first-offset="true"><span data-slate-string="true">如下图所示，黄色的圈就是全局平均的结果。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="853"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/e0/e0/e0a62554422d28601af056809873d8e0.png?wh=1760x730"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="854"><span data-slate-object="text" data-key="855"><span data-slate-leaf="true" data-offset-key="855:0" data-first-offset="true"><span data-slate-string="true">我们下一节课介绍的 EfficientNet 就是采用这种方式，使得网络可以使用任意尺度的图片进行训练。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="856" id="sr-toc-4"><span data-slate-object="text" data-key="857"><span data-slate-leaf="true" data-offset-key="857:0" data-first-offset="true"><span data-slate-string="true">卷积神经网络</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="858"><span data-slate-object="text" data-key="859"><span data-slate-leaf="true" data-offset-key="859:0" data-first-offset="true"><span data-slate-string="true">其实刚才说的多层感知机就是卷积神经网络的前身，由于自身的缺陷（参数量大、难以训练），使其在历史上有段时间一直是停滞不前，直到卷积神经网络的出现，打破了僵局。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="860"><span data-slate-object="text" data-key="861"><span data-slate-leaf="true" data-offset-key="861:0" data-first-offset="true"><span data-slate-string="true">卷积神经网络的最大作用就是提取出输入图片的丰富信息，然后再对接上层的一些应用，比如前面提到的图片分类。把卷积神经网络应用到图像分类原理中，得到的模型如下图所示：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="862"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/8b/1a/8bbc16d51yydca581cb1d88274ec161a.png?wh=1728x664"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="863"><span data-slate-object="text" data-key="864"><span data-slate-leaf="true" data-offset-key="864:0" data-first-offset="true"><span data-slate-string="true">你需要注意的是示意图中各个层的定义，不同层有不同的名称。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="865"><span data-slate-object="text" data-key="866"><span data-slate-leaf="true" data-offset-key="866:0" data-first-offset="true"><span data-slate-string="true">在上图中，</span></span></span><span data-slate-object="text" data-key="867"><span data-slate-leaf="true" data-offset-key="867:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">整个模型或者网络的重点全都在卷积神经网络那块，所以这也是我们的工作重点</span></span></span></span><span data-slate-object="text" data-key="868"><span data-slate-leaf="true" data-offset-key="868:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="869"><span data-slate-object="text" data-key="870"><span data-slate-leaf="true" data-offset-key="870:0" data-first-offset="true"><span data-slate-string="true">那如何找到一个合适的卷积神经网络呢？在实际工作中，我们几乎不会自己去设计一个神经网络网的（因为不可控的变量太多），而是直接选择一些大神设计好的网络直接使用。那网络模型那么多，我们如何验证大神们提出的网络确实是可靠、可用的呢？</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="871" id="sr-toc-5"><span data-slate-object="text" data-key="872"><span data-slate-leaf="true" data-offset-key="872:0" data-first-offset="true"><span data-slate-string="true">ImageNet</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="873"><span data-slate-object="text" data-key="874"><span data-slate-leaf="true" data-offset-key="874:0" data-first-offset="true"><span data-slate-string="true">在业界中有个标杆 ——ImageNet，大家都用它来评价提出模型的好与坏。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="875"><span data-slate-object="text" data-key="876"><span data-slate-leaf="true" data-offset-key="876:0" data-first-offset="true"><span data-slate-string="true">ImageNet 本身包含了一个非常大的数据集，并且从 2010 年开始，每年都会举办一次著名的 ImageNet 大规模视觉识别挑战赛（The ImageNet Large Scale Visual Recognition Challenge ，ILSVRC），比赛包含了图像分类、目标检测与图像分割等任务。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="877"><span data-slate-object="text" data-key="878"><span data-slate-leaf="true" data-offset-key="878:0" data-first-offset="true"><span data-slate-string="true">其中，图像分类比赛使用的数据集是一份有 1000 个类别的庞大数据集，只要能在这个比赛中脱颖而出的模型，都是我们所说的经典网络结构，这些网络在实际项目中基本都是我们的首选。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="879"><span data-slate-object="text" data-key="880"><span data-slate-leaf="true" data-offset-key="880:0" data-first-offset="true"><span data-slate-string="true">从 2012 年开始，伴随着深度学习的发展，几乎每一年都有非常经典的网络结构诞生，下表为历年来 ImageNet 上 Top-5 的错误率。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="881"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/da/73/da4f8fe982d066b8541f63231d257c73.jpg?wh=1920x818"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="882"><span data-slate-object="text" data-key="883"><span data-slate-leaf="true" data-offset-key="883:0" data-first-offset="true"><span data-slate-string="true">你可能会有疑问，了解这么多网络模型真的有必要么？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="884"><span data-slate-object="text" data-key="885"><span data-slate-leaf="true" data-offset-key="885:0" data-first-offset="true"><span data-slate-string="true">我想说的是，磨刀不误砍柴工，</span></span></span><span data-slate-object="text" data-key="886"><span data-slate-leaf="true" data-offset-key="886:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">机器学习这个领域始终是依靠研究驱动的。</span></span></span></span><span data-slate-object="text" data-key="887"><span data-slate-leaf="true" data-offset-key="887:0" data-first-offset="true"><span data-slate-string="true">工作当中，我们很少从 0 到 1 自创一个网络模型，常常是在经典设计基础上做一些自定义配置，所以你最好对这些经典网络都有所了解。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="888"><span data-slate-object="text" data-key="889"><span data-slate-leaf="true" data-offset-key="889:0" data-first-offset="true"><span data-slate-string="true">接下来，我们就挑选几个经典的神经网络来看看。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="890" id="sr-toc-6"><span data-slate-object="text" data-key="891"><span data-slate-leaf="true" data-offset-key="891:0" data-first-offset="true"><span data-slate-string="true">VGG</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="892"><a data-slate-type="link" data-slate-object="inline" data-key="893"><span data-slate-object="text" data-key="894"><span data-slate-leaf="true" data-offset-key="894:0" data-first-offset="true"><span data-slate-string="true">VGG</span></span></span></a><span data-slate-object="text" data-key="895"><span data-slate-leaf="true" data-offset-key="895:0" data-first-offset="true"><span data-slate-string="true"> 取得了 ILSVRC 2014 比赛分类项目的第 2 名和定位项目的第 1 名的优异成绩。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="896"><span data-slate-object="text" data-key="897"><span data-slate-leaf="true" data-offset-key="897:0" data-first-offset="true"><span data-slate-string="true">当年的 VGG 一共提供了 A 到 E6 种不同的 VGG 网络（字母不同，只是表示层数不一样）。VGG19 的效果虽说最好，但是综合模型大小等指标，在实际项目中 VGG16 用得更加多一点。具体的网络结构你可以看看论文。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="898"><span data-slate-object="text" data-key="899"><span data-slate-leaf="true" data-offset-key="899:0" data-first-offset="true"><span data-slate-string="true">我们来看看 VGG 突破的一些重点：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="900"><div data-slate-type="list-line" data-slate-object="block" data-key="901"><div data-code-line-number="1"></div><div><span data-slate-object="text" data-key="902"><span data-slate-leaf="true" data-offset-key="902:0" data-first-offset="true"><span data-slate-string="true">证明了随着模型深度的增加，模型效果也会越来越好。</span></span></span></div></div><div data-slate-type="list-line" data-slate-object="block" data-key="903"><div data-code-line-number="2"></div><div><span data-slate-object="text" data-key="904"><span data-slate-leaf="true" data-offset-key="904:0" data-first-offset="true"><span data-slate-string="true">使用较小的 3x3 的卷积，代替了 AlexNet 中的 11x11、7x7 以及 5x5 的大卷积核。</span></span></span></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="905"><span data-slate-object="text" data-key="906"><span data-slate-leaf="true" data-offset-key="906:0" data-first-offset="true"><span data-slate-string="true">关于第二点，VGG 中将 5x5 的卷积用 2 层 3x3 的卷积替换；将 7x7 的卷积用 3 层 3x3 的卷积替换。这样做首先可以减少网络的参数，其次是可以在相同感受野的前提下，加深网络的层数，从而提取出更加多样的非线性信息。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="907" id="sr-toc-7"><span data-slate-object="text" data-key="908"><span data-slate-leaf="true" data-offset-key="908:0" data-first-offset="true"><span data-slate-string="true">GoogLeNet</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="909"><span data-slate-object="text" data-key="910"><span data-slate-leaf="true" data-offset-key="910:0" data-first-offset="true"><span data-slate-string="true">2014 年分类比赛的冠军是 </span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="911"><span data-slate-object="text" data-key="912"><span data-slate-leaf="true" data-offset-key="912:0" data-first-offset="true"><span data-slate-string="true">GoogLeNet</span></span></span></a><span data-slate-object="text" data-key="913"><span data-slate-leaf="true" data-offset-key="913:0" data-first-offset="true"><span data-slate-string="true">（VGG 同年）。GoogLeNet 的核心是 Inception 模块。这个时期的 Inception 模块是 v1 版本，后续还有 v2、v3 以及 v4 版本。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="914"><span data-slate-object="text" data-key="915"><span data-slate-leaf="true" data-offset-key="915:0" data-first-offset="true"><span data-slate-string="true">我们先来看看 GoogLeNet 解决了什么样的问题。研究人员发现，对于同一个类别的图片，主要物体在不同图片中，所占的区域大小均有不同，例如下图所示。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="916"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/c4/a7/c4bed5998c8yy9d4e4661c8a5520fba7.jpg?wh=2561x992"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="917"><span data-slate-object="text" data-key="918"><span data-slate-leaf="true" data-offset-key="918:0" data-first-offset="true"><span data-slate-string="true">如果使用 AlexNet 或者 VGG 中标准的卷积的话，每一层只能以相同的尺寸的卷积核来提取图片中的特征。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="919"><span data-slate-object="text" data-key="920"><span data-slate-leaf="true" data-offset-key="920:0" data-first-offset="true"><span data-slate-string="true">但是正如上图所示，很可能物体以不同的尺寸出现在图片中，那么能否以不同尺度的卷积来提取不同的特征呢？沿着这个想法，Inception 模块应运而生，如下图示：</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="921"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/91/a1/911eee05256f145209fae76d3yy23fa1.png?wh=2718x1298"></div><div>图片来源：https://arxiv.org/abs/1409.4842</div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="922"><span data-slate-object="text" data-key="923"><span data-slate-leaf="true" data-offset-key="923:0" data-first-offset="true"><span data-slate-string="true">结合图示我们发现，这里是将原来的相同尺寸卷积提取特征的方式拆分为，使用 1x1、3x3、5x5 以及 3x3 的 max pooling 同时进行特征提取，然后再合并到一起。这样就做到了以</span></span></span><span data-slate-object="text" data-key="924"><span data-slate-leaf="true" data-offset-key="924:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">多尺度的方式</span></span></span></span><span data-slate-object="text" data-key="925"><span data-slate-leaf="true" data-offset-key="925:0" data-first-offset="true"><span data-slate-string="true">提取图片中的特征。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="926"><span data-slate-object="text" data-key="927"><span data-slate-leaf="true" data-offset-key="927:0" data-first-offset="true"><span data-slate-string="true">作者为了降低网络的计算成本，将上述的 Inception 模块做了一步改进，在 3x3、5x5 之前与 pooling 之后添加了 1x1 卷积用来降维，从而获得了 Inception 模块的最终形态。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="928"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/8f/21/8fd81403acd0d70fb5ae4a857177ee21.png?wh=2700x1312"></div><div>图片来源：https://arxiv.org/abs/1409.4842</div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="929"><span data-slate-object="text" data-key="930"><span data-slate-leaf="true" data-offset-key="930:0" data-first-offset="true"><span data-slate-object="annotation" data-annotation-key="gkann_f4f8c9bb" data-attr-id="41252" data-attr-name="public" data-annotation-type="public"><span data-slate-string="true">这里有个额外的小知识点，如果是面试，经常会被问到为什么采用 1x1 的卷积或者 1x1 卷积的作用。1x1 卷积的作用就是用来升维或者降维的。</span></span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="931"><span data-slate-object="text" data-key="932"><span data-slate-leaf="true" data-offset-key="932:0" data-first-offset="true"><span data-slate-string="true">GooLeNet 就是由以上的 Inception 模块构成的一个 22 层网络。别看网络层数有 22 层，但是它参数量却比 AlexNet 与 VGG 都要少，这带来的优势就是，搭建起来的模型就很小，占的存储空间也小。具体的网络结构你可以参考它的论文。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="933" id="sr-toc-8"><span data-slate-object="text" data-key="934"><span data-slate-leaf="true" data-offset-key="934:0" data-first-offset="true"><span data-slate-string="true">ResNet</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="935"><span data-slate-object="text" data-key="936"><span data-slate-leaf="true" data-offset-key="936:0" data-first-offset="true"><span data-slate-string="true">ResNet 中文意思是残差神经网络。在 2015 年的 ImageNet 比赛中，模型的分类能力首次超越人眼，1000 类图片 top-5 的错误率降低到 3.57%。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="937"><span data-slate-object="text" data-key="938"><span data-slate-leaf="true" data-offset-key="938:0" data-first-offset="true"><span data-slate-string="true">在</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="939"><span data-slate-object="text" data-key="940"><span data-slate-leaf="true" data-offset-key="940:0" data-first-offset="true"><span data-slate-string="true">论文</span></span></span></a><span data-slate-object="text" data-key="941"><span data-slate-leaf="true" data-offset-key="941:0" data-first-offset="true"><span data-slate-string="true">中作者给出了 18 层、34 层、50 层、101 层与 152 层的 ResNet。101 层的与 152 层的残差神经网络效果最好，但是受硬件设备以及推断时间的限制，50 层的残差神经网络在实际项目中更为常用。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="942"><span data-slate-object="text" data-key="943"><span data-slate-leaf="true" data-offset-key="943:0" data-first-offset="true"><span data-slate-string="true">具体的网络结构你感兴趣的话可以自己看看论文全文，这里我着重带你看看这个网络的主要突破点。</span></span></span></div><h4 data-slate-type="heading" data-slate-object="block" data-key="944" id="sr-toc-9"><span data-slate-object="text" data-key="945"><span data-slate-leaf="true" data-offset-key="945:0" data-first-offset="true"><span data-slate-string="true">网络退化问题</span></span></span></h4><div data-slate-type="paragraph" data-slate-object="block" data-key="946"><span data-slate-object="text" data-key="947"><span data-slate-leaf="true" data-offset-key="947:0" data-first-offset="true"><span data-slate-string="true">虽说研究已经证明，随着网络深度的不断增加，网络的整体性能也会提升。如果只是单纯的增加网络，就会引起以下两个问题：第一，模型容易过拟合；第二，产生梯度消失、梯度爆炸的问题。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="948"><span data-slate-object="text" data-key="949"><span data-slate-leaf="true" data-offset-key="949:0" data-first-offset="true"><span data-slate-string="true">虽然随着研究的不断发展，以上两个问题都可以被解决掉，但是 ResNet 网络的作者发现，以上两个问题被规避之后，简单的堆叠卷积层，依然不能获得很好的效果。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="950"><span data-slate-object="text" data-key="951"><span data-slate-leaf="true" data-offset-key="951:0" data-first-offset="true"><span data-slate-string="true">为了验证刚才的观点，作者做了这样的一个实验。通过搭建一个普通的 20 层卷积神经网络与一个 56 层的卷积神经网络，在 CIFAR-10 数据集上进行了验证。无论训练集误差还是测试集误差，56 层的网络均高于 20 层的网络。下图来源于论文。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="952"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/85/75/8503d95991270ea2d4a3ff80622af375.png?wh=2784x966"></div><div>图片来源：https://arxiv.org/abs/1512.03385</div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="953"><span data-slate-object="text" data-key="954"><span data-slate-leaf="true" data-offset-key="954:0" data-first-offset="true"><span data-slate-string="true">出现这样的情况，作者认为这是网络退化造成的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="955"><span data-slate-object="text" data-key="956"><span data-slate-leaf="true" data-offset-key="956:0" data-first-offset="true"><span data-slate-string="true">网络退化是指当一个网络可以开始收敛时，随着网络层数的增加，网络的精度逐渐达到饱和，并且会迅速降低。这里精度降低的原因并不是过拟合造成的，因为如果是过拟合，上图中 56 层的在训练集上的精度应该高于 20 层的精度。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="957"><span data-slate-object="text" data-key="958"><span data-slate-leaf="true" data-offset-key="958:0" data-first-offset="true"><span data-slate-string="true">作者认为这一现象并不合理，假设 20 层是一个最优的网络，通过加深到 56 层之后，理论上后面的 36 层是可以通过学习到一个恒等映射的，也就是说理论上不会学习到一个比 26 层还差的网络。所以，作者猜测网络不能很容易地学习到恒等映射 (恒等映射就是 f (x)=x)。</span></span></span></div><h4 data-slate-type="heading" data-slate-object="block" data-key="959" id="sr-toc-10"><span data-slate-object="text" data-key="960"><span data-slate-leaf="true" data-offset-key="960:0" data-first-offset="true"><span data-slate-string="true">残差学习</span></span></span></h4><div data-slate-type="paragraph" data-slate-object="block" data-key="961"><span data-slate-object="text" data-key="962"><span data-slate-leaf="true" data-offset-key="962:0" data-first-offset="true"><span data-slate-string="true">正如刚才所说，从网络退化问题中可以发现，通过简单堆叠卷积层似乎很难学会到恒等映射。为了改善网络退化问题，论文作者何凯明提出了一种深度残差学习的框架。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="963"><span data-slate-object="text" data-key="964"><span data-slate-leaf="true" data-offset-key="964:0" data-first-offset="true"><span data-slate-string="true">因为网络不容易学习到恒等映射，所以就让它强制添加一个恒等映射，如下图所示（下图来源于论文）。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="965"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/27/3b/27c8c4a22782ab29e77c36d0131f5e3b.png?wh=2034x806"></div><div>图片来源：https://arxiv.org/abs/1512.03385</div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="966"><span data-slate-object="text" data-key="967"><span data-slate-leaf="true" data-offset-key="967:0" data-first-offset="true"><span data-slate-string="true">具体实现是通过一种叫做 shortcut connection 的机制来完成的。在残差神经网络中 shortcut connection 就是恒等变换，就是上图中带有 x identity 的那条曲线，包含 shortcut connection 的几层网络我们称之为残差块。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="968"><span data-slate-object="text" data-key="969"><span data-slate-leaf="true" data-offset-key="969:0" data-first-offset="true"><span data-slate-string="true">残差块被定义为如下形式：</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="970"><span><span><span aria-hidden="true"><span><span></span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>F</span><span>(</span><span>x</span><span>,</span><span></span><span><span>W</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>+</span><span></span></span><span><span></span><span>x</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="972"><span data-slate-object="text" data-key="973"><span data-slate-leaf="true" data-offset-key="973:0" data-first-offset="true"><span data-slate-string="true">F 可以是 2 层的卷积层。也可以是 3 层的卷积层。最后作者发现，通过残差块，就可以训练出更深、更加优秀的卷积神经网络了。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="974" id="sr-toc-11"><span data-slate-object="text" data-key="975"><span data-slate-leaf="true" data-offset-key="975:0" data-first-offset="true"><span data-slate-string="true">小结</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="976"><span data-slate-object="text" data-key="977"><span data-slate-leaf="true" data-offset-key="977:0" data-first-offset="true"><span data-slate-string="true">恭喜你完成了这节课的学习，让我们回顾一下这节课的主要内容。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="978"><span data-slate-object="text" data-key="979"><span data-slate-leaf="true" data-offset-key="979:0" data-first-offset="true"><span data-slate-string="true">首先我们从多层感知机说起，带你认识了这个卷积神经网络的前身。之后我们一起推导出了图像分类原理的基础模型。</span></span></span><span data-slate-object="text" data-key="980"><span data-slate-leaf="true" data-offset-key="980:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">你需要注意的是，整个模型或者网络的重点全都在卷积神经网络那块，所以这也是我们的工作重点</span></span></span></span><span data-slate-object="text" data-key="981"><span data-slate-leaf="true" data-offset-key="981:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="982"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/8b/1a/8bbc16d51yydca581cb1d88274ec161a.png?wh=1728x664"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="983"><span data-slate-object="text" data-key="984"><span data-slate-leaf="true" data-offset-key="984:0" data-first-offset="true"><span data-slate-string="true">之后我们结合业界标杆 ImageNet 的评选情况，一起学习了一些经典的网络结构：VGG、GoogLeNet、ResNet。这里为了让你快速抓住重点，我是从每个网络解决了什么问题，各自有什么突破点展开的。也建议你课余时间多读读相关论文，做更为详细深入的了解。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="985"><span data-slate-object="text" data-key="986"><span data-slate-leaf="true" data-offset-key="986:0" data-first-offset="true"><span data-slate-string="true">纵观网络结构的发展，我们不难发现，一直都是长江后浪推前浪，一代更比一代强。掌握了这些网络结构，你就是深度学习未来的弄潮儿。下节课我们再一起实践一个图像分类项目，加深你对图像分类的理解，敬请期待。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="987" id="sr-toc-12"><span data-slate-object="text" data-key="988"><span data-slate-leaf="true" data-offset-key="988:0" data-first-offset="true"><span data-slate-string="true">思考题</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="989"><span data-slate-object="text" data-key="990"><span data-slate-leaf="true" data-offset-key="990:0" data-first-offset="true"><span data-slate-string="true">欢迎推荐一下近几年来，你自己觉得比较不错的神经网络模型。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="991"><span data-slate-object="text" data-key="992"><span data-slate-leaf="true" data-offset-key="992:0" data-first-offset="true"><span data-slate-string="true">欢迎你在留言区跟我交流互动，也推荐你把这节课分享给更多的同事、朋友。</span></span></span></div></div></div></div><div><div></div><div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><textarea placeholder="将学到的知识总结成笔记，方便日后快速查找及复习"></textarea></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div><div><div>确认放弃笔记？</div><div>放弃后所记笔记将不保留。</div></div><div><div>新功能上线，你的历史笔记已初始化为私密笔记，是否一键批量公开？</div><div>批量公开的笔记不会为你同步至部落</div></div><div></div></div><div><div><div>公开</div><div>同步至部落</div></div><div>取消</div><div>完成</div></div><div><span>0/2000</span></div></div><div><div><span>划线</span></div><div></div><div></div><div></div><div><span>笔记</span></div><div></div><div><span>复制</span></div></div></div><div><div><div><span></span></div><p><a href="javascript:void(0);">给文章提建议</a></p></div></div><div><span>©</span> 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 </div></div><div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,/9j/4QAYRXhpZgAASUkqAAgAAAAAAAAAAAAAAP/sABFEdWNreQABAAQAAABkAAD/4QN5aHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLwA8P3hwYWNrZXQgYmVnaW49Iu+7vyIgaWQ9Ilc1TTBNcENlaGlIenJlU3pOVGN6a2M5ZCI/PiA8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIiB4OnhtcHRrPSJBZG9iZSBYTVAgQ29yZSA1LjYtYzE0MCA3OS4xNjA0NTEsIDIwMTcvMDUvMDYtMDE6MDg6MjEgICAgICAgICI+IDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+IDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiIHhtbG5zOnhtcE1NPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvbW0vIiB4bWxuczpzdFJlZj0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL3NUeXBlL1Jlc291cmNlUmVmIyIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bXBNTTpPcmlnaW5hbERvY3VtZW50SUQ9InhtcC5kaWQ6YWE3YmZhMDItMzBhMC00MDg3LTg3MmYtOGMwMjMxNjNhZWRjIiB4bXBNTTpEb2N1bWVudElEPSJ4bXAuZGlkOjI2MTlEODM3NTgzMTExRTk5NDY4Qjk3QUFCNDFBN0QzIiB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOjI2MTlEODM2NTgzMTExRTk5NDY4Qjk3QUFCNDFBN0QzIiB4bXA6Q3JlYXRvclRvb2w9IkFkb2JlIFBob3Rvc2hvcCBDQyAyMDE1IChNYWNpbnRvc2gpIj4gPHhtcE1NOkRlcml2ZWRGcm9tIHN0UmVmOmluc3RhbmNlSUQ9InhtcC5paWQ6OTYyRTNCMDNBREI4MTFFOEFFNTJDODlGREQ1OTUzMDMiIHN0UmVmOmRvY3VtZW50SUQ9InhtcC5kaWQ6OTYyRTNCMDRBREI4MTFFOEFFNTJDODlGREQ1OTUzMDMiLz4gPC9yZGY6RGVzY3JpcHRpb24+IDwvcmRmOlJERj4gPC94OnhtcG1ldGE+IDw/eHBhY2tldCBlbmQ9InIiPz7/7gAOQWRvYmUAZMAAAAAB/9sAhAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAgICAgICAgICAgIDAwMDAwMDAwMDAQEBAQEBAQIBAQICAgECAgMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwP/wAARCADuAO4DAREAAhEBAxEB/8QAfAABAAICAwEBAAAAAAAAAAAAAAYHBAgBAwUCCgEBAAAAAAAAAAAAAAAAAAAAABAAAgIBAgIECwQJBQAAAAAAAAECAwQRBSEGMWESF0FRgVITk+MUVJTUIkJiB5EyhBVFhbXFNnFygqJTEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwD9vAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGHmbhg7fD0mbl4+LF69l32wrctPBCMmpTfUk2BG7ue+Wqm4rNsua6XTi5DWvVKyutPyaoDmnnrlq19l506W9NPTYuSk2/xQqnGPlaQElxM7Dzq/S4WVj5VfhlRbC1Rfil2G3GXU9GBlAAAAAAAAAAAAAAAAAAAAAAAAAAAA4bUU5SajGKblJtJJJattvgkkBVHMnP8AJSswtilHSLcLdxcVLV9DWHCWsdF/6ST1+6uiQFW35F+VbK/Jutvum9Z23WSssk/xTm3JgdIADvx8nIxLY34t9uPdD9W2myVc1412otPR6cV0MC1uWufvTTrwd8cITlpCrcYpQhKT4KOXBaQrbf346R8aXFgWmnrxXFPimvCAAAAAAAAAAAAAAAAAAAAAAAAAAFUfmBzHKLexYVjjrGMtxsg+LU12oYia6E4tSn400vOQFTAAAAAAAuDkDmSWRFbHm2OVtUHLb7ZvWU6oLWeK2+LdMV2ofgTX3UBaAAAAAAAAAAAAAAAAAAAAAAAABi52XDAwsvNs4wxce6+S10cvRQlNQX4ptaLrYGr+RfblX3ZN8nO7Itsutk/vWWSc5Pq4sDpAAAAAABlYWXbgZeNmUPS3Guruhx0TcJJ9mWnTGa4NeFMDaDGvrysejJqeteRTVfW/HC2EbI/9ZAdwAAAAAAAAAAAAAAAAAAAAAACJc8WurlncOzwdrxateqeVT2v0wTXlA18AAAAAAAAAbFcnXSu5a2mcnq402U/8cfJuoivJGtASYAAAAAAAAAAAAAAAAAAAAAABFOdqXdyzuSjxlWse7yVZVMp/or1YGvQAAAAAAAADY3lGiWPy3tNclo5Yzv8AF9nJusyYvyxtQEjAAAAAAAAAAAAAAAAAAAAAAAdGVj15eNkYty1qyaLaLF4exbCVctOvSXADWDNxLsDLycLIj2bsa6dM/E3B6KUfHCa0afhTAxQAAAAAAZ224Nu55+LgUp+kyboV6pa9iDetljXm1VpyfUgNnqaoUU1UVLs101wqrj4oVxUILyRQHYAAAAAAAAAAAAAAAAAAAAAAAAVrz5yzPNh++cGtzyaK1HNpgtZX0QX2bopcZW0R4NdLhp5ujCmQAAAAAAXbyLyzPbaXumdW4ZuVX2aKprSWNjS0bck+Mbr9FqumMeHS2gLDAAAAAAAAAAAAAAAAAAAAAAAAAACuOZOQ6c+dmbtDrxcubc7cWX2cbIm+LlW0n7vbLw8OxJ+bxbCpM7bM/bLXVn4l+NPVpekg1CenhrsWtdseuLaAwQAHo7ftO47raqsDEuyZapSlCOlVevhtul2aql/uaAt3lrkWjbJ15u5yry86Gk6qYrXFxpripfaSd90X0NpRi+hNpSAsIAAAAAAAAAAAAAAAAAAAAAAAAAAAAD4sqrug67a4W1y/WhZCM4P/AFjJNMDw7eVuXrm5T2jCTfT6Kr0C49VLrQHNPK/L1ElKvaMJtcU7alfo/Gle7FqB7cK4VQVdcIVwitIwhFQhFeJRikkgPsAAAAAAAAAAAAAAAAAAAAAAAAAY2XmYuBRPKzL68aiv9ay2XZjq+iKXTKcvBFJt+BARGf5g8uRk4q3LsSeinDFkoy60pyhPR9aQHz3h8u+dm/K+0Ad4fLvnZvyvtAHeHy752b8r7QB3h8u+dm/K+0Ad4fLvnZvyvtAHeHy752b8r7QB3h8u+dm/K+0Ad4fLvnZvyvtAMjG575cybY1PKtxnJpRnk0Trq1fglZHtxrXXLRLxgTCMozjGUZKUZJSjKLTjKLWqlFrVNNPgwOQAAAAAAAAAAAAAAAAAAAAUZ+YW43ZG9ywHOSx9vqpUa9fsu7IphkTta8MnCyMepLrYECAAAAAAAAAAAF0/lxuN2Tt+Zg2zlOO320uhyerhTlK1qpPzYWUSa8Xa06NALHAAAAAAAAAAAAAAAAAAAABr3zx/lO6fsX9OxAImAAAAAAAAAAALY/K/+Ofyz+4AWwAAAAAAAAAAAAAAAAAAAADXvnj/ACndP2L+nYgETAAAAAAAAAAAFsflf/HP5Z/cALYAAAAAAAAAAAAAAAAAAAABVvMfJG7bxvOZuONkbdCjI937Eb7cmNq9DiUUS7Ua8S2C1nU2tJPgB4fdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAHdrvvxe0+vzPoAJvyby1ncvfvH323Et989z9F7rZdPs+7+9dvt+loo019OtNNfD0ATcAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//Z"></div><div>Geek__653581f21177</div></div><div><textarea placeholder="由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。" rows="16"></textarea></div><div><div>Ctrl + Enter 发表</div><div>0/2000 字符</div><div>提交留言</div></div></div><div><h2 id="sr-toc-13">精选留言 (13)</h2><ul><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/d2/d7/7f00bea1.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Hit 黎明分明🎩</span></div></div><div>老师 文中提到了 TOP-5 错误率  我在文章中也看到过  不过一直不理解是什么意思，想请教您</div><div><p>作者回复: hello，ImageNet 一共 1000 个类别，所以模型对每张图片都会有 1000 个概率。
Top-1 错误率是指如果预测的 1000 个概率中最大的概率对应的类别是正确的类别，那么就算模型预测正确。
Top-5 错误率是指如果预测的 1000 个概率中前 5 大概率对应的类别包含正确的类别，那么就算模型预测正确。</p></div><div><div>2021-12-05</div><div><div><i></i></div><div><i></i><span>4</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/cd/b7/6efa2c68.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 李雄</span></div></div><div>老师关于 VGG，GoogLeNet，以及 ResNet 的讲解简洁明了，尤其是 ResNet 的讲解，喜欢。</div><div><p>作者回复: hello，感谢你的认可 ^^。很高兴能与你一起学习进步。</p></div><div><div>2021-11-27</div><div><div><i></i></div><div><i></i><span>4</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132"></div></div><div><div><div><span>vcjmhg</span></div></div><div>语义分割领域的一些新网络：
1. Gan 网络
2. Wide ResNet
3. ResNeXT
4. DenseNet
...</div><div><div>2021-11-20</div><div><div><i></i><span></span></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/19/e3/d7/d7b3505f.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 官</span></div></div><div>NLP 领域的话就是 transformer,bert</div><div><p>作者回复: ^^ 👍🏻👍🏻</p></div><div><div>2021-11-20</div><div><div><i></i></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="http://thirdwx.qlogo.cn/mmopen/uqaRIfRCAhJ6t1z92XYEzadRGelHJUZ5mXrausmIK72hVYYYFeQaOWmhmWt3e5863fOavRcibM5mREpObRUT0gH94QcnWoaYq/132"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span> 坚持</span></div></div><div>GoogLeNet 网络结构明细表解析如下：
0、输入
原始输入图像为 224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。
1、第一层（卷积层）
使用 7x7 的卷积核（滑动步长 2，padding 为 3），64 通道，输出为 112x112x64，卷积后进行 ReLU 操作
经过 3x3 的 max pooling（步长为 2），输出为 ((112 - 3+1)/2)+1=56，即 56x56x64，再进行 ReLU 操作
2、第二层（卷积层）
使用 3x3 的卷积核（滑动步长为 1，padding 为 1），192 通道，输出为 56x56x192，卷积后进行 ReLU 操作
经过 3x3 的 max pooling（步长为 2），输出为 ((56 - 3+1)/2)+1=28，即 28x28x192，再进行 ReLU 操作
----------------- 问题 --------------
请问老师，输入通道是 RGB 3 个通道是吧，那第一层的输入 64 个通道，第二层的输出 192 个通道，中间的这些通道和输入通道之间是什么样的关系？这 64 和 192 在网络中怎么理解</div><div><p>作者回复：你好，坚持，感谢你的留言。
输入是 RGB3 个通道的特征图，
第一层（卷积层）有 64 个通道（这里说的不是很严谨，写成卷积核更好，我稍后改一下），也就是有 64 个卷积核，每个卷积核有三个通道。
这样与输入特征进行卷积之后，输出的特征图就有 64 个通道了。
第二层卷积层，有 192 个卷积核，每个卷积核有 64 个通道，与第一层卷积层输出的特征图进行卷积后，就会生成一个 192 个通道的特征图。</p></div><div><div>2022-04-27</div><div><div><i></i><span>2</span></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ0F94uoYZQicSOIfEfSr9gH7CTKibNBsS6d9PRDd8cy7bdTCF9jibXYtf0esGqsQAItHnElejIFovxg/132"></div></div><div><div><div><span>cab</span></div></div><div>Make VGG Great Again</div><div><div>2021-11-19</div><div><div><i></i><span></span></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div></div><div><div><div><span>qifeng.wang</span></div></div><div>请问一下老师，输入 X 转换成 x1,x2,x3 .......xn 小 x1 是指的什么？我理解 X 是指一个三轴的三维数组。</div><div><p>作者回复：你好，感谢你的留言。小 x 就是输入 X 中的元素。如果 X 是 RGB 图片的话，X 是一个三轴的数组。</p></div><div><div>2022-09-01</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>John (易筋)</span></div></div><div>1. 大力出奇迹的自然语言模型 GPT3, BERT, Big Bird
2. 根据碱基生成 3D 蛋白质的 Alpha folder2, 
3. 生成代码模型 Alpha coder, Code Pilot, </div><div><div>2022-08-09</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/16/49/22/f42961fa.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>志翔 (Mike)</span><span><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/89/43/89yyff4c4c2e2b73ce4931bb01a6a943.png"></div></span></div></div><div>1x1 卷积会降维 不明白 老师可以讲一下吗？谢谢</div><div><p>作者回复：你好，Mike，感谢你的留言。
首先这里的维度是指特征的通道数。
举个例子，
降维就是输入特征图从 3 个通道降低为 1 个通道。升维则相反。

当输入特征有 1 个通道，输出特征也有一个通道的时候，1x1 卷积就没有意义，因为就相当于乘了一个常数。
当输入特征有大于 1 个通道的时候，1x1 就相当于对同一个位置上的像素在不同通道上做线性组合，从而控制特征的通道数，完成升维和降维</p></div><div><div>2022-04-24</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/d2/d7/7f00bea1.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Hit 黎明分明🎩</span></div></div><div>YOLO  LSTM </div><div><div>2021-12-03</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/e3/1a/3a7a2511.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>你自信点会死啊</span></div></div><div>老师好，我想问下接受任意尺度输入那里，最后输出的一层卷积的输出是一定要 n 个特征图，然后每个特征图求全局平均，因为全连接层的输入特征个数是 n？是这个意思吗？</div><div><p>作者回复：你好，感谢你的留言。
恩，是这样的。^^</p></div><div><div>2021-12-02</div><div><div><i></i><span>2</span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/28/8a/74/fe20e4aa.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>F</span></div></div><div>我只知道实验室他们在弄啥胶囊模型</div><div><p>作者回复: ^^ 👍🏻👍🏻，加油</p></div><div><div>2021-11-24</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/d1/0e/c0554a72.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>悠闲不自得</span></div></div><div>YOLOV4 </div><div><p>作者回复: 👍🏻👍🏻^^</p></div><div><div>2021-11-20</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li></ul><div> 收起评论<span></span></div></div></sr-rd-content>
                            <toc-bg><toc style="width: initial;overflow: auto!important;"class="simpread-font simpread-theme-root" data-reactid=".4"><outline class="toc-level-h1" data-reactid=".4.0" style="width: 175px;"><active data-reactid=".4.0.0" ></active><a class="toc-outline-theme-github" href="#sr-toc-0" data-reactid=".4.0.1"><span data-reactid=".4.0.1.0">17 | 图像分类（上）：图像分类原理与图像分类模型</span></a></outline><outline class="toc-level-h2" data-reactid=".4.1" style="width: 165px;"><active data-reactid=".4.1.0"></active><a class="toc-outline-theme-github" href="#sr-toc-1" data-reactid=".4.1.1"><span data-reactid=".4.1.1.0">图像分类原理</span></a></outline><outline class="toc-level-h3" data-reactid=".4.2" style="width: 155px;"><active data-reactid=".4.2.0"></active><a class="toc-outline-theme-github" href="#sr-toc-2" data-reactid=".4.2.1"><span data-reactid=".4.2.1.0">感知机</span></a></outline><outline class="toc-level-h3" data-reactid=".4.3" style="width: 155px;"><active data-reactid=".4.3.0"></active><a class="toc-outline-theme-github" href="#sr-toc-3" data-reactid=".4.3.1"><span data-reactid=".4.3.1.0">全连接层</span></a></outline><outline class="toc-level-h2" data-reactid=".4.4" style="width: 165px;"><active data-reactid=".4.4.0"></active><a class="toc-outline-theme-github" href="#sr-toc-4" data-reactid=".4.4.1"><span data-reactid=".4.4.1.0">卷积神经网络</span></a></outline><outline class="toc-level-h3" data-reactid=".4.5" style="width: 155px;"><active data-reactid=".4.5.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-5" data-reactid=".4.5.1"><span data-reactid=".4.5.1.0">ImageNet</span></a></outline><outline class="toc-level-h3" data-reactid=".4.6" style="width: 155px;"><active data-reactid=".4.6.0"></active><a class="toc-outline-theme-github" href="#sr-toc-6" data-reactid=".4.6.1"><span data-reactid=".4.6.1.0">VGG</span></a></outline><outline class="toc-level-h3" data-reactid=".4.7" style="width: 155px;"><active data-reactid=".4.7.0"></active><a class="toc-outline-theme-github" href="#sr-toc-7" data-reactid=".4.7.1"><span data-reactid=".4.7.1.0">GoogLeNet</span></a></outline><outline class="toc-level-h3" data-reactid=".4.8" style="width: 155px;"><active data-reactid=".4.8.0"></active><a class="toc-outline-theme-github" href="#sr-toc-8" data-reactid=".4.8.1"><span data-reactid=".4.8.1.0">ResNet</span></a></outline><outline class="toc-level-h4" data-reactid=".4.9" style="width: 145px;"><active data-reactid=".4.9.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-9" data-reactid=".4.9.1"><span data-reactid=".4.9.1.0">网络退化问题</span></a></outline><outline class="toc-level-h4" data-reactid=".4.a" style="width: 145px;"><active data-reactid=".4.a.0"></active><a class="toc-outline-theme-github" href="#sr-toc-10" data-reactid=".4.a.1"><span data-reactid=".4.a.1.0">残差学习</span></a></outline><outline class="toc-level-h2" data-reactid=".4.b" style="width: 165px;"><active data-reactid=".4.b.0"></active><a class="toc-outline-theme-github" href="#sr-toc-11" data-reactid=".4.b.1"><span data-reactid=".4.b.1.0">小结</span></a></outline><outline class="toc-level-h2" data-reactid=".4.c" style="width: 165px;"><active data-reactid=".4.c.0"></active><a class="toc-outline-theme-github" href="#sr-toc-12" data-reactid=".4.c.1"><span data-reactid=".4.c.1.0">思考题</span></a></outline><outline class="toc-level-h2" data-reactid=".4.d" style="width: 165px;"><active data-reactid=".4.d.0"></active><a class="toc-outline-theme-github" href="#sr-toc-13" data-reactid=".4.d.1"><span data-reactid=".4.d.1.0">精选留言 (13)</span></a></outline></toc></toc-bg>
                            <sr-rd-footer>
                                <sr-rd-footer-group>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                </sr-rd-footer-group>
                                <sr-rd-footer-copywrite>
                                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://time.geekbang.org/column/article/446645" target="_blank">原文地址 </a></div>
                                </sr-rd-footer-copywrite>
                            </sr-rd-footer>
                        </sr-read>
                    </body>
                </html>