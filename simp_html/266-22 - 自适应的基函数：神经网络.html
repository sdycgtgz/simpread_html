
                <html lang="en" class="simpread-font simpread-theme-root" style=''>
                    <head>
                        <meta charset="utf-8">
                        <meta http-equiv="content-type" content="text/html; charset=UTF-8;charset=utf-8">
                        <meta http-equiv="X-UA-Compatible" content="IE=Edge">
                        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
                        <meta name="author" content="Kenshin"/>
                        <meta name="description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展" />
                        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, 简悦, 简阅, read mode, reading mode, reader view, firefox, firefox addon, userscript, safari, opera, tampermonkey"/>
                        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:title" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <meta property="og:type" content="website">
                        <meta property="og:local" content="zh_CN"/>
                        <meta property="og:url" content="http://ksria.com/simpread"/>
                        <meta property="og:image" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:image:type" content="image/png"/>
                        <meta property="og:image:width" content="960"/>
                        <meta property="og:image:height" content="355"/>
                        <meta property="og:site_name" content="http://ksria.com/simpread"/>
                        <meta property="og:description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <style type="text/css">.simpread-font{font:300 16px/1.8 -apple-system,PingFang SC,Microsoft Yahei,Lantinghei SC,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#333;text-rendering:optimizelegibility;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased}.simpread-hidden{display:none}.simpread-read-root{display:-webkit-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;margin:0;top:-1000px;left:0;width:100%;z-index:2147483646;overflow-x:hidden;opacity:0;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}.simpread-read-root-show{top:0}.simpread-read-root-hide{top:1000px}sr-read{display:-webkit-flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-flow:column nowrap;flex-flow:column;margin:20px 20%;min-width:400px;min-height:400px;text-align:center}read-process{position:fixed;top:0;left:0;height:3px;width:100%;background-color:#64b5f6;-webkit-transition:width 2s;transition:width 2s;z-index:20000}sr-rd-content-error{display:block;position:relative;margin:0;margin-bottom:30px;padding:25px;background-color:rgba(0,0,0,.05)}sr-rd-footer{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column;font-size:14px}sr-rd-footer,sr-rd-footer-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}sr-rd-footer-group{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-rd-footer-line{width:100%;border-top:1px solid #e0e0e0}sr-rd-footer-text{min-width:150px}sr-rd-footer-copywrite{margin:10px 0 0;color:inherit}sr-rd-footer-copywrite abbr{-webkit-font-feature-settings:normal;font-feature-settings:normal;font-variant:normal;text-decoration:none}sr-rd-footer-copywrite .second{margin:10px 0}sr-rd-footer-copywrite .third a:hover{border:none!important}sr-rd-footer-copywrite .third a:first-child{margin-right:50px}sr-rd-footer-copywrite .sr-icon{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:33px;height:33px;opacity:.8;-webkit-transition:opacity .5s ease;transition:opacity .5s ease;cursor:pointer}sr-rd-footer-copywrite .sr-icon:hover{opacity:1}sr-rd-footer-copywrite a,sr-rd-footer-copywrite a:link,sr-rd-footer-copywrite a:visited{margin:0;padding:0;color:inherit;background-color:transparent;font-size:inherit!important;line-height:normal;text-decoration:none;vertical-align:baseline;vertical-align:initial;border:none!important;box-sizing:border-box}sr-rd-footer-copywrite a:focus,sr-rd-footer-copywrite a:hover,sr-rd-footer a:active{color:inherit;text-decoration:none;border-bottom:1px dotted!important}.simpread-blocks{text-decoration:none!important}.simpread-blocks *{margin:0}.simpread-blocks a{padding:0;text-decoration:none!important}.simpread-blocks img{margin:0;padding:0;border:0;background:transparent;box-shadow:none}.simpread-focus-root{display:block;position:fixed;top:0;left:0;right:0;bottom:0;background-color:hsla(0,0%,92%,.9);z-index:2147483645;opacity:0;-webkit-transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms;transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms}.simpread-focus-highlight{position:relative;box-shadow:0 0 0 20px #fff;background-color:#fff;overflow:visible;z-index:2147483646}.sr-controlbar-bg sr-rd-crlbar,.sr-controlbar-bg sr-rd-crlbar fab{z-index:2147483647}sr-rd-crlbar.controlbar{position:fixed;right:0;bottom:0;width:100px;height:100%;opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}sr-rd-crlbar.controlbar:hover{opacity:1}sr-rd-crlbar fap *{box-sizing:border-box}@media (max-height:620px){fab{zoom:.8}}@media (max-height:783px){dialog-gp dialog-content{max-height:580px}dialog-gp dialog-footer{border-top:1px solid #e0e0e0}}.simpread-highlight-selector{outline:3px dashed #1976d2!important;cursor:pointer!important}.simpread-highlight-controlbar,.simpread-highlight-selector{background-color:#fafafa!important;opacity:.8!important;-webkit-transition:opacity .5s ease!important;transition:opacity .5s ease!important}.simpread-highlight-controlbar{position:relative!important;border:3px dashed #1976d2!important}simpread-highlight,sr-snapshot-ctlbar{position:fixed;top:0;left:0;right:0;padding:15px;height:50px;background-color:rgba(50,50,50,.9);box-shadow:0 2px 5px rgba(0,0,0,.26);box-sizing:border-box;z-index:2147483640}simpread-highlight,sr-highlight-ctl,sr-snapshot-ctlbar{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-highlight-ctl{margin:0 5px;width:50px;height:20px;color:#fff;background-color:#1976d2;border-radius:4px;box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12);cursor:pointer}toc-bg{position:fixed;left:0;top:0;width:50px;height:200px;font-size:medium}toc-bg:hover{z-index:3}.toc-bg-hidden{opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}.toc-bg-hidden:hover{opacity:1;z-index:3}.toc-bg-hidden:hover toc{width:180px}toc *{all:unset}toc{position:fixed;left:0;top:100px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;padding:10px;width:0;max-width:200px;max-height:500px;overflow-x:hidden;overflow-y:hidden;cursor:pointer;border:1px solid hsla(0,0%,62%,.22);-webkit-transition:width .5s;transition:width .5s}toc:hover{overflow-y:auto}toc.mini:hover{width:200px!important}toc::-webkit-scrollbar{width:3px}toc::-webkit-scrollbar-thumb{border-radius:10px;background-color:hsla(36,2%,54%,.5)}toc outline{position:relative;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;padding:2px 0;min-height:21px;line-height:21px;text-align:left}toc outline a,toc outline a:active,toc outline a:focus,toc outline a:visited{display:block;width:100%;color:inherit;font-size:11px;text-decoration:none!important;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}toc outline a:hover{font-weight:700!important}toc outline a.toc-outline-theme-dark,toc outline a.toc-outline-theme-night{color:#fff!important}.toc-level-h1{padding-left:5px}.toc-level-h2{padding-left:15px}.toc-level-h3{padding-left:25px}.toc-level-h4{padding-left:35px}.toc-outline-active{border-left:2px solid #f44336}toc outline active{position:absolute;left:0;top:0;bottom:0;padding:0 0 0 3px;border-left:2px solid #e8e8e8}sr-kbd{background:-webkit-gradient(linear,0 0,0 100%,from(#fff785),to(#ffc542));border:1px solid #e3be23;-o-border-image:none;border-image:none;-o-border-image:initial;border-image:initial;position:absolute;left:0;padding:1px 3px 0;font-size:11px!important;font-weight:700;box-shadow:0 3px 7px 0 rgba(0,0,0,.3);overflow:hidden;border-radius:3px}.sr-kbd-a{position:relative}kbd-mapping{position:fixed;left:5px;bottom:5px;-ms-flex-flow:row;flex-flow:row;width:250px;height:500px;background-color:#fff;border:1px solid hsla(0,0%,62%,.22);box-shadow:0 2px 5px rgba(0,0,0,.26);border-radius:3px}kbd-mapping,kbd-maps{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}kbd-maps{margin:40px 0 20px;width:100%;overflow-x:auto}kbd-maps::-webkit-scrollbar-thumb{background-clip:padding-box;border-radius:10px;border:2px solid transparent;background-color:rgba(85,85,85,.55)}kbd-maps::-webkit-scrollbar{width:10px;-webkit-transition:width .7s cubic-bezier(.4,0,.2,1);transition:width .7s cubic-bezier(.4,0,.2,1)}kbd-mapping kbd-map-title{position:absolute;margin:5px 0;width:100%;font-size:14px;font-weight:700}kbd-maps-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}kbd-maps-title{margin:5px 0;padding-left:53px;font-size:12px;font-weight:700}kbd-map kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fafbfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}kbd-map kbd-name{display:inline-block;text-align:right;width:50px}kbd-map kbd-desc{padding-left:3px}sharecard-bg{position:fixed;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,.4);z-index:2147483647}sharecard{max-width:450px;background-color:#64b5f6}sharecard,sharecard-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-head{margin:25px;color:#fff;border-radius:10px;box-shadow:0 2px 6px 0 rgba(0,0,0,.2),0 25px 50px 0 rgba(0,0,0,.15)}sharecard-card{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-card,sharecard-top{display:-webkit-box;display:-ms-flexbox;display:flex}sharecard-top{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:65px;background-color:#fff;color:#878787;font-size:25px;font-weight:500;border-top-left-radius:10px;border-top-right-radius:10px}sharecard-top span.logos{display:block;width:48px;height:48px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAMAAABg3Am1AAABU1BMVEUAAAAnNJMnNZI3Q5onNJInNJMnNJInNJMnNJI8SJ0tOZY/S55EUKAoNJI6RpwoNJNIU6InNJInNJImNJI7SJwmNJJ2fLUiMJFKVaNCTJ9faK1HUaJOWKVSXaUnNJNYY6pye7cmM5JXYKhwebMjMI8mL4719fW9vb0oNZP/UlLz8/QqN5TAwMAnNJPv7+/Pz8/q6+/p6enNzc3Kysry8vMsOJXc3env7/LU1uXo29vR0dHOzs7ExMTwjo73bW37XV3Aj1TCYELl5u3n5+fW2Obn6O7f4OrZ2+g0QJkxPpgvO5bh4uvS1OTP0ePCwsJQW6ZLVqTs7fHd3d3V1dXqv79VX6lET6A1TIxXUIBSgHxWQnpelHf+WVnopkXqbC7j5Ozi4uLDw8NGUaFATJ9SgH3r6+vGyd7BxNva2trX19ejqM2gpczHx8dze7Zha67Z2dlTgH1aXQeSAAAAJnRSTlMA6ff+497Y8NL+/fv49P379sqab/BeOiX06tzVy8m/tKqpalA7G6oKj0EAAAJlSURBVEjHndNXWxpBFIDhcS2ICRLAkt4Dx4WhLk0E6R0MYoIISrWX5P9f5cwSIRC2+T1czMV5n2FnZwn2eWONUqCAv3H2Uf5Ra1hx4+0WEXtDQW0fCPYJ1EffEfIV4CSROAE4jsePoTFsNmTJF/IeIHF2lgCIn57GodlqDWXBK7IwBYatVlMWFAildPKX7I3m74Z9fsCiQChoimoFQAz04Ad2gH1n9fv9n9hgMNDr9euLWD6fLxQKxaLfb7dTSlahbFVdEPwIQtrAihZQgyKCtCagbQe3xh0QFMgy5MR11+ewYY5/qlZ7vT2xu93ULKjbFLpiUxnIIwjgKmVTLDUFXMrAi2NJWCRLIthTBo4xyOLKpwyqU6CuDCI41hFBCVdOhyLw4FgJ1skCAiyl9BSHbCorgo6VJXTru5hrVCQS8Yr5xLzX59YJSFpVFwD9U0BGC3hGdFpATgRupTGe9R9I1b1ePBvXKDyvq/O/44LT4/E4BUbSCAwj8Evq6HlnOBprx6JhJz8Gktc7xeaP9ndY+0coQvCccFBD4JW60UIY50ciLOAODAQRVOeCHm4Q3Xks6uRDY+CQ+AR4T2wMYh6+jMCIQOp78CFoj0H7EQgIuhI3dGaHCrwgADwCPjJvA372GRigCJg49FUdk3D87pq3zp4SA5zc1Zh9DxfwkpjgUg5Mv+lbeE3McC8Lpu7SA3wk2xzcqL2tN5DfIsQC8HB7UamUy6FQOpTO5QKBQDZbKnWSyUzGjdWCwaDA8+7Le4BNgm3qQGWchYh9s5hNq6wVbBlbwhZYOp3OYOA4zmgEypnM2zj8ByIdedKrH8vDAAAAAElFTkSuQmCC");zoom:.8}sharecard-content{padding:15px;max-height:500px;font-size:20px;text-align:justify;background-color:#2196f3;overflow-x:hidden;overflow-y:auto}sharecard-via{padding:10px;font-size:10px;background-color:#2196f3}sharecard-footer{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:100px;background-color:#fff;color:#878787;font-size:15px;font-weight:500;border-bottom-left-radius:10px;border-bottom-right-radius:10px}sharecard-footer,sharecard-footer div{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sharecard-footer span.qrcode{display:block;width:100px;height:100px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,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")}sharecard-control{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 19px;height:80px;background-color:#fff}simpread-snapshot{width:100%;height:100%;cursor:move;z-index:2147483645}simpread-snapshot,sr-mask{position:fixed;left:0;top:0}sr-mask{background-color:rgba(0,0,0,.1)}.simpread-feedback,.simpread-urlscheme{position:fixed;right:20px;bottom:20px;z-index:2147483646}simpread-feedback,simpread-urlscheme{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;padding:20px 20px 0;width:500px;color:rgba(51,51,51,.87);background-color:#fff;border-radius:3px;box-shadow:0 0 2px rgba(0,0,0,.12),0 2px 2px rgba(0,0,0,.26);overflow:hidden;-webkit-transform-origin:bottom;transform-origin:bottom;-webkit-transition:all .6s ease;transition:all .6s ease}simpread-feedback *,simpread-urlscheme *{font-size:12px!important;box-sizing:border-box}simpread-feedback.active,simpread-urlscheme.active{-webkit-animation-name:srFadeInUp;animation-name:srFadeInUp;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback.hide,simpread-urlscheme.hide{-webkit-animation-name:srFadeInDown;animation-name:srFadeInDown;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback sr-fb-label,simpread-urlscheme sr-urls-label{width:100%}simpread-feedback sr-fb-head,simpread-urlscheme sr-urls-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:5px;width:100%}simpread-feedback sr-fb-content,simpread-urlscheme sr-urls-content{margin-bottom:5px;width:100%}simpread-feedback sr-urls-footer,simpread-urlscheme sr-urls-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-fb-a,simpread-urlscheme sr-urls-a{color:#2163f7;cursor:pointer}simpread-feedback text-field-state,simpread-urlscheme text-field-state{border-top:none rgba(34,101,247,.8)!important;border-left:none rgba(34,101,247,.8)!important;border-right:none rgba(34,101,247,.8)!important;border-bottom:2px solid rgba(34,101,247,.8)!important}simpread-feedback switch,simpread-urlscheme switch{margin-top:0!important}@-webkit-keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@-webkit-keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}@keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}simpread-feedback sr-fb-head{font-weight:700}simpread-feedback sr-fb-content{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column}simpread-feedback sr-fb-content,simpread-feedback sr-fb-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}simpread-feedback sr-fb-footer{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-close{position:absolute;right:20px;cursor:pointer;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s;z-index:200}simpread-feedback sr-close:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin-top:10px}simpread-feedback sr-stars i{margin-right:10px;cursor:pointer}simpread-feedback sr-stars i svg{-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}simpread-feedback sr-stars i svg:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars i.active svg{-webkit-transform:rotate(0) scale(1);transform:rotate(0) scale(1)}simpread-feedback sr-emojis{display:block;height:100px;overflow:hidden}simpread-feedback sr-emoji{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:.3s;transition:.3s}simpread-feedback sr-emoji>svg{margin:15px 0;width:70px;height:70px;-ms-flex-negative:0;flex-shrink:0}simpread-feedback sr-stars-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin:10px 0 20px}</style>
                        <style type="text/css">.simpread-theme-root{font-size:62.5%!important}sr-rd-content,sr-rd-desc,sr-rd-title{width:100%}sr-rd-title{display:-webkit-box;margin:1em 0 .5em;overflow:hidden;text-overflow:ellipsis;text-rendering:optimizelegibility;-webkit-line-clamp:3;-webkit-box-orient:vertical}sr-rd-content{text-align:left;word-break:break-word}sr-rd-desc{text-align:justify;line-height:2.4;margin:0 0 1.2em;box-sizing:border-box}sr-rd-content{font-size:25.6px;font-size:1.6rem;line-height:1.6}sr-rd-content h1,sr-rd-content h1 *,sr-rd-content h2,sr-rd-content h2 *,sr-rd-content h3,sr-rd-content h3 *,sr-rd-content h4,sr-rd-content h4 *,sr-rd-content h5,sr-rd-content h5 *,sr-rd-content h6,sr-rd-content h6 *{word-break:break-all}sr-rd-content div,sr-rd-content p{display:block;float:inherit;line-height:1.6;font-size:25.6px;font-size:1.6rem}sr-rd-content div,sr-rd-content p,sr-rd-content pre,sr-rd-content sr-blockquote{margin:0 0 1.2em;word-break:break-word}sr-rd-content a{padding:0 5px;vertical-align:baseline;vertical-align:initial}sr-rd-content a,sr-rd-content a:link{color:inherit;font-size:inherit;font-weight:inherit;border:none}sr-rd-content a:hover{background:transparent}sr-rd-content img{margin:10px;padding:5px;max-width:100%;background:#fff;border:1px solid #bbb;box-shadow:1px 1px 3px #d4d4d4}sr-rd-content figcaption{text-align:center;font-size:14px}sr-rd-content sr-blockquote{display:block;position:relative;padding:15px 25px;text-align:left;line-height:inherit}sr-rd-content sr-blockquote:before{position:absolute}sr-rd-content sr-blockquote *{margin:0;font-size:inherit}sr-rd-content table{width:100%;margin:0 0 1.2em;word-break:keep-all;word-break:normal;overflow:auto;border:none}sr-rd-content table td,sr-rd-content table th{border:none}sr-rd-content ul{margin:0 0 1.2em;margin-left:1.3em;padding:0;list-style:disc}sr-rd-content ol{list-style:decimal;margin:0;padding:0}sr-rd-content ol li,sr-rd-content ul li{font-size:inherit;list-style:disc;margin:0 0 1.2em}sr-rd-content ol li{list-style:decimal;margin-left:1.3em}sr-rd-content ol li *,sr-rd-content ul li *{margin:0;text-align:left;text-align:initial}sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em}sr-rd-content li ul{list-style:circle}sr-rd-content pre{font-family:Consolas,Monaco,Andale Mono,Source Code Pro,Liberation Mono,Courier,monospace;display:block;padding:15px;line-height:1.5;word-break:break-all;word-wrap:break-word;white-space:pre;overflow:auto}sr-rd-content pre,sr-rd-content pre *,sr-rd-content pre div{font-size:17.6px;font-size:1.1rem}sr-rd-content li pre code,sr-rd-content p pre code,sr-rd-content pre{background-color:transparent;border:none}sr-rd-content pre code{margin:0;padding:0}sr-rd-content pre code,sr-rd-content pre code *{font-size:17.6px;font-size:1.1rem}sr-rd-content pre p{margin:0;padding:0;color:inherit;font-size:inherit;line-height:inherit}sr-rd-content li code,sr-rd-content p code{margin:0 4px;padding:2px 4px;font-size:17.6px;font-size:1.1rem}sr-rd-content mark{margin:0 5px;padding:2px;background:#fffdd1;border-bottom:1px solid #ffedce}.sr-rd-content-img{width:90%;height:auto}.sr-rd-content-img-load{width:48px;height:48px;margin:0;padding:0;border-style:none;border-width:0;background-repeat:no-repeat;background-image:url(data:image/gif;base64,R0lGODlhMAAwAPcAAAAAABMTExUVFRsbGx0dHSYmJikpKS8vLzAwMDc3Nz4+PkJCQkRERElJSVBQUFdXV1hYWFxcXGNjY2RkZGhoaGxsbHFxcXZ2dnl5eX9/f4GBgYaGhoiIiI6OjpKSkpaWlpubm56enqKioqWlpampqa6urrCwsLe3t7q6ur6+vsHBwcfHx8vLy8zMzNLS0tXV1dnZ2dzc3OHh4eXl5erq6u7u7vLy8vf39/n5+f///wEBAQQEBA4ODhkZGSEhIS0tLTk5OUNDQ0pKSk1NTV9fX2lpaXBwcHd3d35+foKCgoSEhIuLi4yMjJGRkZWVlZ2dnaSkpKysrLOzs7u7u7y8vMPDw8bGxsnJydvb293d3eLi4ubm5uvr6+zs7Pb29gYGBg8PDyAgICcnJzU1NTs7O0ZGRkxMTFRUVFpaWmFhYWVlZWtra21tbXNzc3V1dXh4eIeHh4qKipCQkJSUlJiYmJycnKampqqqqrW1tcTExMrKys7OztPT09fX19jY2Ojo6PPz8/r6+hwcHCUlJTQ0NDg4OEFBQU9PT11dXWBgYGZmZm9vb3Jycnp6en19fYCAgIWFhaurq8DAwMjIyM3NzdHR0dTU1ODg4OTk5Onp6fDw8PX19fv7+xgYGB8fHz8/P0VFRVZWVl5eXmpqanR0dImJiaCgoKenp6+vr9/f3+fn5+3t7fHx8QUFBQgICBYWFioqKlVVVWJiYo+Pj5eXl6ioqLa2trm5udbW1vT09C4uLkdHR1FRUVtbW3x8fJmZmcXFxc/Pz42Njb+/v+/v7/j4+EtLS5qamri4uL29vdDQ0N7e3jIyMpOTk6Ojo7GxscLCwisrK1NTU1lZWW5ubkhISAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH/C05FVFNDQVBFMi4wAwEAAAAh/i1NYWRlIGJ5IEtyYXNpbWlyYSBOZWpjaGV2YSAod3d3LmxvYWRpbmZvLm5ldCkAIfkEAAoA/wAsAAAAADAAMAAABv/AnHBILBqPyKRySXyNSC+mdFqEAAARqpaIux0dVwduq2VJLN7iI3ys0cZkosogIJSKODBAXLzJYjJpcTkuCAIBDTRceg5GNDGAcIM5GwKWHkWMkjk2kDI1k0MzCwEBCTBEeg9cM5AzoUQjAwECF5KaQzWQMYKwNhClBStDjEM4fzGKZCxRRioFpRA2OXlsQrqAvUM300gsCgofr0UWhwMjQhgHBxhjfpCgeDMtLtpCOBYG+g4lvS8JAQZoEHKjRg042GZsylHjBYuHMY7gyHBAn4EDE1ZI8tCAhL1tNLoJsQGDxYoVEJHcOPHAooEEGSLmKKjlWIuHKF/ES0IjxAL/lwxCfFRCwwVKlC4UTomxIYFFaVtKomzBi8yKCetMkKnxEIZIMjdKdBi6ZIYyWAthSZGUVu0RGRsyyJ07V0SoGC3yutCrN40KcIADK6hAlgmLE4hNIF58QlmKBYIDV2g75bBixouVydCAAUOGzp87h6AsBQa9vfTy0uuFA86Y1m5jyyaDQwUJ0kpexMC95AWHBw9YkJlBYoSKs1RmhJDgoIGDDIWN1BZBvUSLr0psmKDgoLuDCSZ4G4FhgrqIESZeFMbBAsOD7g0ifJBxT7wkGyxImB+Bgr7EEA8418ADGrhARAodtKCEDNYRQYNt+wl3RAfNOWBBCr3MkMEEFZxg3YwkLXjQQQg7URPDCSNQN8wRMEggwQjICUECBRNQoIIQKYAAQgpCvOABBx2ksNANLpRQQolFuCBTETBYQOMHaYxwwQV2UVMCkPO1MY4WN3wwwQQWNJPDCJ2hI4QMH3TQQXixsVDBlyNIIiUGZuKopgdihmLDBjVisOWYGFxQJ0MhADkCdnGcQCMFHsZyAQZVDhEikCtOIsMFNXKAHZmQ9kFCBxyAEGNUmFYgIREiTDmoEDCICMKfccQAgghpiRDoqtSkcAKsk7RlK51IiAcLCZ2RMJsWRbkw6rHMFhEEACH5BAAKAP8ALAAAAAAwADAAAAf/gDmCg4SFhoeIiYqLhFhRUViMkpOFEwICE5SahDg4hjgSAQJEh16em4ctRklehkQBAaSFXhMPVaiFVwoGPyeFOK+xp4MkOzoCVLiDL7sGEF2cwbKDW0A6Oj0tyoNOBt5PhUQCwoRL1zpI29QO3gxZhNLDLz7XP1rqg1E/3kmDwLDTcBS5tgMcPkG0vCW4MkjaICoBrgmxgcrFO0NWEnib0OofORtDrvGYcqhTIhcOHIjgYgiJtx9RcuBQEiSIEkFPjOnIZMiGFi3DCiVRQFTClFaDsDDg1UQQDhs2kB4x1uPFrC1ZsrL8tCQIUQVBMLgY9uSBFKSGvEABwoSQFy5Z/7NqgVZqygSvRIU0uSeTrqIuSHF00RI3yxa0iLqIePBVwYMoQSX5LKyF4qQsTIR8NYJYEla5XSIzwnHFSBAGtzZ5IcylsyYvJ564lmz5oO3buAttabKEie/fS5bE3LYFi/Hjx7MgtZKyefMhQzCIpvTiipUr2LNjp8vcuXck0ydVt649O90tTIIrUbKEfXsS4T0jn6+ck0x/8XPr34/Dyon8iRimDhZOFFGBC6hwMcUULfhFCRckGFHEBEUwAeAvLUhxwglUYDFbXRgUMeEEGExxYSFaULHhhlUApQgOLSwh4gQTGCECXyYtMowNL6i44hVcTIcDCRXQOEEFTVg1SPAVT0SSyBZVKClIFy1MIYWGUzhpyBM0FpGEFYhxscQRSKTmiTwkiCBFbTJt4d+GCB6CxRFHROGgTFLQiYQ2OVxBAgkM5ZAFFCKIECgnWVBBBZuFvMBXIVkkcQQGIpwiRXBSOFVFoSRsVYgNd0qCwxMYHJHERTlcykSmgkBYaBUnStICEhhgIMUwly7BqiBXFAoFqurY0ASdS3iaam+75mCDFIWe8KEmVJSKQWqD5JpsDi8QCoWUymwxJgZOMGrtL1QUaqc6WShBJreCjItimlEYi4sWUNxqiLu5WCHvNtPhu98iJ/hG0r+MdGFcqAQTHAgAIfkEAAoA/wAsAAAAADAAMAAACP8AcwgcSLCgwYMIEypcSDALHjxZGEqcWNCNAQNvKGokGCjQQTYX2Ry84XHjQT4a5JQk2CakwRtu1OQxWXCPAwVlqhQMBNJAm5UCoxAIcEAnTYF+bipYU4NjSwNsgP5pEIAon6MD6yjYeqdgzzYF5QgIIAAO1oF/0mxFI4NgT5ED/YypuqDtWYFSFmyVMzDQ06gCA7kZO8DO3YGA2mw1c1Xg24FVxIxFA8hkH7sF9TTY+uZGDr8XweYAhKaqGCoH96BG2CeNmihNOTLZugCFQCYOHDARaGcAWdEEZ2QYIMCoQTlmcrep4nlgljM4RQQGBKi5Bt9j+hAEVAcBgO9ngAb/pnMmt4MzcLQPtMOmiviBN6KU4RuYSoMv3wF8UdN8ZxU35jkQAR0zCHRDZQvVUFIfaoCRHwBk3PEeQTVEoUaAa+AxYUI3xEHAg2HE8cdEM8yBRm5mZNCfRDWQkR8Ya6inEUoOoKGHSXZ88UUDVGzI0A0oSGgSIG/UseJhG/k4kZJIolUHHXQ8CeWUGmIFyB9YZvlHDVuWpMcaa6ihRphgihkHkwr9kcWabLbZ3B5hihnnmGowgWZCM7SpZxYIzkDHHHP8CeigUpzFpZaIirfSnU026ihHexi30QyxHZVFHW9k4IdJNeyhhx8IalSDFHC8YWodjA7Uhx6s7iEDozdU/8HEG26YGoekE/3hKat68FGgQoHwMYeptGogxYiBaXRDFp7mwSqoCAUiRQbEZiBCRAPtIQW2CP2hB2aj+cErq+ASZAexcuwBVA11MJFuXytlgQIezBX0x6qscltQFnDEQUWoA1HBhLvq8YECCurNMC8Km+40wx57HNnQrwXJMMfAUngUSBUiiGBUIHs8REWl2wG8pBRMxDEHZhx7XFINVOCBgrpN9iHHwJK2LGkfD6FA8Vk32DFwHSTrTNANMeOhR6oJ6THwuwQZ3VDP+tL0Bx0D33Gk1H3p8VAVJm8kA9ZyVJ0DFR3jmoPCUox81x94rFYQx3WonYMffIR91IRcPxHKUB522DGT3xIBsqbehCceEAAh+QQACgD/ACwAAAAAMAAwAAAI/wBzCBxIsKDBgwgTKlxI8BIVSZcYSpxIkNMjBQo4UNxYkNNBRxgfHdzkkeNBLB3qlBzIqRFGRwY5OVpEyWRBS4kcPJjU0aUCmAXxIDCggKdNgVkQOXDgSFNFn0AHdkFjgKilowOhLHUgpaBPkQTrVDUwB+vATIuWrsHE8itBLAyqOmBrViCVpYfqEITK8lHVH13rCtz0aCmiqzlahhy4olBVRU45YqFbsBKapZA8KlYAdtOaqoRWHKwkaWVBLG7c4IlMcI6DQw8kCQSxaI0IgSV+VI06EBOHHz9EHwShqDikSaYvKYIdSSAnkiU76GaAheAmKIYECAigyLRzKGuKK/9aMwfLyhKOkCPcJOWBXueS0AgKEECAIEbenU+CFL44IyiZOLcJQ5oMmAMWjAxCn3YMSGEgQprg0Yh4azQyRX4KceIBIdvVR4gHAUqECRSMiNcBhgl1IUSHgzBSHUeWeLAGTSZFIoggaKyAIkObSCLFjgkRJgJrghVpJEeaJaakaV1EIgIUUD4JhQgiUIFVS4dspaUDaCBWSSNugNnImGG6AQKQCnWBgA5stulmczl8KWaYYjZy5lFquqmnDnA2KSWUU05p5VFY4rVllxkeyUlJSaJ5ZF2cWEKJowcVaBYmUngwRxYmbXLJJZk8SJEmVMzBQQcclEApQZlk4eolXVD/tMkkdXRgqwd11MSRJp++egmRCGURiQeocjCHJLEmtqpzXVziahagiloQFR5wcKoHUkQ0EBZUUFbpZBVh8iy0yRqEx6kdQIHYQJpIIUIk6yopECaUTFKJtJuI62q5BWECAgiTAJsDJYBymkMWK6xgcBf1UqJtRbxesiOoB2XipAilCUQJHnjoeuAk9krr3LIsSUJlJCHGybHHmtQ7yYtFXjKlCB6r3HFDIFPCL1ab4EGlFERujEcl1lUCcrxYWRIo0pWs3C/Ik3hrUxclUHlhZU5XhEW995qVSdWRPDyQ0EQX1AXIlQjMUSYrGFUQ2Qc5KzKho3Fc9qMTNY0H0ngrCrRJJqH2LXhCAQEAIfkEAAoA/wAsAAAAADAAMAAACP8AcwgcSLCgwYMIEypcSFBVlTyqGEqcSJBTBwdmPFDcWJDTwVIOHHQ4yMkjx4Op6pwySXBDyFIGvZTS8OJkQRikFFXY0xGkA5gFpxj6ZIaPzYGXcioqxaqiS5EFVyn6ZCgUjKMDTShSNGpKQZ9AB5r6RLYO1oGrNGx1FFEgJ58jB6ZyQFYRjbMDq4zaGokgSDMdTFokC8orXoFePGy1cDUHp6dxc7BoQPZNU46p2hZ8YWHrBy8C4SK2QLYBT4MvWLAsmGpDqRSXB3IytXcUC4GR3rzpm8OEoaEaC9L4QPb2wVO633jYs1rVG50m3HopKbAOqE+hUhFkhcqBge8VVrv/NeEouSNTqVie6MBHvOwqFXg7zqPowHcDCRy5d8znQ/I3GqByl2OgLTSdQKloUMh9BoRyQoEIsVJFB/+Vksd+CXFShyEMGlLHKhPRYIIGydWBIUKriHJfAhpoh5kpjtB0EioHHKCIakd5sceFJ7HSASoQHibkkBx5ZKRjSKJ1gglLMumkCcbZ5MUGolRppZWKNAZDBx2UUkqXXX4ZyYkLsQJKAGimKQCaAqAi0JZfesllmPKdtIoha66ZJptu5rDKFCYw2WSgJ+SB1WNXJpqlQmRuZOSjbhEpqUGcpFJTj2/UEdtJNFRxyimaUWTKF1+YkUKjBrGyRySmtJoCR6t8/wLArAGMcilDXrxgwimtnmLCrRPJ5Mmss3pSyoAIcXLJFLzyGgkLsaFK0AuK8EAsAIVEEiRBe/DaaxXI5pAKC+HGpEq0KTTwBbFfKLKtQFX0ekJ626VwwhQupnpJKpesxkodBxAbyn40oIIKH+++cMK9bV3ywgttsZLKxCAWdIkGnXRSRUI0VCycvSeclgMMeeSRryoTX/JuDnucehILC6fg8bgsNJaDF/umUu5ZqgB6gs0js1AzQaukvPJJXuSxcBWbwsCCyRXtC4Mq0i6UysInXHKT0PkKVPTEm9rEir1Qiud0HkALhDK/VaNYhQlT7Oz00AVJzO/RFK3CR9pvPhndNVo0tG0TyXRPKhHNfxue4Sqr4K244QEBACH5BAAKAP8ALAAAAAAwADAAAAj/AHMIHEiwoMGDCBMqXEhwBgsWNBhKnFjwiRo1pihqLMjpIK2LdA7m6rjxoJYRJkgS/KgmZMFctGZhKVkwy4Y3jnBxZOmS4IpYh2TppClwxs03dDQV/Eihp8BVRxw4UKOF6MAUb7KuIMiJliw1TwqikuqgltWBmjxknRVRYFeQBLXIknpk1dmBlBxlNbHyYtiBtKTGUnF3ICdTR45oyAL4a08XaKRuyFVyRtuaGrI+6fgWrMBcGqRGGFoQF6WEM2jRWUFZbFZHp3OYWLKEb44UQB04FUiDjlQXCG3RnjUCl8ocNJbgJJyDk/OBtWI5oFB1YC4TsgwpULABYQoPS2aF/0dVXaCKJzMRcmLhyJZhFm20bzfk4bhhLLXEi6eVwm5z+yKRlMUSQmyngCEUqAAgQblQ8oR44dFByYIJcTKCAwYqgEYtSkm0Sgq0hDcLKhQilMsi8h3iQXkUzWDCLB4wtpEKZRjyBnBEcWJaiRWacktrhQUpZEmcNefWcwJpsoIKS6rApJMqkEbkLItUaWUbbSxyhIwnmWLKCF6G6aNVmjgAy5kFoHkmLO7l0KWXYIp5C5lmrmnnmW0qCeWTT+JIEydUWiloG1sOuRCSziFp6KKGzSDjRppoMAKQJa1CyS23XEYRKoIIgoaCkGKRgi2ksgCpEAGkWsARUirESRYqkP9KqgosSgQTAq+kGkACHmhqECcOyXpLClgAyeNTrWHRRgG6viKECZQShMUtwlLiH2+4XGtQLiMksIRhKqAhiK6CtLGgC6TessIMxzXIAiUzIPRGKwD44GcOmoxgSK4ByLLgKk5mAaAWD7Hg3yozzODfE/QCoIZ9Rh1wwFYIrdJhQZaysEJ6yGWRRVuaHAIAAGCkcJALzG2ExUOUXEyDx5elAMbIQlx81yoas8Diyx8bpsbIrfx1FycurMCCC5TyrCkuPoyMQK00zWA0RAU52jNBS4wMgCN35eKCxsYVpHTVQIzcQ2xEaULJQ9ryBrNBtbgCwCsmn5VLFlB3fDWDFAwUxihBY297bGGB/31oLiMZrnhBAQEAIfkEAAoA/wAsAAAAADAAMAAACP8AcwgcSLCgwYMIEypcSDCTCxeZGEqcWPDOmzd3KGosyOmgnQtv7Bzk1HHjQVW2qJQk+PGCyII3RPxKZbKgql9MmtAsaOeiCIMs2Ci64KfmwEw4mdy5UVDExZcDWUFSNFSV0YEsmGhlQZDTxzc/CdqiusbW1ah2tIqowfIpQVVvqEJidXbgiyZaqbAEKaIkJxFU2QCrO5CTCa1OLg38CvWFBapOVlLMxNbgJSdaTXT06jYHpyZULbw4mMpFwkwlSrhgWpCK1iajc1D59UtvDhVrqEIdWEOEBAlFDwITIcKOrVSSe+cMVnilCaG+rA68QYUNrwa8miBkYYd4cRURBwb/K7FzZDAmtgW60PCA1/UHvyQTvISiO/E7LOh6ln+QdY7LETSA3QNvsMBfVy+Y4J0dJvhxYEKclCCBe+4pYoJ+DLESzB3epTfRDb5gx0sEv0inUSYq2HGHYhux0B4TsdXESSoxahShCv4RpuOOJpHk2Y+S3eBCMEMGY2SR5dUUAkhv+HKRk29owGImKJhggi1YYnklMA8ydAMbCoQp5gJhLmAbSlnacqWatgxm1JdixlmmbUIaeeSdSW70ly++aNCnn3wywSKPhBZaVyYmanQDEyVgaBIrfgTDQmUamaCLLooYuNENqUjKAjDBUVRDLwaUmoAGeUKoigufAsMCRJuG/7BLqaXuEkJ4CdXwAgutBnNJlwfVwJofGiRAqwEPoJAjQanw6ioLqTjKiirLEnTDHbtoJxAnwCiiC60I+HJgs66+UINknFySSrQC3cDKuQJpMEAACdR4gwkN0GrBgaw8pAp/mazLLidvXHqBQHbMK4AFBqniRJhcIcRKtTncoG4q4XHCCwAA8CIQK70EEIAYKhy0K7AIBZzKrwNt3HFJKoghci+OnsXKupdQqjHHHg9kgQABDLDbWar4sfJKO3dMkB8JiLxAokbVILCjSfc8UBNAB8BEXemm4gfUVUuWSQMi68LcVRavvGzYBZVAgAC6lHwWJ5Qd5LLV01kggZuGehZ2d38oE9YLxxH0LdELdthRo+GM5xAQACH5BAAKAP8ALAAAAAAwADAAAAj/AHMIHEiwoMGDCBMqXEiQGAwYxBhKnFgQhTBhKChqLFjsoIklwkwc7LgRYSZgVw7iuSiSowk7l0oWzFRCBEyDJlga5JMBg5IsMgcSMyFCBAqSA3OGLGjjiRufM4IO5GPHJq6CSvEUlISh6zCpA3OhKGrCBsGcS1oKzLSkqxyzYAVeqiqCEkE8ILUmdeMmg924AotJKloi08CVS/TmyKKk6xOkFInBnRmpqCSSaFsWE9E1CVCDl2AkJCZpWBbIAq8UtfP5SqRIKXNQyvBUrVATfD/vxMMb2AzINohGuhoYqaSeSwwPFJxEkfPHB2Gg4I0HBaWIA2FIioqwGIwnkgji/5JTxLmiIpESZroynfcwXLmWM0Q6t4L5IksooeZ4SRJ1FJLEtBEKbtyHwTCTLZQLDMO0d8V+ChUjjHmM2KGcRsRQggIKF1JESQUVOKGbTJmMSFExeAADIWAstjgRSTBCVkwWD2VBIww3cidTMZEoscQSPgL5oxzcEXPFkUgmSdyOGTgwhANQRvkkMAIZmeSVS5ZUDAZRSjnEEKFQmcOMONqIY406yhQJSBe1CRKRLkq0Ypx0DmRDgic+YUJ8QeWSySWX8KmRJAww4IZ+GxVDzCU2ZpGmRLm4ocCkQixhYkLF2DBDo47iOV8koUw6aSgiYJdQLps2egkxJOXiqUE28P95iRxDiBqEIigIWtCiqmYCmTCFiKArQcWYEMoTBFGCQRC2LgFhiTbOMCwuPejQihsCuWoDScL8YAADI4olgahJdDfDJZ4Wo4gO1iKbgxJBBKGEQCV4a0ASqBEjApRZcgQhCjywOwRcRAQQABHZKmKAAQmIWVAWf2lkgxDsBvBVDrkUfDBJVySwsCLDSvVEK+wWAaPGRCCVxMI/lMDiJT+w60OWKBOUBQMLO/CoTBmwq8MSxBb8CsIEPbGwAU7ERckr7BbSYQ4oQ0YMEQsr0O9GwzDdSnpBG0z0WQgYoEBsUkkSiiKeRl1QLhkwQjZYxYRcDBGvHDzSnC0qUrcieNcLmV0JJYjm9+AGBQQAIfkEAAoA/wAsAAAAADAAMAAACP8AcwgcSLCgwYMIEypcSBCQlmWAGEqcWHAFFBErKGqUKEmECEkHA21MCEhZn4OSLoI0mOzElpEFa7RE9rJgx48Gl8lZcqwmzByAJJ04sUIkwZsrB3qpxYTnn58Dlw09scymx4wEW8hhwuQK1IGBVpyQIsnLUY9Jc9R4whWK2a8C/yAbenIgUoLJuMqpCzdHoBZDkdUYuALtQC20mpYwqhHQ24KAWp5oYfQm1kBSuNLScnBLVYQllW1hPLDP1JrKkCFTJrDPTibJDEbesIHzwWVXcisbTNCLUGSfDV5J/IS3wL9yMCiHglBL7ucQCTp/mlBLiRYEl4lAohwDEimkCdb/gPH8SotljyUy/iMliRs3ymkpC2/wj7Lyyv7QXyhpSXcMS5Q1USBatLBCbjBsFMgTGMCXhBTUNYZbC8ZR1AcSSIgQHEw1RLiRJFfs19eIJKoH1nGkBfLHiiy2WOFIJdAioxwy1vhETV4so+OOPPo0UiBLKCLkkERil4MXD/HYI1RAEulkEUaq2OKUL2oUyAm0HHNMllweI4KHJYYp5k+AMBiRgrUkk56VyRjzxRcijHTFA7wkwdpGfRQBBgB8klGlQl4kwcugEBxjG0N/LOEDn3x6ssSaC12pCC9mUCpBCX8qVQsZjAIAhiJ1eZFpb0ZtcQwElFbqhiT7eaHIF4x+/2EMMozJYUwJkB4nCRvMlbYEnYM+cAx9gTzAKAJPnNnaGAF0ksRxgABilAigKPDAhr4ZQSkvTOwnSSedIOGjX0YIEIAnzAXCxKBMCITMAgoosER4NZQggQQJIpSMkTYVEEAAEJxphAEGsCGQFxjEawxWBS3DF0WAQPBvAQwPbIARRiljRrxG5AoTFJ0IIIAbRgVisREEyRHvAieMuMUCIo+Rr0AnSwdBvBGACdMS/wogR0E1E1RLvAo8AZcyB/xrjIcmE4yxeGzEy8vMMElygACelFBQ0xeHJ0m1vPD70woSdGxQ0AQFIoedIwaSKxsEG2xQICKWiEEBBmAw5kRSSQex4d6ADxQQACH5BAAKAP8ALAAAAAAwADAAAAj/AHMIHEiwoMGDCBMqXEhwE5ctmxhKnFgQFx48lShqlEjpYkaDxTYm3JQly8FKFymBpGSFi8iCmihdoVTDYEc8KgtqseMMlcuXAjdVunIFV0iCNz8OLIbCWc+aQAVyIXrl58CkBf04taM0ajFcRCtFHIgSJ8Eaz5ziGRtVYA2ZV7Qg9Yh0q8m2BLMQpaSJLF2pkZwOO6qxGGGCMYn6ufq32DCnkawS5CIXYTEtWvoa1LL3p94ri3Nk4eksZ0MrIEBsQcilZJYtmpcOpbRa4GFcgZ/FzvHVTocOHPAgrKHFdRYubHNwwQUV4ZZhuAhuQdWMA/Bmw0ZuMa6lxmGGhGtA/5vDwXqHSFm+G9S03XV3kZSe/Lb+hFJyhcWIu65NsRgq83MM0xxFDmF2n0RZNNPMM/y9tMluGhWlHl4UWmYbb7xN+NKEhOGCBi8ghhhiIwdS9BhPKDpjhx2RCRSJDjDGKCMzAxYGQiMX4Ihjjjl+ZIeMQOpAI1DFgMCjjhfk2MhHHooo4iGNaCgRNE5tpSJkkhmGYYYVdumlSJrYkUSJCxWDBzRkTomGIIJEAt8iozQT3UZ+XDBIAHgKUWOZzUzgZxt2NKgQF80QIgCeAhAyR5oHOdbIKH5O0AgeezaECigCHCrAIG2E9iBDmxzFhR1tRDqKEldweIEgmQYgyAPQEP/2xAPPkFnMFY6gQpAfcywyAaSjONPoBIgaYsdufoACywEd2BbqUZE8wMsEldl2hRKQTgDChFYccAAHguaQBCyDHKBrDs4sssgTAkHzwCGHzPFdDXjkeNdB0HQ1kBWEwALLBGM5ooACUfLGAS+HoKGvQFuEppEmE/hbyBUDCUzwQLhEAOKYXaLCjL9JEJbEwI0Q9ESI2VG4BS/+gnJvDhYXzPAEh/CyiGRAzeEvLOwSNPLFBOGBMC924IWLAv4+gLPFjhymSSMgRvCySFYgfYBwBcX83RXSprHwRlcswnHWJIMEQgcOt6WlQTE3+iVCHAwc8tsTaTHMMNXSrbdBAQEAIfkEAAoA/wAsAAAAADAAMAAACP8AcwgcSLCgwYMIEypcSPDGqlWcGEqcWDDLlStZKGqUaPEKlo0bOWXKdBDLFSsfDWJRZgNkwRtasmi5ofJkSoKZUOBRscrlQE4xs5AsaNJjQU5X8OBJ0dKnQBtZovYkWPSmQC1KUWR0KpDTlqhaIg6s2lCFUis0uT6NmmWqQLJjleLZohYn2LQ54OawkUIKnmBiNaYIdhBoVLpvL95UpjSFW4Krhh5U0amTBi0GV7FNu8WSJcRbdOKxZPCGshIlHv8MBaC1rhBNu37VonpgFp0q8ObglAUPFCjOrBy8oehLawBfGqQIbGOLboOZrmAemEkFcGfOoBAeXqvQcQA8FJH/psj8Si3s2FGEVZiplI/vPko9Z2hJCvYQUKRYCrzQkqIAxyVQm0KcqIBeLVfERlEKDXzxhTMgbVELFCpIBpINIbyhIEWWbKUWf3UlxMmIu0VEYogLYaGIKKKsyOKLkICo0RVS1FgjHjbiMZUUAfTo44+gDDhRLaUU2UGRpRzZQUol/OhkAKBsSF4tRxqJZAdLvuUiixO8KAok802ElI1k3uiWiSWSKCOKbLaJ0A0ldBDmQgUC5pQViugSjRQgWaJBBiF4SBEWGiRgQDTRTCMlgRm+8YYGUljIXghBGHBoNEGEMGdCVpTiqKMdqLDoQDfgMQ2iiCaQwU2bkipWJlJo//DpG07YaRAnGegZjQG6KGJFYLVQo8KauwXTAR4EZRFCBqQ4moEUMnLCCKoNlKAbFtOAkmlXuw2EBzWKvDFdV8E0IesbUCCkDBmFOCFpDk2wGwSfOUDxBinp5mAFuIo4AyJfkEAyrkFWKHNQMA2QAQopaXUgjTQx5nCDE4oowojBBn0F0g1vFFJIA1cMVIoZ0pQyFiMVN9GqRiiA4nETgZUijRkmDwRFxWsIV1cmiigciqAdkByxQJlkULEGQmrkjMug5Cvyw0MLlMIaFdPrVBbSeKyIpA6bAUlBNpRSMSmCgqRMKIWAgoJBI5dsUDBrUMOIVS4po0EpMsoMMYicQB7hRNk+nVhQ11/f6uZBTZDcweETbWGFFQMzLvlAAQEAIfkEAAoA/wAsAAAAADAAMAAACP8AcwgcSLCgwYMIEypcSLDYjRvFGEqcWPBPqlR/KGpseOOgRYwbN6oINaFjxYsZDWpJZTLkwGQEALiqZfBjSoJd9kyqBMjlwD2CAAAAclPgR0wGYUyatKelTyRCAXA4CZIgJp2TkPocqAWBUB8wCNpsWGmppYhbBz5pJZQC2hxjuS7d0yUtQUDVhAZINjBujhtYw4bMU+lgMh5Ch/SEi3JgqqWTFhe8URfhpB8/OGgdWIyC0FZPBHbBhKnyH8ipDBZLlUyF5IYTAgR4tcDO60oxWzVCiKlsJadw89gaXlh1GwKyAxCAoOItByC2EwKCUbRLpVvDbd2yhPCGiWqvkg//ciOYssYbMJJlv5V1IaZmhMLPJvTh7UQtKtarSGVfIQw3g4T3SjWVTVTMHtklYwlwDBWjAgQECELTRn/ccgtdWwFihwYMSpQKJv25FKJdCkX01ogkGpSKG9RQ04aLL7Y4S4cTWaLCjTjimMdithjg44+D/CjNaxvdIsKRSCJphxYC9fjjkz6GQiRFxSST5JVLCpRKIy3G2KKMNEpkY4457thQDvahmOKabCp0g5FhJnTgWVtV0sgCDKgQkhbNNGPCZhTxWc0nhLYRp2qozMLBLB8kU+BCgNQCAaGESmOHmgjtccwsis7yRFMlqkDBApRWw0FqaGIq0FtdJPNBp7PU/8LfQcU0wwClC7QxCUEmILFrQjA8oedAmJjQzKIcNMOXahpQGoEtr2lBgTShTGjiQCog0QgHRRVjiQiccnALQpVIM8QTRQl0zBDSSDNuDrZwwIEJAu2hbSP0TpbHMccAWtAe3BlkSQTscqguBRN8sKoIjbihAaoVMbnRDRu0C0FxORwzQcJopaKBG26IcChFI7GrsFoTUHCyQCY00ggSe6TYhRvsyiKxuhsfI9YsbjTSzJQh1WKuNKgUdAzCKwukgsuNLLuVFhOY68ajGW+c9F8f9KxZWpbIMkQowxKkMccFWYKEGxvc7BMMsxwT4thXo2lCliQWM6LGKtPaJkIipA8c2t4T/bHHHv4CbjhBAQEAOw==)}.sr-rd-content-center{text-align:center;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;-webkit-box-orient:vertical}.sr-rd-content-center-small{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.sr-rd-content-center-small img{margin:0;padding:0;border:0;box-shadow:none}img.simpread-img-broken{cursor:pointer}.sr-rd-content-nobeautify{margin:0;padding:0;border:0;box-shadow:0 0 0}sr-rd-mult{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin:0 0 16px;padding:16px 0 24px;width:100%;background-color:#fff;border-radius:4px;box-shadow:0 1px 2px 0 rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}sr-rd-mult:hover{-webkit-transition:all .45s 0ms;transition:all .45s 0ms;box-shadow:1px 1px 8px rgba(0,0,0,.16)}sr-rd-mult sr-rd-mult-content{padding:0 16px;overflow:auto}sr-rd-mult sr-rd-mult-avatar,sr-rd-mult sr-rd-mult-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sr-rd-mult sr-rd-mult-avatar{-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 15px}sr-rd-mult sr-rd-mult-avatar span{display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;max-width:75px;overflow:hidden;text-overflow:ellipsis;text-align:left;font-size:16px;font-size:1rem}sr-rd-mult sr-rd-mult-avatar img{margin-bottom:0;max-width:50px;max-height:50px;width:50px;height:50px;border-radius:50%}sr-rd-mult sr-rd-mult-content img{max-width:80%}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center{margin:0}sr-page{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;width:100%}</style>
                        <style type="text/css">sr-rd-theme-github{display:none}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{position:relative;margin-top:1em;margin-bottom:1pc;font-weight:700;line-height:1.4;text-align:left;color:#363636}sr-rd-content h1{padding-bottom:.3em;font-size:57.6px;font-size:3.6rem;line-height:1.2}sr-rd-content h2{padding-bottom:.3em;font-size:44.8px;font-size:2.8rem;line-height:1.225}sr-rd-content h3{font-size:38.4px;font-size:2.4rem;line-height:1.43}sr-rd-content h4{font-size:32px;font-size:2rem}sr-rd-content h5,sr-rd-content h6{font-size:25.6px;font-size:1.6rem}sr-rd-content h6{color:#777}sr-rd-content ol,sr-rd-content ul{list-style-type:disc;padding:0;padding-left:2em}sr-rd-content ol ol,sr-rd-content ul ol{list-style-type:lower-roman}sr-rd-content ol ol ol,sr-rd-content ol ul ol,sr-rd-content ul ol ol,sr-rd-content ul ul ol{list-style-type:lower-alpha}sr-rd-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all}sr-rd-content table th{font-weight:700}sr-rd-content table td,sr-rd-content table th{padding:6px 13px;border:1px solid #ddd}sr-rd-content table tr{background-color:#fff;border-top:1px solid #ccc}sr-rd-content table tr:nth-child(2n){background-color:#f8f8f8}sr-rd-content sr-blockquote{border-left:4px solid #ddd}.simpread-theme-root{background-color:#fff;color:#333}sr-rd-title{font-family:PT Sans,SF UI Display,\.PingFang SC,PingFang SC,Neue Haas Grotesk Text Pro,Arial Nova,Segoe UI,Microsoft YaHei,Microsoft JhengHei,Helvetica Neue,Source Han Sans SC,Noto Sans CJK SC,Source Han Sans CN,Noto Sans SC,Source Han Sans TC,Noto Sans CJK TC,Hiragino Sans GB,sans-serif;font-size:54.4px;font-size:3.4rem;font-weight:700;line-height:1.3}sr-rd-desc{position:relative;margin:0;margin-bottom:30px;padding:25px;padding-left:56px;font-size:28.8px;font-size:1.8rem;color:#777;background-color:rgba(0,0,0,.05);box-sizing:border-box}sr-rd-desc:before{content:"\201C";position:absolute;top:-28px;left:16px;font-size:80px;font-family:Arial;color:rgba(0,0,0,.15)}sr-rd-content,sr-rd-content *,sr-rd-content div,sr-rd-content p{color:#363636;font-weight:400;line-height:1.8}sr-rd-content b *,sr-rd-content strong,sr-rd-content strong * sr-rd-content b{-webkit-animation:none 0s ease 0s 1 normal none running;animation:none 0s ease 0s 1 normal none running;-webkit-backface-visibility:visible;backface-visibility:visible;background:transparent none repeat 0 0/auto auto padding-box border-box scroll;border:medium none currentColor;border-collapse:separate;-o-border-image:none;border-image:none;border-radius:0;border-spacing:0;bottom:auto;box-shadow:none;box-sizing:content-box;caption-side:top;clear:none;clip:auto;color:#000;-webkit-columns:auto;-moz-columns:auto;columns:auto;-webkit-column-count:auto;-moz-column-count:auto;column-count:auto;-webkit-column-fill:balance;-moz-column-fill:balance;column-fill:balance;-webkit-column-gap:normal;-moz-column-gap:normal;column-gap:normal;-webkit-column-rule:medium none currentColor;-moz-column-rule:medium none currentColor;column-rule:medium none currentColor;-webkit-column-span:1;-moz-column-span:1;column-span:1;-webkit-column-width:auto;-moz-column-width:auto;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;direction:ltr;display:inline;empty-cells:show;float:none;font-family:serif;font-size:medium;font-style:normal;font-variant:normal;font-weight:400;font-stretch:normal;line-height:normal;height:auto;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;left:auto;letter-spacing:normal;list-style:disc outside none;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;opacity:1;orphans:2;outline:medium none invert;overflow:visible;overflow-x:visible;overflow-y:visible;padding:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;-webkit-perspective:none;perspective:none;-webkit-perspective-origin:50% 50%;perspective-origin:50% 50%;position:static;right:auto;-moz-tab-size:8;-o-tab-size:8;tab-size:8;table-layout:auto;text-align:left;text-align-last:auto;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;top:auto;-webkit-transform:none;transform:none;-webkit-transform-origin:50% 50% 0;transform-origin:50% 50% 0;-webkit-transform-style:flat;transform-style:flat;-webkit-transition:none 0s ease 0s;transition:none 0s ease 0s;unicode-bidi:normal;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;word-spacing:normal;z-index:auto;all:initial}sr-rd-content a,sr-rd-content a:link{color:#4183c4;text-decoration:none}sr-rd-content a:active,sr-rd-content a:focus,sr-rd-content a:hover{color:#4183c4;text-decoration:underline}sr-rd-content pre{background-color:#f7f7f7;border-radius:3px}sr-rd-content li code,sr-rd-content p code{background-color:rgba(0,0,0,.04);border-radius:3px}.simpread-multi-root{background:#f8f9fa}</style>
                        <style type="text/css"></style>
                        <style type="text/css">@media (pointer:coarse){sr-read{margin:20px 5%!important;min-width:0!important;max-width:90%!important}sr-rd-title{margin-top:0;font-size:2.7rem}sr-rd-content sr-blockquote,sr-rd-desc{margin:10 0!important;padding:0 0 0 10px!important;width:90%;font-size:1.8rem;font-style:normal;line-height:1.7;text-align:justify}sr-rd-content{font-size:1.75rem;font-weight:300}sr-rd-content figure{margin:0;padding:0;text-align:center}sr-rd-content a,sr-rd-content a:link,sr-rd-content li code,sr-rd-content p code{font-size:inherit}sr-rd-footer{margin-top:20px}sr-blockquote,sr-blockquote *{margin:5px!important;padding:5px!important}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6,sr-rd-title{font-family:PingFang SC,Verdana,Helvetica Neue,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;font-weight:100;line-height:1.35}sr-rd-content-h1,sr-rd-content-h2,sr-rd-content-h3,sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}sr-rd-content-h1,sr-rd-content h1{font-size:1.8em}sr-rd-content-h2,sr-rd-content h2{font-size:1.6em}sr-rd-content-h3,sr-rd-content h3{font-size:1.4em}sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{font-size:1.2em}sr-rd-content-ul,sr-rd-content ul{margin-left:1.3em!important;list-style:disc}sr-rd-content-ol,sr-rd-content ol{list-style:decimal;margin-left:1.9em!important}sr-rd-content-ol ol,sr-rd-content-ol ul,sr-rd-content-ul ol,sr-rd-content-ul ul,sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em!important}sr-rd-content img{margin:0;padding:0;border:0;max-width:100%!important;height:auto;box-shadow:0 20px 20px -10px rgba(0,0,0,.1)}sr-rd-mult{min-width:0;background-color:#fff;box-shadow:0 1px 6px rgba(32,33,36,.28);border-radius:8px}sr-rd-mult sr-rd-mult-avatar div{margin:0}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center-small{margin:7px 0!important}sr-rd-mult sr-rd-mult-avatar span{display:block}sr-rd-mult sr-rd-mult-content{padding-left:0}@media only screen and (max-device-width:1024px){.simpread-theme-root,html.simpread-theme-root{font-size:80%!important}sr-rd-mult sr-rd-mult-avatar img{width:50px;height:50px;min-width:50px;min-height:50px}toc-bg toc{width:10px!important}toc-bg:hover toc{width:auto!important}}@media only screen and (max-device-width:414px){.simpread-theme-root,html.simpread-theme-root{font-size:70%!important}sr-rd-mult sr-rd-mult-avatar img{width:30px;height:30px;min-width:30px;min-height:30px}}@media only screen and (max-device-width:320px){.simpread-theme-root,html.simpread-theme-root{font-size:90%!important}sr-rd-content p{margin-bottom:.5em}}}</style>
                        <style type="text/css">undefinedsr-rd-content *, sr-rd-content p, sr-rd-content div {}sr-rd-content pre code, sr-rd-content pre code * {}sr-rd-desc {}sr-rd-content pre {}sr-rd-title {}</style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css">sr-rd-content *, sr-rd-content p, sr-rd-content div {
        font-size: 15px;
    }

    .annote-perview, .annote-perview * {
        color: rgb(85, 85, 85);
        font-weight: 400;
        line-height: 1.8;
    }</style>
                        
                        
                        <script>setTimeout(()=>{const e=location.hash.replace("#id=","");let t,a=!1;const n=t=>{for(let n of t){let t;if((t=e.length>6?n.getAttribute("data-id"):n.getAttribute("data-idx"))==e){n.scrollIntoView({behavior:"smooth",block:"start",inline:"nearest"}),a=!0;break}}};e&&(0==(t=document.getElementsByClassName("sr-unread-card")).length&&(t=document.getElementsByTagName("sr-annote")),n(t),a||n(t=document.getElementsByClassName("sr-annote")))},500);</script>
                        <script>document.addEventListener("DOMContentLoaded",function(){if("localhost"==location.hostname){const t=document.getElementsByTagName("img");for(let o of t){const t=o.src;t.startsWith("http")&&(o.src=location.origin+"/proxy?url="+t)}}},!1);</script>
                        <style>toc a {font-size: inherit!important;font-weight: 300!important;}</style><script>setTimeout(()=>{const max=document.getElementsByTagName('sr-annote-note-tip').length;for(let i=0;i<max;i++){const target=document.getElementsByTagName('sr-annote-note-tip')[i],value=target.dataset.value;value&&(target.innerText=value)}},1000);</script><title>简悦 | 22 | 自适应的基函数：神经网络</title>
                    </head>
                    <body>
                        <sr-read style='font-family: "LXGW WenKai Screen";'>
                            <sr-rd-title>22 | 自适应的基函数：神经网络</sr-rd-title>
                    <sr-rd-desc style="margin: 0;padding-top: 0;padding-bottom: 0;font-style: normal;font-size: 18px;">新一季的主题是机器学习，我会帮你把握不同模型之间的内在关联，让你形成观察机器学习的宏观视角，找准进一步理解与创新的方向。</sr-rd-desc>
                    <sr-rd-content><h1 id="sr-toc-0">22 | 自适应的基函数：神经网络</h1><div><span>王天一</span> <span> 2018-07-24</span></div><div><div><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/98/69/9884563ebd247dd070a3feaa7b854b69.jpg"></div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADEAAAABCAYAAAB35kaxAAAAAXNSR0IArs4c6QAAAChJREFUGFdjfPfu3X8GKBAUFASz3r9/DxNiQBbDxcamn1yzSLEDZi8A2agny86FR+IAAAAASUVORK5CYII="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAABCAYAAAA8TpVcAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFCYtjkAcT9D8ti7hUOAAAAAElFTkSuQmCC"></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD0AAAABCAYAAABt2qY/AAAAAXNSR0IArs4c6QAAACdJREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULy2PQQK0YLewiZCQDhUS3LBhDf1QAAAABJRU5ErkJggg=="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAABCAYAAAA4u0VhAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULyAF6lD8tbqYWOAAAAAElFTkSuQmCC"></div></div></div><div><div><div></div></div><div><div><div><div><div><div>00:00</div></div><div></div></div></div><a href="javascript:;"> 1.0x <i><span></span></i></a></div><div><span>讲述：王天一</span><span>大小：8.58M</span><span> 时长：18:45</span></div></div><audio title="22 | 自适应的基函数：神经网络" src="https://res001.geekbang.org/media/audio/bc/ad/bca345f126ed2e450aa589d96f4dcfad/ld/ld.m3u8" g6hbzi36y="" __idm_id__="1294349"></audio></div><div><div><div><div data-slate-editor="true" data-key="3949" autocorrect="off" spellcheck="false" data-gramm="false"><div data-slate-type="paragraph" data-slate-object="block" data-key="3950"><span data-slate-object="text" data-key="3951"><span data-slate-leaf="true" data-offset-key="3951:0" data-first-offset="true"><span data-slate-string="true">回眸人工神经网络的前半生，不由得让人唏嘘造化弄人。出道即巅峰的它经历了短暂的辉煌之后便以惊人的速度陨落，几乎沦落到人人喊打的境地。可谁曾想三十年河东三十年河西，一位天才的出现让神经网络起死回生，众人的态度也迅速从避之不及变成趋之若鹜。如果人工神经网络果真有一天如人所愿实现了智能，不知它会对自己的命运作何评价。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3952"><span data-slate-object="text" data-key="3953"><span data-slate-leaf="true" data-offset-key="3953:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">人工神经网络</span></span></span></span><span data-slate-object="text" data-key="3954"><span data-slate-leaf="true" data-offset-key="3954:0" data-first-offset="true"><span data-slate-string="true">（artificial neural network）是对生物神经网络的模拟，意在通过结构的复制实现功能的复制。但人类神经系统在百万年进化中留下的智能密码并没有那么容易破解，因而神经网络最终也难以跳出统计模型的窠臼，成为</span></span></span><span data-slate-object="text" data-key="3955"><span data-slate-leaf="true" data-offset-key="3955:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">线性模型</span></span></span></span><span data-slate-object="text" data-key="3956"><span data-slate-leaf="true" data-offset-key="3956:0" data-first-offset="true"><span data-slate-string="true">大家族的又一位成员。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="3957"><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/47/b2/47476b2d5418ea0e3157655abe8e7fb2.png?wh=826*304"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3958"><span data-slate-object="text" data-key="3959"><span data-slate-leaf="true" data-offset-key="3959:0" data-first-offset="true"><span data-slate-type="secondary" data-slate-object="mark"><span data-slate-string="true">感知器示意图（图片来自 Machine Learning: an Algorithmic Perspective, 图 3.1）</span></span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3960"><span data-slate-object="text" data-key="3961"><span data-slate-leaf="true" data-offset-key="3961:0" data-first-offset="true"><span data-slate-string="true">人工神经网络的祖师爷是</span></span></span><span data-slate-object="text" data-key="3962"><span data-slate-leaf="true" data-offset-key="3962:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">感知器</span></span></span></span><span data-slate-object="text" data-key="3963"><span data-slate-leaf="true" data-offset-key="3963:0" data-first-offset="true"><span data-slate-string="true">（perceptron），其作用是根据输入数据的属性对它进行二分类。当偏置 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="3964"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>b</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span></span></span><span data-slate-object="text" data-key="3966"><span data-slate-leaf="true" data-offset-key="3966:0" data-first-offset="true"><span data-slate-string="true"> 时，感知器计算输入属性的线性组合 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="3967"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span>⋯</span><span></span><span>+</span><span></span></span><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="3969"><span data-slate-leaf="true" data-offset-key="3969:0" data-first-offset="true"><span data-slate-string="true">，所有参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="3970"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="3972"><span data-slate-leaf="true" data-offset-key="3972:0" data-first-offset="true"><span data-slate-string="true"> 共通构成分类边界的法向量 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="3973"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span><span>w</span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="3975"><span data-slate-leaf="true" data-offset-key="3975:0" data-first-offset="true"><span data-slate-string="true">。求出的线性组合接下来被送入</span></span></span><span data-slate-object="text" data-key="3976"><span data-slate-leaf="true" data-offset-key="3976:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">激活函数</span></span></span></span><span data-slate-object="text" data-key="3977"><span data-slate-leaf="true" data-offset-key="3977:0" data-first-offset="true"><span data-slate-string="true">（activation function）中计算结果。感知器的激活函数是</span></span></span><span data-slate-object="text" data-key="3978"><span data-slate-leaf="true" data-offset-key="3978:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">符号函数</span></span></span></span><span data-slate-object="text" data-key="3979"><span data-slate-leaf="true" data-offset-key="3979:0" data-first-offset="true"><span data-slate-string="true">，其输出的二元结果就表示了两种不同的类别。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="3980"><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/02/1e/02200fbc2a07d8644aae056ca6d6461e.png?wh=721*229"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3981"><span data-slate-object="text" data-key="3982"><span data-slate-leaf="true" data-offset-key="3982:0" data-first-offset="true"><span data-slate-type="secondary" data-slate-object="mark"><span data-slate-string="true">感知器的学习过程示意图</span></span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3983"><span data-slate-object="text" data-key="3984"><span data-slate-leaf="true" data-offset-key="3984:0" data-first-offset="true"><span data-slate-string="true">（图片来自 https://www.willamette.edu/~gorr/classes/</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3985"><span data-slate-object="text" data-key="3986"><span data-slate-leaf="true" data-offset-key="3986:0" data-first-offset="true"><span data-slate-string="true">cs449/Classification/perceptron.html）</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3987"><span data-slate-object="text" data-key="3988"><span data-slate-leaf="true" data-offset-key="3988:0" data-first-offset="true"><span data-slate-string="true">上图给出了感知器的学习过程。训练数据集是个线性可分的数据集，数据点的星号和圆圈代表不同的类别。感知器的初始参数是随机生成的，用这组随机参数生成的分类边界是图中的红色虚线。显然，在分类边界两侧的两个类别中都有误分类的点。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3989"><span data-slate-object="text" data-key="3990"><span data-slate-leaf="true" data-offset-key="3990:0" data-first-offset="true"><span data-slate-string="true">直观来看，要让走错片场的星号和圆圈找到组织，唯一的办法就是调整分类边界，让新边界把原始边界上方不同颜色的点区分开来。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3991"><span data-slate-object="text" data-key="3992"><span data-slate-leaf="true" data-offset-key="3992:0" data-first-offset="true"><span data-slate-string="true">调整的方法一目了然：既然星号集中在左侧而圆圈集中在右侧，那就要让分类边界向右侧旋转，把右侧的星号包进来，把左侧的圆圈踢出去。右侧子图表示的就是将原始边界试探性地旋转一个角度所得的结果。虽然这个小角度的旋转还是没能完全正确分类，却对分类的准确率有所改善。只要在此基础上进一步旋转，新的分类边界就可以将两个类别的点完全分开了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3993"><span data-slate-object="text" data-key="3994"><span data-slate-leaf="true" data-offset-key="3994:0" data-first-offset="true"><span data-slate-string="true">由于分类时无需使用数据的概率分布，因此</span></span></span><span data-slate-object="text" data-key="3995"><span data-slate-leaf="true" data-offset-key="3995:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">感知器是一种基于判别式的分类模型</span></span></span></span><span data-slate-object="text" data-key="3996"><span data-slate-leaf="true" data-offset-key="3996:0" data-first-offset="true"><span data-slate-string="true">。但它和前面提到的线性判别分析又有所不同，其算法不是利用所有数据的统计特性一鼓作气计算出最优的参数，而是通过不断试错为参数优化过程提供反馈，从而实现动态的参数调整。</span></span></span><span data-slate-object="text" data-key="3997"><span data-slate-leaf="true" data-offset-key="3997:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">具备自适应的学习能力是感知器和前面所有模型相比独有的优势</span></span></span></span><span data-slate-object="text" data-key="3998"><span data-slate-leaf="true" data-offset-key="3998:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="3999"><span data-slate-object="text" data-key="4000"><span data-slate-leaf="true" data-offset-key="4000:0" data-first-offset="true"><span data-slate-string="true">在感知器的动态学习过程中，作为优化目标出现的是</span></span></span><span data-slate-object="text" data-key="4001"><span data-slate-leaf="true" data-offset-key="4001:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">感知准则</span></span></span></span><span data-slate-object="text" data-key="4002"><span data-slate-leaf="true" data-offset-key="4002:0" data-first-offset="true"><span data-slate-string="true">（perceptron criterion）。之所以没有选择常见的误分类率作为指标是因为它并不适用于参数的动态学习过程。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4003"><span data-slate-object="text" data-key="4004"><span data-slate-leaf="true" data-offset-key="4004:0" data-first-offset="true"><span data-slate-string="true">在分类时，产生每一种分类结果的分类边界都不是唯一的，这就让误分类率变成了关于参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4005"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4007"><span data-slate-leaf="true" data-offset-key="4007:0" data-first-offset="true"><span data-slate-string="true"> 的分段常数函数。这不仅会使关于 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4008"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4010"><span data-slate-leaf="true" data-offset-key="4010:0" data-first-offset="true"><span data-slate-string="true"> 的误分类率存在间断点，在求解梯度时也无法给出关于参数移动方向的信息。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4011"><span data-slate-object="text" data-key="4012"><span data-slate-leaf="true" data-offset-key="4012:0" data-first-offset="true"><span data-slate-string="true">感知准则虽然也是建立在误分类率的基础上，但它完全回避了上面的那些缺点，其表达式可以写成</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="4013"><span><span><span aria-hidden="true"><span><span></span><span><span>E</span><span><span><span><span><span><span></span><span><span>P</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>(</span><span><span><span>w</span></span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>−</span><span></span><span><span><span><span><span><span></span><span><span><span>x</span><span>∈</span><span><span>X</span><span><span><span><span><span><span></span><span><span>M</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span><span></span><span><span>∑</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span><span><span><span>w</span></span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4015"><span data-slate-object="text" data-key="4016"><span data-slate-leaf="true" data-offset-key="4016:0" data-first-offset="true"><span data-slate-string="true">其中 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4017"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>X</span><span><span><span><span><span><span></span><span><span>M</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4019"><span data-slate-leaf="true" data-offset-key="4019:0" data-first-offset="true"><span data-slate-string="true"> 是由所有误分类点组成的集合，这说明分类正确的点都具有零误差。感知准则的基本思路是让每个误分类点的贡献 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4020"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>−</span><span><span><span><span>w</span></span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4022"><span data-slate-leaf="true" data-offset-key="4022:0" data-first-offset="true"><span data-slate-string="true"> 都大于 0，这就保证了感知准则整体上的非负性。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4023"><span data-slate-object="text" data-key="4024"><span data-slate-leaf="true" data-offset-key="4024:0" data-first-offset="true"><span data-slate-string="true">二元变量 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4025"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4027"><span data-slate-leaf="true" data-offset-key="4027:0" data-first-offset="true"><span data-slate-string="true"> 可以看成是数据点的真实类别和预测类别的差值，其作用在于控制每个误分类点的贡献。如果一个正类被判定为负类，那 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4028"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4030"><span data-slate-leaf="true" data-offset-key="4030:0" data-first-offset="true"><span data-slate-string="true"> 就是个大于 0 的值，可以取成 +1；反过来负类被判定成正类时，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4031"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4033"><span data-slate-leaf="true" data-offset-key="4033:0" data-first-offset="true"><span data-slate-string="true"> 则取 -1。当感知准则取得最小值 0 时，所有的数据点都被正确分类，感知器算法也就完全收敛。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4034"><span data-slate-object="text" data-key="4035"><span data-slate-leaf="true" data-offset-key="4035:0" data-first-offset="true"><span data-slate-string="true">对上面定义的感知准则求解梯度，可以得到每个轮次中参数的更新方式，也就是</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="4036"><span><span><span aria-hidden="true"><span><span></span><span><span><span><span>w</span></span></span><span><span><span><span><span><span></span><span><span><span>(</span><span>τ</span><span>+</span><span>1</span><span>)</span></span></span></span></span></span></span></span></span><span></span><span>=</span><span></span></span><span><span></span><span><span><span><span>w</span></span></span><span><span><span><span><span><span></span><span><span><span>(</span><span>τ</span><span>)</span></span></span></span></span></span></span></span></span><span></span><span>−</span><span></span></span><span><span></span><span>η</span><span>∇</span><span><span>E</span><span><span><span><span><span><span></span><span><span>P</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>(</span><span><span><span>w</span></span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span><span><span>w</span></span></span><span><span><span><span><span><span></span><span><span><span>(</span><span>τ</span><span>)</span></span></span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span>η</span><span><span>x</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4038"><span data-slate-object="text" data-key="4039"><span data-slate-leaf="true" data-offset-key="4039:0" data-first-offset="true"><span data-slate-string="true">其中的超参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4040"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>η</span></span></span></span></span></span><span data-slate-object="text" data-key="4042"><span data-slate-leaf="true" data-offset-key="4042:0" data-first-offset="true"><span data-slate-string="true"> 是学习率（learning rate），</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4043"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>τ</span></span></span></span></span></span><span data-slate-object="text" data-key="4045"><span data-slate-leaf="true" data-offset-key="4045:0" data-first-offset="true"><span data-slate-string="true"> 表示的是算法的轮次。这个表达式是感知器算法的</span></span></span><span data-slate-object="text" data-key="4046"><span data-slate-leaf="true" data-offset-key="4046:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">批处理更新原则</span></span></span></span><span data-slate-object="text" data-key="4047"><span data-slate-leaf="true" data-offset-key="4047:0" data-first-offset="true"><span data-slate-string="true">（batch update principle）。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4048"><span data-slate-object="text" data-key="4049"><span data-slate-leaf="true" data-offset-key="4049:0" data-first-offset="true"><span data-slate-string="true">根据这个算法的角度回头看上面的示意图，可以获得更清晰的解释。左侧子图中的 p1 点是个被误判为负类的正类点，其系数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4050"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span></span><span><span></span><span>+</span><span>1</span></span></span></span></span></span><span data-slate-object="text" data-key="4052"><span data-slate-leaf="true" data-offset-key="4052:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4053"><span data-slate-object="text" data-key="4054"><span data-slate-leaf="true" data-offset-key="4054:0" data-first-offset="true"><span data-slate-string="true">要让这个点被正确分类，原始的系数向量 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4055"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>w</span></span></span></span></span></span><span data-slate-object="text" data-key="4057"><span data-slate-leaf="true" data-offset-key="4057:0" data-first-offset="true"><span data-slate-string="true"> 就要和向量 p1 与学习率的乘积相加，其几何意义就是向 p1 接近，移动的结果就是图中的 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4058"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>n</span><span>e</span><span>w</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4060"><span data-slate-leaf="true" data-offset-key="4060:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4061"><span data-slate-object="text" data-key="4062"><span data-slate-leaf="true" data-offset-key="4062:0" data-first-offset="true"><span data-slate-string="true">位于第三象限的 p2 同样是误分类点，但是是被误判为正类。当负类被误判为正类时，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4063"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4065"><span data-slate-leaf="true" data-offset-key="4065:0" data-first-offset="true"><span data-slate-string="true"> 的取值为 -1，此时原始的系数向量 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4066"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>w</span></span></span></span></span></span><span data-slate-object="text" data-key="4068"><span data-slate-leaf="true" data-offset-key="4068:0" data-first-offset="true"><span data-slate-string="true"> 要和向量 p2 与学习率的乘积相减，这里的减法体现为右侧子图中两个天蓝色箭头的方向区别。相减的几何意义是让新系数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4069"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span><span><span><span><span><span><span></span><span><span><span>n</span><span>e</span><span>w</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4071"><span data-slate-leaf="true" data-offset-key="4071:0" data-first-offset="true"><span data-slate-string="true"> 远离误分类点 p2，不难看出，它和上面对 p1 的操作具有相同的效果。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4072"><span data-slate-object="text" data-key="4073"><span data-slate-leaf="true" data-offset-key="4073:0" data-first-offset="true"><span data-slate-string="true">感知器模型可以进一步推广为</span></span></span><span data-slate-object="text" data-key="4074"><span data-slate-leaf="true" data-offset-key="4074:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">多层感知器</span></span></span></span><span data-slate-object="text" data-key="4075"><span data-slate-leaf="true" data-offset-key="4075:0" data-first-offset="true"><span data-slate-string="true">（multilayer perceptron），也就是神经网络。最简单的神经网络是多个感知器的线性集成，神经网络的总输出是对每个感知器单独输出的线性组合进行非线性变换。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4076"><span data-slate-object="text" data-key="4077"><span data-slate-leaf="true" data-offset-key="4077:0" data-first-offset="true"><span data-slate-string="true">放在线性模型的大框架下，具有单个隐藏层的神经网络的数学表达式可以写成</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="4078"><span><span><span aria-hidden="true"><span><span></span><span>f</span><span>(</span><span>x</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>σ</span><span>[</span><span><span><span><span><span><span></span><span><span><span>j</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∑</span></span></span><span><span></span><span><span>M</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span><span>β</span><span><span><span><span><span><span></span><span><span>j</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>h</span><span>(</span><span><span><span><span><span><span></span><span><span><span>i</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∑</span></span></span><span><span></span><span><span>N</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span><span>α</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>α</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>+</span><span></span></span><span><span></span><span><span>β</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>]</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4080"><span data-slate-object="text" data-key="4081"><span data-slate-leaf="true" data-offset-key="4081:0" data-first-offset="true"><span data-slate-string="true">其中 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4082"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>σ</span><span>(</span><span>⋅</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="4084"><span data-slate-leaf="true" data-offset-key="4084:0" data-first-offset="true"><span data-slate-string="true"> 是输出层的激活函数，其最常见的选择是</span></span></span><span data-slate-object="text" data-key="4085"><span data-slate-leaf="true" data-offset-key="4085:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">对数几率函数</span></span></span></span><span data-slate-object="text" data-key="4086"><span data-slate-leaf="true" data-offset-key="4086:0" data-first-offset="true"><span data-slate-string="true">，这时输出层实质上就是个逻辑回归分类器。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4087"><span data-slate-object="text" data-key="4088"><span data-slate-leaf="true" data-offset-key="4088:0" data-first-offset="true"><span data-slate-string="true">除了对数几率函数之外，</span></span></span><span data-slate-object="text" data-key="4089"><span data-slate-leaf="true" data-offset-key="4089:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">双曲正切函数</span></span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4090"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span> t</span><span>a</span><span>n</span><span>h</span></span></span></span></span></span><span data-slate-object="text" data-key="4092"><span data-slate-leaf="true" data-offset-key="4092:0" data-first-offset="true"><span data-slate-string="true">（hyperbolic tangent）也是不错的选择，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4093"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>t</span><span>a</span><span>n</span><span>h</span></span></span></span></span></span><span data-slate-object="text" data-key="4095"><span data-slate-leaf="true" data-offset-key="4095:0" data-first-offset="true"><span data-slate-string="true"> 的值域是 [-1, +1]，这让它的特性和对数几率函数略有差别。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4096"><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4097"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>h</span><span>(</span><span>⋅</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="4099"><span data-slate-leaf="true" data-offset-key="4099:0" data-first-offset="true"><span data-slate-string="true"> 表示的是隐藏层的激活函数，它既可以与 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4100"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>σ</span><span>(</span><span>⋅</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="4102"><span data-slate-leaf="true" data-offset-key="4102:0" data-first-offset="true"><span data-slate-string="true"> 相同，也可以选取其他的非线性函数。</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4103"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>α</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4105"><span data-slate-leaf="true" data-offset-key="4105:0" data-first-offset="true"><span data-slate-string="true"> 和 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4106"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>β</span><span><span><span><span><span><span></span><span><span>j</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="4108"><span data-slate-leaf="true" data-offset-key="4108:0" data-first-offset="true"><span data-slate-string="true"> 分别表示了隐藏层和输出层的权重系数与偏置。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4109"><span data-slate-object="text" data-key="4110"><span data-slate-leaf="true" data-offset-key="4110:0" data-first-offset="true"><span data-slate-string="true">从上面的公式中不难看出，</span></span></span><span data-slate-object="text" data-key="4111"><span data-slate-leaf="true" data-offset-key="4111:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">神经网络的每个神经元都可以看成是做了基函数扩展的线性模型</span></span></span></span><span data-slate-object="text" data-key="4112"><span data-slate-leaf="true" data-offset-key="4112:0" data-first-offset="true"><span data-slate-string="true">：非线性的激活函数不仅将输出变成了输入属性的非线性函数，也变成了权重系数的非线性函数，体现的是整体的非线性处理。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4113"><span data-slate-object="text" data-key="4114"><span data-slate-leaf="true" data-offset-key="4114:0" data-first-offset="true"><span data-slate-string="true">当所有的激活函数都取恒等函数时，神经网络就将退化成最基础的线性回归。但神经网络的动态学习能力可以自适应地调整模型的参数，也就是线性组合中的权重系数。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4115"><span data-slate-object="text" data-key="4116"><span data-slate-leaf="true" data-offset-key="4116:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">神经网络的一个创新之处在于隐藏层的引入</span></span></span></span><span data-slate-object="text" data-key="4117"><span data-slate-leaf="true" data-offset-key="4117:0" data-first-offset="true"><span data-slate-string="true">。除了输入层和输出层之外，所有无法直接观察的层都属于隐藏层（hidden layer）。</span></span></span><span data-slate-object="text" data-key="4118"><span data-slate-leaf="true" data-offset-key="4118:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">隐藏层的输出可以看成是某种导出特征（derived feature），它并不直接存在于输入之中，却可以根据对输入特征的挖掘推导出来</span></span></span></span><span data-slate-object="text" data-key="4119"><span data-slate-leaf="true" data-offset-key="4119:0" data-first-offset="true"><span data-slate-string="true">。神经网络的强大之处就是能够自适应地提取并修正人造特征，从而适配到数据中潜在存在的模式，深度学习优异的性能便由此而来。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4120"><span data-slate-object="text" data-key="4121"><span data-slate-leaf="true" data-offset-key="4121:0" data-first-offset="true"><span data-slate-string="true">在解决分类问题时，对神经网络的参数优化依赖于对</span></span></span><span data-slate-object="text" data-key="4122"><span data-slate-leaf="true" data-offset-key="4122:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">交叉熵</span></span></span></span><span data-slate-object="text" data-key="4123"><span data-slate-leaf="true" data-offset-key="4123:0" data-first-offset="true"><span data-slate-string="true">（cross-entropy）的最小化。网络输出的分类结果 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4124"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>t</span></span></span></span></span></span><span data-slate-object="text" data-key="4126"><span data-slate-leaf="true" data-offset-key="4126:0" data-first-offset="true"><span data-slate-string="true"> 满足两点分布，它关于数据 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4127"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4129"><span data-slate-leaf="true" data-offset-key="4129:0" data-first-offset="true"><span data-slate-string="true"> 和参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4130"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4132"><span data-slate-leaf="true" data-offset-key="4132:0" data-first-offset="true"><span data-slate-string="true"> 的似然概率可以写成</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="4133"><span><span><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>t</span><span>∣</span><span><span><span>x</span></span></span><span>,</span><span></span><span><span><span>w</span></span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>y</span><span>(</span><span><span><span>x</span></span></span><span>,</span><span></span><span><span><span>w</span></span></span><span><span>)</span><span><span><span><span><span><span></span><span><span>t</span></span></span></span></span></span></span></span><span>[</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span>y</span><span>(</span><span><span><span>x</span></span></span><span>,</span><span></span><span><span><span>w</span></span></span><span>)</span><span><span>]</span><span><span><span><span><span><span></span><span><span><span>1</span><span>−</span><span>t</span></span></span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4135"><span data-slate-object="text" data-key="4136"><span data-slate-leaf="true" data-offset-key="4136:0" data-first-offset="true"><span data-slate-string="true">其中 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4137"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>y</span><span>(</span><span><span><span>x</span></span></span><span>,</span><span></span><span><span><span>w</span></span></span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="4139"><span data-slate-leaf="true" data-offset-key="4139:0" data-first-offset="true"><span data-slate-string="true"> 是输出层激活函数为对数几率函数时的输出，可以视为 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4140"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4142"><span data-slate-leaf="true" data-offset-key="4142:0" data-first-offset="true"><span data-slate-string="true"> 归属于正类的条件概率。求解上面式子的负对数似然，得到的就是交叉熵误差函数</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="4143"><span><span><span aria-hidden="true"><span><span></span><span>E</span><span>(</span><span><span><span>w</span></span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>−</span><span></span><span><span><span><span><span><span></span><span><span><span>n</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∑</span></span></span><span><span></span><span><span>N</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span>[</span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>ln</span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span>(</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>ln</span><span>(</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span>]</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4145"><span data-slate-object="text" data-key="4146"><span data-slate-leaf="true" data-offset-key="4146:0" data-first-offset="true"><span data-slate-string="true">交叉熵的最小化与似然概率的最大化是等效的。误差函数的最小值可以通过反向传播（backpropagation）方法来求解，这在上一季的专栏中已经有过介绍，这里就不重复了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4147"><span data-slate-object="text" data-key="4148"><span data-slate-leaf="true" data-offset-key="4148:0" data-first-offset="true"><span data-slate-string="true">神经网络中隐藏神经元的数目决定着网络的泛化性能，足够多的神经元可以实现任意复杂的函数，却也会带来严重的过拟合倾向，因而通过正则化的手段来控制网络的复杂度和性能是非常必要的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4149"><span data-slate-object="text" data-key="4150"><span data-slate-leaf="true" data-offset-key="4150:0" data-first-offset="true"><span data-slate-string="true">一种简单的策略是</span></span></span><span data-slate-object="text" data-key="4151"><span data-slate-leaf="true" data-offset-key="4151:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">权重衰减</span></span></span></span><span data-slate-object="text" data-key="4152"><span data-slate-leaf="true" data-offset-key="4152:0" data-first-offset="true"><span data-slate-string="true">（weight decay），它与前面介绍过的岭回归类似，也是通过添加二次的正则化项来避免过拟合。权重衰减的误差函数可以写成</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="4153"><span><span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span></span><span>E</span></span><span><span></span><span>~</span></span></span></span></span></span><span>(</span><span><span><span>w</span></span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>E</span><span>(</span><span><span><span>w</span></span></span><span>)</span><span></span><span>+</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>2</span></span></span><span><span></span><span></span></span><span><span></span><span><span>λ</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span><span><span><span>w</span></span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span><span>w</span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4155"><span data-slate-object="text" data-key="4156"><span data-slate-leaf="true" data-offset-key="4156:0" data-first-offset="true"><span data-slate-string="true">这里的 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4157"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>λ</span></span></span></span></span></span><span data-slate-object="text" data-key="4159"><span data-slate-leaf="true" data-offset-key="4159:0" data-first-offset="true"><span data-slate-string="true"> 是个超参数，控制着权重衰减的幅度。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4160"><span data-slate-object="text" data-key="4161"><span data-slate-leaf="true" data-offset-key="4161:0" data-first-offset="true"><span data-slate-string="true">另一种经常应用于神经网络中的正则化是</span></span></span><span data-slate-object="text" data-key="4162"><span data-slate-leaf="true" data-offset-key="4162:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">早停</span></span></span></span><span data-slate-object="text" data-key="4163"><span data-slate-leaf="true" data-offset-key="4163:0" data-first-offset="true"><span data-slate-string="true">（early stopping）。早停是建立在验证数据集上的正则化策略，简单地说就是对每一轮次训练出的模型计算出其在验证集上的性能，并将当前模型的参数和超参数存储下来。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4164"><span data-slate-object="text" data-key="4165"><span data-slate-leaf="true" data-offset-key="4165:0" data-first-offset="true"><span data-slate-string="true">在之后的每一轮训练中，训练结果在验证集上的性能都被拿来和先前存储的模型性能进行比较，之后保留两者中表现较好的模型的配置。这种策略和感知器训练中的口袋算法（pocket algorithm）类似。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4166"><span data-slate-object="text" data-key="4167"><span data-slate-leaf="true" data-offset-key="4167:0" data-first-offset="true"><span data-slate-string="true">如果从贝叶斯的角度去分析神经网络，模型训练的任务就变成了根据先验假设和训练数据来计算未知参数的后验分布，再对参数的分布积分来计算预测结果，写成数学表达式就是</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="4168"><span><span><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>n</span><span>e</span><span>w</span></span></span></span></span></span></span></span></span><span>∣</span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>n</span><span>e</span><span>w</span></span></span></span></span></span></span></span></span><span>,</span><span></span><span>D</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>∫</span><span></span><span>p</span><span>(</span><span><span>y</span><span><span><span><span><span><span></span><span><span><span>n</span><span>e</span><span>w</span></span></span></span></span></span></span></span></span><span>∣</span><span><span>x</span><span><span><span><span><span><span></span><span><span><span>n</span><span>e</span><span>w</span></span></span></span></span></span></span></span></span><span>,</span><span></span><span><span><span>w</span></span></span><span>)</span><span>p</span><span>(</span><span><span><span>w</span></span></span><span>∣</span><span>D</span><span>)</span><span><span><span>d</span></span></span><span><span><span>w</span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4170"><span data-slate-object="text" data-key="4171"><span data-slate-leaf="true" data-offset-key="4171:0" data-first-offset="true"><span data-slate-string="true">其中的 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4172"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>D</span></span></span></span></span></span><span data-slate-object="text" data-key="4174"><span data-slate-leaf="true" data-offset-key="4174:0" data-first-offset="true"><span data-slate-string="true"> 表示数据集。积分式中的第一项在分类中就对应着对数几率函数的输出，第二项则是参数的后验概率。对神经网络的贝叶斯分析涉及大量的复杂运算，所以我在这里就只介绍一些基本的思路。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4175"><span data-slate-object="text" data-key="4176"><span data-slate-leaf="true" data-offset-key="4176:0" data-first-offset="true"><span data-slate-string="true">在用于分类的神经网络中，先验假设就是参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4177"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4179"><span data-slate-leaf="true" data-offset-key="4179:0" data-first-offset="true"><span data-slate-string="true"> 的概率分布，这个分布通常被处理成</span></span></span><span data-slate-object="text" data-key="4180"><span data-slate-leaf="true" data-offset-key="4180:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">零均值的高斯分布</span></span></span></span><span data-slate-object="text" data-key="4181"><span data-slate-leaf="true" data-offset-key="4181:0" data-first-offset="true"><span data-slate-string="true">。这个高斯分布的参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4182"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>α</span></span></span></span></span></span><span data-slate-object="text" data-key="4184"><span data-slate-leaf="true" data-offset-key="4184:0" data-first-offset="true"><span data-slate-string="true"> 又可以用超先验来表示。由于分类结果是离散的随机变量，它不像连续变量一样存在估计值和真实值的偏差，也就不用对这部分误差定义先验了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4185"><span data-slate-object="text" data-key="4186"><span data-slate-leaf="true" data-offset-key="4186:0" data-first-offset="true"><span data-slate-string="true">虽然参数本身的先验分布是高斯形式，但激活函数的非线性特性会导致给定数据时参数对于数据的后验概率不满足高斯分布，这时就需要使用</span></span></span><span data-slate-object="text" data-key="4187"><span data-slate-leaf="true" data-offset-key="4187:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">拉普拉斯近似</span></span></span></span><span data-slate-object="text" data-key="4188"><span data-slate-leaf="true" data-offset-key="4188:0" data-first-offset="true"><span data-slate-string="true">（Laplace approximation）生成一个高斯分布，作为对未知后验的模拟。拉普拉斯近似的具体细节在这里暂且略过，你只需要知道它的用处就可以了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4189"><span data-slate-object="text" data-key="4190"><span data-slate-leaf="true" data-offset-key="4190:0" data-first-offset="true"><span data-slate-string="true">在生成高斯分布时，拉普拉斯近似需要找到后验概率的一个最大值，这等效于对添加正则化项的误差函数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4191"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span><span><span><span><span></span><span>E</span></span><span><span></span><span>~</span></span></span></span></span></span><span>(</span><span><span><span>w</span></span></span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="4193"><span data-slate-leaf="true" data-offset-key="4193:0" data-first-offset="true"><span data-slate-string="true"> 进行最小化，其中的正则化项就是参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4194"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4196"><span data-slate-leaf="true" data-offset-key="4196:0" data-first-offset="true"><span data-slate-string="true"> 先验分布的体现。利用复杂的数值计算方法可以求出后验概率的最大值，进而确定后验概率的高斯近似。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4197"><span data-slate-object="text" data-key="4198"><span data-slate-leaf="true" data-offset-key="4198:0" data-first-offset="true"><span data-slate-string="true">处理完了参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4199"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4201"><span data-slate-leaf="true" data-offset-key="4201:0" data-first-offset="true"><span data-slate-string="true">，还要处理超参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4202"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>α</span></span></span></span></span></span><span data-slate-object="text" data-key="4204"><span data-slate-leaf="true" data-offset-key="4204:0" data-first-offset="true"><span data-slate-string="true">。在后验概率的计算中，和参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4205"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4207"><span data-slate-leaf="true" data-offset-key="4207:0" data-first-offset="true"><span data-slate-string="true"> 相关的超参数被看成是已知的固定值。但在计算预测结果时，还需要考虑超参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4208"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>α</span></span></span></span></span></span><span data-slate-object="text" data-key="4210"><span data-slate-leaf="true" data-offset-key="4210:0" data-first-offset="true"><span data-slate-string="true"> 的分布。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4211"><span data-slate-object="text" data-key="4212"><span data-slate-leaf="true" data-offset-key="4212:0" data-first-offset="true"><span data-slate-string="true">对参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4213"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="4215"><span data-slate-leaf="true" data-offset-key="4215:0" data-first-offset="true"><span data-slate-string="true"> 进行积分可以得到数据关于超参数的似然分布，也就是</span></span></span><span data-slate-object="text" data-key="4216"><span data-slate-leaf="true" data-offset-key="4216:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">边际似然函数</span></span></span></span><span data-slate-object="text" data-key="4217"><span data-slate-leaf="true" data-offset-key="4217:0" data-first-offset="true"><span data-slate-string="true">（marginal likelihood）。对边际似然函数进行最优化可以得到关于超参数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="4218"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>α</span></span></span></span></span></span><span data-slate-object="text" data-key="4220"><span data-slate-leaf="true" data-offset-key="4220:0" data-first-offset="true"><span data-slate-string="true"> 的点估计。由于非线性的激活函数让积分难以计算，通常会假设参数的后验概率非常窄，再利用使后验概率最大的参数来计算未知数据的输出。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4221"><span data-slate-object="text" data-key="4222"><span data-slate-leaf="true" data-offset-key="4222:0" data-first-offset="true"><span data-slate-string="true">神经网络是非参数模型的一种，它利用激活函数对线性模型做出了非线性的扩展，让每个输出变成了权重系数的非线性函数，从而在整体上拟合出非线性的效果。更重要的是，它引入了隐藏神经元与隐藏层，这种特殊的结构能够对原始的特征实现重构，从而给数据分析带来了更多的可能。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4223"><span data-slate-object="text" data-key="4224"><span data-slate-leaf="true" data-offset-key="4224:0" data-first-offset="true"><span data-slate-string="true">在 Scikit-learn 中，实现感知器的类 Perceptron 属于线性模型模块 linear_model，这样设置的原因无疑在于感知器本身属于线性判别模型。由于前面使用的中锋 - 中卫数据集是个线性可分的数据集，因此可以用感知器来进行分类。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4225"><span data-slate-object="text" data-key="4226"><span data-slate-leaf="true" data-offset-key="4226:0" data-first-offset="true"><span data-slate-string="true">下图给出了感知器对数据集的分类结果，从左到右的迭代次数分别为 1，3 和 5。可以看出，当初始分类结果有误时，感知器的算法会不断将分类边界向误分类点的方向调整，直到分类正确为止。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4227"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/22/9e/22597330211ee2005ac258dc8663f39e.png?wh=1397*546"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4228"><span data-slate-object="text" data-key="4229"><span data-slate-leaf="true" data-offset-key="4229:0" data-first-offset="true"><span data-slate-type="secondary" data-slate-object="mark"><span data-slate-string="true">感知器对中锋 - 中卫数据集的分类结果</span></span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4230"><span data-slate-object="text" data-key="4231"><span data-slate-leaf="true" data-offset-key="4231:0" data-first-offset="true"><span data-slate-string="true">之前使用过的另一个分类数据集 —— 曼城 - 西布朗数据集是个线性不可分的数据集，可以用它来验证多层感知器的性能。实现多层感知器的类叫做 MLPClassifier，在神经网络模块 neural_network 之中。但由于这个数据集是近似线性可分的，即使使用多层感知器也不会生成明显的非线性判决边界，你可以自己运行一下代码并观察结果。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4232"><span data-slate-object="text" data-key="4233"><span data-slate-leaf="true" data-offset-key="4233:0" data-first-offset="true"><span data-slate-string="true">今天我和你分享了感知器和神经网络的基本原理，包含以下四个要点：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="4234"><div data-slate-type="list-line" data-slate-object="block" data-key="4235"><span data-slate-object="text" data-key="4236"><span data-slate-leaf="true" data-offset-key="4236:0" data-first-offset="true"><span data-slate-type="primary" data-slate-object="mark"><span data-slate-string="true"> 神经网络是一类非线性模型，利用非线性的激活函数对输入的线性组合进行分类；</span></span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4237"><span data-slate-object="text" data-key="4238"><span data-slate-leaf="true" data-offset-key="4238:0" data-first-offset="true"><span data-slate-type="primary" data-slate-object="mark"><span data-slate-string="true">神经网络可以通过误差反向传播自适应地调整网络结构中的参数；</span></span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4239"><span data-slate-object="text" data-key="4240"><span data-slate-leaf="true" data-offset-key="4240:0" data-first-offset="true"><span data-slate-type="primary" data-slate-object="mark"><span data-slate-string="true">神经网络中隐藏层的作用是构造出新的导出特征；</span></span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4241"><span data-slate-object="text" data-key="4242"><span data-slate-leaf="true" data-offset-key="4242:0" data-first-offset="true"><span data-slate-type="primary" data-slate-object="mark"><span data-slate-string="true">用贝叶斯方法分析神经网络时，需要使用近似方法来应对非线性导致的计算问题。</span></span></span></span></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4243"><span data-slate-object="text" data-key="4244"><span data-slate-leaf="true" data-offset-key="4244:0" data-first-offset="true"><span data-slate-string="true">2017 年时，神经网络的元老宿耆乔弗雷・辛顿（Geoffrey Hinton）提出了 “胶囊网络”（capsule）的概念。胶囊由神经网络单个层中的若干神经元组合而成，可以看成是层中的一个子层。胶囊可以执行大量的内部计算，并输出一个矢量形式的结果，获得更多的输出信息。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4245"><span data-slate-object="text" data-key="4246"><span data-slate-leaf="true" data-offset-key="4246:0" data-first-offset="true"><span data-slate-string="true">你可以查阅关于胶囊网络的资料，思考它对神经网络的发展有何意义，并在这里分享你的见解。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4247"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/d5/57/d567d00672f7c375143a2db783b38857.jpg?wh=2379*2408"></div></div></div></div></div><div><div></div><div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><textarea placeholder="将学到的知识总结成笔记，方便日后快速查找及复习"></textarea></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div><div><div>确认放弃笔记？</div><div>放弃后所记笔记将不保留。</div></div><div><div>新功能上线，你的历史笔记已初始化为私密笔记，是否一键批量公开？</div><div>批量公开的笔记不会为你同步至部落</div></div><div></div></div><div><div><div>公开</div><div>同步至部落</div></div><div>取消</div><div>完成</div></div><div><span>0/2000</span></div></div><div><div><span>划线</span></div><div></div><div></div><div></div><div><span>笔记</span></div><div></div><div><span>复制</span></div></div></div><div><div><div><span></span></div><p><a href="javascript:void(0);">给文章提建议</a></p></div></div><div><span>©</span> 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 </div></div><div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div><div>Geek__653581f21177</div></div><div><textarea placeholder="由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。" rows="16"></textarea></div><div><div>Ctrl + Enter 发表</div><div>0/2000 字符</div><div>提交留言</div></div></div><div><h2 id="sr-toc-1">精选留言 (7)</h2><ul><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/10/ae/11/f04cc393.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>杨森</span></div></div><div>我虽然难以理解清晰，但是这种方式我是喜欢的，已经不再是基础课了，目的是打通任督二脉。必须到一定难度才能触及到本质。一篇文章看一天我觉得不为过，不懂的名词需要慢慢查询学习了解。希望能度过难关，柳暗花明。</div><div><p>作者回复：是的，不能一直都在基础课转悠。如果看不懂细节可以先理解思想方法，搞清楚模型的思想原理，融会贯通之后再来深入细节。</p></div><div><div>2018-07-30</div><div><div><i></i></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/11/08/a6/fe1992bf.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 吕胜</span></div></div><div>麻烦老师增加一些直观的解释</div><div><div>2018-07-25</div><div><div><i></i><span></span></div><div><i></i><span>2</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/ab/84/9c098ccf.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 吴常亮</span></div></div><div>越来越看不懂了，还是需要老师深入浅出的讲解下去</div><div><div>2018-07-25</div><div><div><i></i><span></span></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/11/41/8d/f14a278d.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 风的轨迹</span></div></div><div>老师我想问一个问题:
“在用于分类的神经网络中，先验假设就是参数 ww 的概率分布，这个分布通常被处理成零均值的高斯分布。”
确实我们在进行神经网络的参数初始化的时候一般都是用高斯分布，但是为什么必须用高斯分布而不能用别的分布呢？</div><div><p>作者回复：我觉得主要是在取值范围，高斯分布的取值基本在 (-3, 3) 范围内，在这个区间里 sigmoid 函数变化比较剧烈。</p></div><div><div>2019-03-14</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Python</span></div></div><div>WC，看到今天终于懂老师写的专栏文章牛逼的地方了，之前看的懵懵懂懂，现在算有点前后融汇的感觉了</div><div><div>2019-01-27</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/11/c4/eb/0cd6d6ff.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>zhoujie</span></div></div><div>一位天才的出现这里天才是指的谁？Hilton 吗？</div><div><p>作者回复：是的</p></div><div><div>2018-09-05</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/11/c4/eb/0cd6d6ff.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>zhoujie</span></div></div><div>关于深度学习，除了那本圣经之外还有其他书籍推荐吗</div><div><p>作者回复: Francois Collet 的 Deep Learning with Python 据说不错，但我没读过</p></div><div><div>2018-09-05</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li></ul><div> 收起评论<span></span></div></div></sr-rd-content>
                            <toc-bg><toc style="width: initial;overflow: auto!important;"class="simpread-font simpread-theme-root" data-reactid=".1p"><outline class="toc-level-h1" data-reactid=".1p.0" style="width: 175px;"><active data-reactid=".1p.0.0" ></active><a class="toc-outline-theme-github" href="#sr-toc-0" data-reactid=".1p.0.1"><span data-reactid=".1p.0.1.0">22 | 自适应的基函数：神经网络</span></a></outline><outline class="toc-level-h2" data-reactid=".1p.1" style="width: 165px;"><active data-reactid=".1p.1.0"></active><a class="toc-outline-theme-github" href="#sr-toc-1" data-reactid=".1p.1.1"><span data-reactid=".1p.1.1.0">精选留言 (7)</span></a></outline></toc></toc-bg>
                            <sr-rd-footer>
                                <sr-rd-footer-group>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                </sr-rd-footer-group>
                                <sr-rd-footer-copywrite>
                                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://time.geekbang.org/column/article/11693" target="_blank">原文地址 </a></div>
                                </sr-rd-footer-copywrite>
                            </sr-rd-footer>
                        </sr-read>
                    </body>
                </html>