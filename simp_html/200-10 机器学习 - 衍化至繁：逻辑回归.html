
                <html lang="en" class="simpread-font simpread-theme-root" style=''>
                    <head>
                        <meta charset="utf-8">
                        <meta http-equiv="content-type" content="text/html; charset=UTF-8;charset=utf-8">
                        <meta http-equiv="X-UA-Compatible" content="IE=Edge">
                        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
                        <meta name="author" content="Kenshin"/>
                        <meta name="description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展" />
                        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, 简悦, 简阅, read mode, reading mode, reader view, firefox, firefox addon, userscript, safari, opera, tampermonkey"/>
                        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:title" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <meta property="og:type" content="website">
                        <meta property="og:local" content="zh_CN"/>
                        <meta property="og:url" content="http://ksria.com/simpread"/>
                        <meta property="og:image" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:image:type" content="image/png"/>
                        <meta property="og:image:width" content="960"/>
                        <meta property="og:image:height" content="355"/>
                        <meta property="og:site_name" content="http://ksria.com/simpread"/>
                        <meta property="og:description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <style type="text/css">.simpread-font{font:300 16px/1.8 -apple-system,PingFang SC,Microsoft Yahei,Lantinghei SC,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#333;text-rendering:optimizelegibility;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased}.simpread-hidden{display:none}.simpread-read-root{display:-webkit-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;margin:0;top:-1000px;left:0;width:100%;z-index:2147483646;overflow-x:hidden;opacity:0;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}.simpread-read-root-show{top:0}.simpread-read-root-hide{top:1000px}sr-read{display:-webkit-flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-flow:column nowrap;flex-flow:column;margin:20px 20%;min-width:400px;min-height:400px;text-align:center}read-process{position:fixed;top:0;left:0;height:3px;width:100%;background-color:#64b5f6;-webkit-transition:width 2s;transition:width 2s;z-index:20000}sr-rd-content-error{display:block;position:relative;margin:0;margin-bottom:30px;padding:25px;background-color:rgba(0,0,0,.05)}sr-rd-footer{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column;font-size:14px}sr-rd-footer,sr-rd-footer-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}sr-rd-footer-group{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-rd-footer-line{width:100%;border-top:1px solid #e0e0e0}sr-rd-footer-text{min-width:150px}sr-rd-footer-copywrite{margin:10px 0 0;color:inherit}sr-rd-footer-copywrite abbr{-webkit-font-feature-settings:normal;font-feature-settings:normal;font-variant:normal;text-decoration:none}sr-rd-footer-copywrite .second{margin:10px 0}sr-rd-footer-copywrite .third a:hover{border:none!important}sr-rd-footer-copywrite .third a:first-child{margin-right:50px}sr-rd-footer-copywrite .sr-icon{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:33px;height:33px;opacity:.8;-webkit-transition:opacity .5s ease;transition:opacity .5s ease;cursor:pointer}sr-rd-footer-copywrite .sr-icon:hover{opacity:1}sr-rd-footer-copywrite a,sr-rd-footer-copywrite a:link,sr-rd-footer-copywrite a:visited{margin:0;padding:0;color:inherit;background-color:transparent;font-size:inherit!important;line-height:normal;text-decoration:none;vertical-align:baseline;vertical-align:initial;border:none!important;box-sizing:border-box}sr-rd-footer-copywrite a:focus,sr-rd-footer-copywrite a:hover,sr-rd-footer a:active{color:inherit;text-decoration:none;border-bottom:1px dotted!important}.simpread-blocks{text-decoration:none!important}.simpread-blocks *{margin:0}.simpread-blocks a{padding:0;text-decoration:none!important}.simpread-blocks img{margin:0;padding:0;border:0;background:transparent;box-shadow:none}.simpread-focus-root{display:block;position:fixed;top:0;left:0;right:0;bottom:0;background-color:hsla(0,0%,92%,.9);z-index:2147483645;opacity:0;-webkit-transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms;transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms}.simpread-focus-highlight{position:relative;box-shadow:0 0 0 20px #fff;background-color:#fff;overflow:visible;z-index:2147483646}.sr-controlbar-bg sr-rd-crlbar,.sr-controlbar-bg sr-rd-crlbar fab{z-index:2147483647}sr-rd-crlbar.controlbar{position:fixed;right:0;bottom:0;width:100px;height:100%;opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}sr-rd-crlbar.controlbar:hover{opacity:1}sr-rd-crlbar fap *{box-sizing:border-box}@media (max-height:620px){fab{zoom:.8}}@media (max-height:783px){dialog-gp dialog-content{max-height:580px}dialog-gp dialog-footer{border-top:1px solid #e0e0e0}}.simpread-highlight-selector{outline:3px dashed #1976d2!important;cursor:pointer!important}.simpread-highlight-controlbar,.simpread-highlight-selector{background-color:#fafafa!important;opacity:.8!important;-webkit-transition:opacity .5s ease!important;transition:opacity .5s ease!important}.simpread-highlight-controlbar{position:relative!important;border:3px dashed #1976d2!important}simpread-highlight,sr-snapshot-ctlbar{position:fixed;top:0;left:0;right:0;padding:15px;height:50px;background-color:rgba(50,50,50,.9);box-shadow:0 2px 5px rgba(0,0,0,.26);box-sizing:border-box;z-index:2147483640}simpread-highlight,sr-highlight-ctl,sr-snapshot-ctlbar{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-highlight-ctl{margin:0 5px;width:50px;height:20px;color:#fff;background-color:#1976d2;border-radius:4px;box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12);cursor:pointer}toc-bg{position:fixed;left:0;top:0;width:50px;height:200px;font-size:medium}toc-bg:hover{z-index:3}.toc-bg-hidden{opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}.toc-bg-hidden:hover{opacity:1;z-index:3}.toc-bg-hidden:hover toc{width:180px}toc *{all:unset}toc{position:fixed;left:0;top:100px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;padding:10px;width:0;max-width:200px;max-height:500px;overflow-x:hidden;overflow-y:hidden;cursor:pointer;border:1px solid hsla(0,0%,62%,.22);-webkit-transition:width .5s;transition:width .5s}toc:hover{overflow-y:auto}toc.mini:hover{width:200px!important}toc::-webkit-scrollbar{width:3px}toc::-webkit-scrollbar-thumb{border-radius:10px;background-color:hsla(36,2%,54%,.5)}toc outline{position:relative;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;padding:2px 0;min-height:21px;line-height:21px;text-align:left}toc outline a,toc outline a:active,toc outline a:focus,toc outline a:visited{display:block;width:100%;color:inherit;font-size:11px;text-decoration:none!important;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}toc outline a:hover{font-weight:700!important}toc outline a.toc-outline-theme-dark,toc outline a.toc-outline-theme-night{color:#fff!important}.toc-level-h1{padding-left:5px}.toc-level-h2{padding-left:15px}.toc-level-h3{padding-left:25px}.toc-level-h4{padding-left:35px}.toc-outline-active{border-left:2px solid #f44336}toc outline active{position:absolute;left:0;top:0;bottom:0;padding:0 0 0 3px;border-left:2px solid #e8e8e8}sr-kbd{background:-webkit-gradient(linear,0 0,0 100%,from(#fff785),to(#ffc542));border:1px solid #e3be23;-o-border-image:none;border-image:none;-o-border-image:initial;border-image:initial;position:absolute;left:0;padding:1px 3px 0;font-size:11px!important;font-weight:700;box-shadow:0 3px 7px 0 rgba(0,0,0,.3);overflow:hidden;border-radius:3px}.sr-kbd-a{position:relative}kbd-mapping{position:fixed;left:5px;bottom:5px;-ms-flex-flow:row;flex-flow:row;width:250px;height:500px;background-color:#fff;border:1px solid hsla(0,0%,62%,.22);box-shadow:0 2px 5px rgba(0,0,0,.26);border-radius:3px}kbd-mapping,kbd-maps{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}kbd-maps{margin:40px 0 20px;width:100%;overflow-x:auto}kbd-maps::-webkit-scrollbar-thumb{background-clip:padding-box;border-radius:10px;border:2px solid transparent;background-color:rgba(85,85,85,.55)}kbd-maps::-webkit-scrollbar{width:10px;-webkit-transition:width .7s cubic-bezier(.4,0,.2,1);transition:width .7s cubic-bezier(.4,0,.2,1)}kbd-mapping kbd-map-title{position:absolute;margin:5px 0;width:100%;font-size:14px;font-weight:700}kbd-maps-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}kbd-maps-title{margin:5px 0;padding-left:53px;font-size:12px;font-weight:700}kbd-map kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fafbfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}kbd-map kbd-name{display:inline-block;text-align:right;width:50px}kbd-map kbd-desc{padding-left:3px}sharecard-bg{position:fixed;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,.4);z-index:2147483647}sharecard{max-width:450px;background-color:#64b5f6}sharecard,sharecard-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-head{margin:25px;color:#fff;border-radius:10px;box-shadow:0 2px 6px 0 rgba(0,0,0,.2),0 25px 50px 0 rgba(0,0,0,.15)}sharecard-card{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-card,sharecard-top{display:-webkit-box;display:-ms-flexbox;display:flex}sharecard-top{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:65px;background-color:#fff;color:#878787;font-size:25px;font-weight:500;border-top-left-radius:10px;border-top-right-radius:10px}sharecard-top span.logos{display:block;width:48px;height:48px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAMAAABg3Am1AAABU1BMVEUAAAAnNJMnNZI3Q5onNJInNJMnNJInNJMnNJI8SJ0tOZY/S55EUKAoNJI6RpwoNJNIU6InNJInNJImNJI7SJwmNJJ2fLUiMJFKVaNCTJ9faK1HUaJOWKVSXaUnNJNYY6pye7cmM5JXYKhwebMjMI8mL4719fW9vb0oNZP/UlLz8/QqN5TAwMAnNJPv7+/Pz8/q6+/p6enNzc3Kysry8vMsOJXc3env7/LU1uXo29vR0dHOzs7ExMTwjo73bW37XV3Aj1TCYELl5u3n5+fW2Obn6O7f4OrZ2+g0QJkxPpgvO5bh4uvS1OTP0ePCwsJQW6ZLVqTs7fHd3d3V1dXqv79VX6lET6A1TIxXUIBSgHxWQnpelHf+WVnopkXqbC7j5Ozi4uLDw8NGUaFATJ9SgH3r6+vGyd7BxNva2trX19ejqM2gpczHx8dze7Zha67Z2dlTgH1aXQeSAAAAJnRSTlMA6ff+497Y8NL+/fv49P379sqab/BeOiX06tzVy8m/tKqpalA7G6oKj0EAAAJlSURBVEjHndNXWxpBFIDhcS2ICRLAkt4Dx4WhLk0E6R0MYoIISrWX5P9f5cwSIRC2+T1czMV5n2FnZwn2eWONUqCAv3H2Uf5Ra1hx4+0WEXtDQW0fCPYJ1EffEfIV4CSROAE4jsePoTFsNmTJF/IeIHF2lgCIn57GodlqDWXBK7IwBYatVlMWFAildPKX7I3m74Z9fsCiQChoimoFQAz04Ad2gH1n9fv9n9hgMNDr9euLWD6fLxQKxaLfb7dTSlahbFVdEPwIQtrAihZQgyKCtCagbQe3xh0QFMgy5MR11+ewYY5/qlZ7vT2xu93ULKjbFLpiUxnIIwjgKmVTLDUFXMrAi2NJWCRLIthTBo4xyOLKpwyqU6CuDCI41hFBCVdOhyLw4FgJ1skCAiyl9BSHbCorgo6VJXTru5hrVCQS8Yr5xLzX59YJSFpVFwD9U0BGC3hGdFpATgRupTGe9R9I1b1ePBvXKDyvq/O/44LT4/E4BUbSCAwj8Evq6HlnOBprx6JhJz8Gktc7xeaP9ndY+0coQvCccFBD4JW60UIY50ciLOAODAQRVOeCHm4Q3Xks6uRDY+CQ+AR4T2wMYh6+jMCIQOp78CFoj0H7EQgIuhI3dGaHCrwgADwCPjJvA372GRigCJg49FUdk3D87pq3zp4SA5zc1Zh9DxfwkpjgUg5Mv+lbeE3McC8Lpu7SA3wk2xzcqL2tN5DfIsQC8HB7UamUy6FQOpTO5QKBQDZbKnWSyUzGjdWCwaDA8+7Le4BNgm3qQGWchYh9s5hNq6wVbBlbwhZYOp3OYOA4zmgEypnM2zj8ByIdedKrH8vDAAAAAElFTkSuQmCC");zoom:.8}sharecard-content{padding:15px;max-height:500px;font-size:20px;text-align:justify;background-color:#2196f3;overflow-x:hidden;overflow-y:auto}sharecard-via{padding:10px;font-size:10px;background-color:#2196f3}sharecard-footer{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:100px;background-color:#fff;color:#878787;font-size:15px;font-weight:500;border-bottom-left-radius:10px;border-bottom-right-radius:10px}sharecard-footer,sharecard-footer div{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sharecard-footer span.qrcode{display:block;width:100px;height:100px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,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")}sharecard-control{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 19px;height:80px;background-color:#fff}simpread-snapshot{width:100%;height:100%;cursor:move;z-index:2147483645}simpread-snapshot,sr-mask{position:fixed;left:0;top:0}sr-mask{background-color:rgba(0,0,0,.1)}.simpread-feedback,.simpread-urlscheme{position:fixed;right:20px;bottom:20px;z-index:2147483646}simpread-feedback,simpread-urlscheme{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;padding:20px 20px 0;width:500px;color:rgba(51,51,51,.87);background-color:#fff;border-radius:3px;box-shadow:0 0 2px rgba(0,0,0,.12),0 2px 2px rgba(0,0,0,.26);overflow:hidden;-webkit-transform-origin:bottom;transform-origin:bottom;-webkit-transition:all .6s ease;transition:all .6s ease}simpread-feedback *,simpread-urlscheme *{font-size:12px!important;box-sizing:border-box}simpread-feedback.active,simpread-urlscheme.active{-webkit-animation-name:srFadeInUp;animation-name:srFadeInUp;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback.hide,simpread-urlscheme.hide{-webkit-animation-name:srFadeInDown;animation-name:srFadeInDown;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback sr-fb-label,simpread-urlscheme sr-urls-label{width:100%}simpread-feedback sr-fb-head,simpread-urlscheme sr-urls-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:5px;width:100%}simpread-feedback sr-fb-content,simpread-urlscheme sr-urls-content{margin-bottom:5px;width:100%}simpread-feedback sr-urls-footer,simpread-urlscheme sr-urls-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-fb-a,simpread-urlscheme sr-urls-a{color:#2163f7;cursor:pointer}simpread-feedback text-field-state,simpread-urlscheme text-field-state{border-top:none rgba(34,101,247,.8)!important;border-left:none rgba(34,101,247,.8)!important;border-right:none rgba(34,101,247,.8)!important;border-bottom:2px solid rgba(34,101,247,.8)!important}simpread-feedback switch,simpread-urlscheme switch{margin-top:0!important}@-webkit-keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@-webkit-keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}@keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}simpread-feedback sr-fb-head{font-weight:700}simpread-feedback sr-fb-content{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column}simpread-feedback sr-fb-content,simpread-feedback sr-fb-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}simpread-feedback sr-fb-footer{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-close{position:absolute;right:20px;cursor:pointer;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s;z-index:200}simpread-feedback sr-close:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin-top:10px}simpread-feedback sr-stars i{margin-right:10px;cursor:pointer}simpread-feedback sr-stars i svg{-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}simpread-feedback sr-stars i svg:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars i.active svg{-webkit-transform:rotate(0) scale(1);transform:rotate(0) scale(1)}simpread-feedback sr-emojis{display:block;height:100px;overflow:hidden}simpread-feedback sr-emoji{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:.3s;transition:.3s}simpread-feedback sr-emoji>svg{margin:15px 0;width:70px;height:70px;-ms-flex-negative:0;flex-shrink:0}simpread-feedback sr-stars-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin:10px 0 20px}</style>
                        <style type="text/css">.simpread-theme-root{font-size:62.5%!important}sr-rd-content,sr-rd-desc,sr-rd-title{width:100%}sr-rd-title{display:-webkit-box;margin:1em 0 .5em;overflow:hidden;text-overflow:ellipsis;text-rendering:optimizelegibility;-webkit-line-clamp:3;-webkit-box-orient:vertical}sr-rd-content{text-align:left;word-break:break-word}sr-rd-desc{text-align:justify;line-height:2.4;margin:0 0 1.2em;box-sizing:border-box}sr-rd-content{font-size:25.6px;font-size:1.6rem;line-height:1.6}sr-rd-content h1,sr-rd-content h1 *,sr-rd-content h2,sr-rd-content h2 *,sr-rd-content h3,sr-rd-content h3 *,sr-rd-content h4,sr-rd-content h4 *,sr-rd-content h5,sr-rd-content h5 *,sr-rd-content h6,sr-rd-content h6 *{word-break:break-all}sr-rd-content div,sr-rd-content p{display:block;float:inherit;line-height:1.6;font-size:25.6px;font-size:1.6rem}sr-rd-content div,sr-rd-content p,sr-rd-content pre,sr-rd-content sr-blockquote{margin:0 0 1.2em;word-break:break-word}sr-rd-content a{padding:0 5px;vertical-align:baseline;vertical-align:initial}sr-rd-content a,sr-rd-content a:link{color:inherit;font-size:inherit;font-weight:inherit;border:none}sr-rd-content a:hover{background:transparent}sr-rd-content img{margin:10px;padding:5px;max-width:100%;background:#fff;border:1px solid #bbb;box-shadow:1px 1px 3px #d4d4d4}sr-rd-content figcaption{text-align:center;font-size:14px}sr-rd-content sr-blockquote{display:block;position:relative;padding:15px 25px;text-align:left;line-height:inherit}sr-rd-content sr-blockquote:before{position:absolute}sr-rd-content sr-blockquote *{margin:0;font-size:inherit}sr-rd-content table{width:100%;margin:0 0 1.2em;word-break:keep-all;word-break:normal;overflow:auto;border:none}sr-rd-content table td,sr-rd-content table th{border:none}sr-rd-content ul{margin:0 0 1.2em;margin-left:1.3em;padding:0;list-style:disc}sr-rd-content ol{list-style:decimal;margin:0;padding:0}sr-rd-content ol li,sr-rd-content ul li{font-size:inherit;list-style:disc;margin:0 0 1.2em}sr-rd-content ol li{list-style:decimal;margin-left:1.3em}sr-rd-content ol li *,sr-rd-content ul li *{margin:0;text-align:left;text-align:initial}sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em}sr-rd-content li ul{list-style:circle}sr-rd-content pre{font-family:Consolas,Monaco,Andale Mono,Source Code Pro,Liberation Mono,Courier,monospace;display:block;padding:15px;line-height:1.5;word-break:break-all;word-wrap:break-word;white-space:pre;overflow:auto}sr-rd-content pre,sr-rd-content pre *,sr-rd-content pre div{font-size:17.6px;font-size:1.1rem}sr-rd-content li pre code,sr-rd-content p pre code,sr-rd-content pre{background-color:transparent;border:none}sr-rd-content pre code{margin:0;padding:0}sr-rd-content pre code,sr-rd-content pre code *{font-size:17.6px;font-size:1.1rem}sr-rd-content pre p{margin:0;padding:0;color:inherit;font-size:inherit;line-height:inherit}sr-rd-content li code,sr-rd-content p code{margin:0 4px;padding:2px 4px;font-size:17.6px;font-size:1.1rem}sr-rd-content mark{margin:0 5px;padding:2px;background:#fffdd1;border-bottom:1px solid #ffedce}.sr-rd-content-img{width:90%;height:auto}.sr-rd-content-img-load{width:48px;height:48px;margin:0;padding:0;border-style:none;border-width:0;background-repeat:no-repeat;background-image:url(data:image/gif;base64,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)}.sr-rd-content-center{text-align:center;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;-webkit-box-orient:vertical}.sr-rd-content-center-small{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.sr-rd-content-center-small img{margin:0;padding:0;border:0;box-shadow:none}img.simpread-img-broken{cursor:pointer}.sr-rd-content-nobeautify{margin:0;padding:0;border:0;box-shadow:0 0 0}sr-rd-mult{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin:0 0 16px;padding:16px 0 24px;width:100%;background-color:#fff;border-radius:4px;box-shadow:0 1px 2px 0 rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}sr-rd-mult:hover{-webkit-transition:all .45s 0ms;transition:all .45s 0ms;box-shadow:1px 1px 8px rgba(0,0,0,.16)}sr-rd-mult sr-rd-mult-content{padding:0 16px;overflow:auto}sr-rd-mult sr-rd-mult-avatar,sr-rd-mult sr-rd-mult-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sr-rd-mult sr-rd-mult-avatar{-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 15px}sr-rd-mult sr-rd-mult-avatar span{display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;max-width:75px;overflow:hidden;text-overflow:ellipsis;text-align:left;font-size:16px;font-size:1rem}sr-rd-mult sr-rd-mult-avatar img{margin-bottom:0;max-width:50px;max-height:50px;width:50px;height:50px;border-radius:50%}sr-rd-mult sr-rd-mult-content img{max-width:80%}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center{margin:0}sr-page{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;width:100%}</style>
                        <style type="text/css">sr-rd-theme-github{display:none}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{position:relative;margin-top:1em;margin-bottom:1pc;font-weight:700;line-height:1.4;text-align:left;color:#363636}sr-rd-content h1{padding-bottom:.3em;font-size:57.6px;font-size:3.6rem;line-height:1.2}sr-rd-content h2{padding-bottom:.3em;font-size:44.8px;font-size:2.8rem;line-height:1.225}sr-rd-content h3{font-size:38.4px;font-size:2.4rem;line-height:1.43}sr-rd-content h4{font-size:32px;font-size:2rem}sr-rd-content h5,sr-rd-content h6{font-size:25.6px;font-size:1.6rem}sr-rd-content h6{color:#777}sr-rd-content ol,sr-rd-content ul{list-style-type:disc;padding:0;padding-left:2em}sr-rd-content ol ol,sr-rd-content ul ol{list-style-type:lower-roman}sr-rd-content ol ol ol,sr-rd-content ol ul ol,sr-rd-content ul ol ol,sr-rd-content ul ul ol{list-style-type:lower-alpha}sr-rd-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all}sr-rd-content table th{font-weight:700}sr-rd-content table td,sr-rd-content table th{padding:6px 13px;border:1px solid #ddd}sr-rd-content table tr{background-color:#fff;border-top:1px solid #ccc}sr-rd-content table tr:nth-child(2n){background-color:#f8f8f8}sr-rd-content sr-blockquote{border-left:4px solid #ddd}.simpread-theme-root{background-color:#fff;color:#333}sr-rd-title{font-family:PT Sans,SF UI Display,\.PingFang SC,PingFang SC,Neue Haas Grotesk Text Pro,Arial Nova,Segoe UI,Microsoft YaHei,Microsoft JhengHei,Helvetica Neue,Source Han Sans SC,Noto Sans CJK SC,Source Han Sans CN,Noto Sans SC,Source Han Sans TC,Noto Sans CJK TC,Hiragino Sans GB,sans-serif;font-size:54.4px;font-size:3.4rem;font-weight:700;line-height:1.3}sr-rd-desc{position:relative;margin:0;margin-bottom:30px;padding:25px;padding-left:56px;font-size:28.8px;font-size:1.8rem;color:#777;background-color:rgba(0,0,0,.05);box-sizing:border-box}sr-rd-desc:before{content:"\201C";position:absolute;top:-28px;left:16px;font-size:80px;font-family:Arial;color:rgba(0,0,0,.15)}sr-rd-content,sr-rd-content *,sr-rd-content div,sr-rd-content p{color:#363636;font-weight:400;line-height:1.8}sr-rd-content b *,sr-rd-content strong,sr-rd-content strong * sr-rd-content b{-webkit-animation:none 0s ease 0s 1 normal none running;animation:none 0s ease 0s 1 normal none running;-webkit-backface-visibility:visible;backface-visibility:visible;background:transparent none repeat 0 0/auto auto padding-box border-box scroll;border:medium none currentColor;border-collapse:separate;-o-border-image:none;border-image:none;border-radius:0;border-spacing:0;bottom:auto;box-shadow:none;box-sizing:content-box;caption-side:top;clear:none;clip:auto;color:#000;-webkit-columns:auto;-moz-columns:auto;columns:auto;-webkit-column-count:auto;-moz-column-count:auto;column-count:auto;-webkit-column-fill:balance;-moz-column-fill:balance;column-fill:balance;-webkit-column-gap:normal;-moz-column-gap:normal;column-gap:normal;-webkit-column-rule:medium none currentColor;-moz-column-rule:medium none currentColor;column-rule:medium none currentColor;-webkit-column-span:1;-moz-column-span:1;column-span:1;-webkit-column-width:auto;-moz-column-width:auto;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;direction:ltr;display:inline;empty-cells:show;float:none;font-family:serif;font-size:medium;font-style:normal;font-variant:normal;font-weight:400;font-stretch:normal;line-height:normal;height:auto;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;left:auto;letter-spacing:normal;list-style:disc outside none;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;opacity:1;orphans:2;outline:medium none invert;overflow:visible;overflow-x:visible;overflow-y:visible;padding:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;-webkit-perspective:none;perspective:none;-webkit-perspective-origin:50% 50%;perspective-origin:50% 50%;position:static;right:auto;-moz-tab-size:8;-o-tab-size:8;tab-size:8;table-layout:auto;text-align:left;text-align-last:auto;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;top:auto;-webkit-transform:none;transform:none;-webkit-transform-origin:50% 50% 0;transform-origin:50% 50% 0;-webkit-transform-style:flat;transform-style:flat;-webkit-transition:none 0s ease 0s;transition:none 0s ease 0s;unicode-bidi:normal;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;word-spacing:normal;z-index:auto;all:initial}sr-rd-content a,sr-rd-content a:link{color:#4183c4;text-decoration:none}sr-rd-content a:active,sr-rd-content a:focus,sr-rd-content a:hover{color:#4183c4;text-decoration:underline}sr-rd-content pre{background-color:#f7f7f7;border-radius:3px}sr-rd-content li code,sr-rd-content p code{background-color:rgba(0,0,0,.04);border-radius:3px}.simpread-multi-root{background:#f8f9fa}</style>
                        <style type="text/css"></style>
                        <style type="text/css">@media (pointer:coarse){sr-read{margin:20px 5%!important;min-width:0!important;max-width:90%!important}sr-rd-title{margin-top:0;font-size:2.7rem}sr-rd-content sr-blockquote,sr-rd-desc{margin:10 0!important;padding:0 0 0 10px!important;width:90%;font-size:1.8rem;font-style:normal;line-height:1.7;text-align:justify}sr-rd-content{font-size:1.75rem;font-weight:300}sr-rd-content figure{margin:0;padding:0;text-align:center}sr-rd-content a,sr-rd-content a:link,sr-rd-content li code,sr-rd-content p code{font-size:inherit}sr-rd-footer{margin-top:20px}sr-blockquote,sr-blockquote *{margin:5px!important;padding:5px!important}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6,sr-rd-title{font-family:PingFang SC,Verdana,Helvetica Neue,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;font-weight:100;line-height:1.35}sr-rd-content-h1,sr-rd-content-h2,sr-rd-content-h3,sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}sr-rd-content-h1,sr-rd-content h1{font-size:1.8em}sr-rd-content-h2,sr-rd-content h2{font-size:1.6em}sr-rd-content-h3,sr-rd-content h3{font-size:1.4em}sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{font-size:1.2em}sr-rd-content-ul,sr-rd-content ul{margin-left:1.3em!important;list-style:disc}sr-rd-content-ol,sr-rd-content ol{list-style:decimal;margin-left:1.9em!important}sr-rd-content-ol ol,sr-rd-content-ol ul,sr-rd-content-ul ol,sr-rd-content-ul ul,sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em!important}sr-rd-content img{margin:0;padding:0;border:0;max-width:100%!important;height:auto;box-shadow:0 20px 20px -10px rgba(0,0,0,.1)}sr-rd-mult{min-width:0;background-color:#fff;box-shadow:0 1px 6px rgba(32,33,36,.28);border-radius:8px}sr-rd-mult sr-rd-mult-avatar div{margin:0}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center-small{margin:7px 0!important}sr-rd-mult sr-rd-mult-avatar span{display:block}sr-rd-mult sr-rd-mult-content{padding-left:0}@media only screen and (max-device-width:1024px){.simpread-theme-root,html.simpread-theme-root{font-size:80%!important}sr-rd-mult sr-rd-mult-avatar img{width:50px;height:50px;min-width:50px;min-height:50px}toc-bg toc{width:10px!important}toc-bg:hover toc{width:auto!important}}@media only screen and (max-device-width:414px){.simpread-theme-root,html.simpread-theme-root{font-size:70%!important}sr-rd-mult sr-rd-mult-avatar img{width:30px;height:30px;min-width:30px;min-height:30px}}@media only screen and (max-device-width:320px){.simpread-theme-root,html.simpread-theme-root{font-size:90%!important}sr-rd-content p{margin-bottom:.5em}}}</style>
                        <style type="text/css">undefinedsr-rd-content *, sr-rd-content p, sr-rd-content div {}sr-rd-content pre code, sr-rd-content pre code * {}sr-rd-desc {}sr-rd-content pre {}sr-rd-title {}</style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css">sr-rd-content *, sr-rd-content p, sr-rd-content div {
        font-size: 15px;
    }

    .annote-perview, .annote-perview * {
        color: rgb(85, 85, 85);
        font-weight: 400;
        line-height: 1.8;
    }</style>
                        
                        
                        <script>setTimeout(()=>{const e=location.hash.replace("#id=","");let t,a=!1;const n=t=>{for(let n of t){let t;if((t=e.length>6?n.getAttribute("data-id"):n.getAttribute("data-idx"))==e){n.scrollIntoView({behavior:"smooth",block:"start",inline:"nearest"}),a=!0;break}}};e&&(0==(t=document.getElementsByClassName("sr-unread-card")).length&&(t=document.getElementsByTagName("sr-annote")),n(t),a||n(t=document.getElementsByClassName("sr-annote")))},500);</script>
                        <script>document.addEventListener("DOMContentLoaded",function(){if("localhost"==location.hostname){const t=document.getElementsByTagName("img");for(let o of t){const t=o.src;t.startsWith("http")&&(o.src=location.origin+"/proxy?url="+t)}}},!1);</script>
                        <style>toc a {font-size: inherit!important;font-weight: 300!important;}</style><script>setTimeout(()=>{const max=document.getElementsByTagName('sr-annote-note-tip').length;for(let i=0;i<max;i++){const target=document.getElementsByTagName('sr-annote-note-tip')[i],value=target.dataset.value;value&&(target.innerText=value)}},1000);</script><title>简悦 | 10 机器学习 | 衍化至繁：逻辑回归</title>
                    </head>
                    <body>
                        <sr-read style='font-family: "LXGW WenKai Screen";'>
                            <sr-rd-title>10 机器学习 | 衍化至繁：逻辑回归</sr-rd-title>
                    <sr-rd-desc style="margin: 0;padding-top: 0;padding-bottom: 0;font-style: normal;font-size: 18px;">人工智能基础课结课了！来做个结课测试吧！</sr-rd-desc>
                    <sr-rd-content><h1 id="sr-toc-0">10 机器学习 | 衍化至繁：逻辑回归</h1><div><span>王天一</span> <span> 2017-12-30</span></div><div><div><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/e2/9e/e208b6727c8da590e7f1f6a4b1edae9e.jpg" style="width: auto;"></div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADEAAAABCAYAAAB35kaxAAAAAXNSR0IArs4c6QAAAChJREFUGFdjfPfu3X8GKBAUFASz3r9/DxNiQBbDxcamn1yzSLEDZi8A2agny86FR+IAAAAASUVORK5CYII="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAABCAYAAAA8TpVcAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFCYtjkAcT9D8ti7hUOAAAAAElFTkSuQmCC"></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD0AAAABCAYAAABt2qY/AAAAAXNSR0IArs4c6QAAACdJREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULy2PQQK0YLewiZCQDhUS3LBhDf1QAAAABJRU5ErkJggg=="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAABCAYAAAA4u0VhAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULyAF6lD8tbqYWOAAAAAElFTkSuQmCC"></div></div></div><div><div><div></div></div><div><div><div><div><div><div>00:00</div></div><div></div></div></div><a href="javascript:;"> 1.0x <i><span></span></i></a></div><div><span>讲述：王天一</span><span>大小：5.60M</span><span> 时长：12:13</span></div></div><audio title="10 机器学习 | 衍化至繁：逻辑回归" src="https://res001.geekbang.org/media/audio/91/c8/91ac5e7a8fa259d498160fec8c1c68c8/ld.m3u8"></audio></div><div><div><div><div data-slate-editor="true" data-key="2082" autocorrect="off" spellcheck="false" data-gramm="false"><div data-slate-type="paragraph" data-slate-object="block" data-key="2083"><span data-slate-object="text" data-key="2084"><span data-slate-leaf="true" data-offset-key="2084:0" data-first-offset="true"><span data-slate-string="true">周四我和你分享了机器学习中的朴素贝叶斯分类算法，这一算法解决的是将连续取值的输入映射为离散取值的输出的分类问题。朴素贝叶斯分类器是一类</span></span></span><span data-slate-object="text" data-key="2085"><span data-slate-leaf="true" data-offset-key="2085:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">生成模型</span></span></span></span><span data-slate-object="text" data-key="2086"><span data-slate-leaf="true" data-offset-key="2086:0" data-first-offset="true"><span data-slate-string="true">，通过构造联合概率分布 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2087"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>P</span><span>(</span><span>X</span><span>,</span><span></span><span>Y</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2089"><span data-slate-leaf="true" data-offset-key="2089:0" data-first-offset="true"><span data-slate-string="true"> 实现分类。如果换一种思路，转而用</span></span></span><span data-slate-object="text" data-key="2090"><span data-slate-leaf="true" data-offset-key="2090:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">判别模型</span></span></span></span><span data-slate-object="text" data-key="2091"><span data-slate-leaf="true" data-offset-key="2091:0" data-first-offset="true"><span data-slate-string="true">解决分类问题的话，得到的算法就是 “</span></span></span><span data-slate-object="text" data-key="2092"><span data-slate-leaf="true" data-offset-key="2092:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">逻辑回归</span></span></span></span><span data-slate-object="text" data-key="2093"><span data-slate-leaf="true" data-offset-key="2093:0" data-first-offset="true"><span data-slate-string="true">”。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2094"><span data-slate-object="text" data-key="2095"><span data-slate-leaf="true" data-offset-key="2095:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">虽然顶着 “回归” 的名号，但逻辑回归解决的却是实打实的分类问题</span></span></span></span><span data-slate-object="text" data-key="2096"><span data-slate-leaf="true" data-offset-key="2096:0" data-first-offset="true"><span data-slate-string="true">。之所以取了这个名字，原因在于它来源于对线性回归算法的改进。通过引入单调可微函数 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2097"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>g</span><span>(</span><span>⋅</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2099"><span data-slate-leaf="true" data-offset-key="2099:0" data-first-offset="true"><span data-slate-string="true">，线性回归模型就可以推广为 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2100"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span><span>g</span><span><span><span><span><span><span></span><span><span><span>−</span><span>1</span></span></span></span></span></span></span></span></span><span>(</span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2102"><span data-slate-leaf="true" data-offset-key="2102:0" data-first-offset="true"><span data-slate-string="true">，进而将线性回归模型的连续预测值与分类任务的离散标记联系起来。当 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2103"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>g</span><span>(</span><span>⋅</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2105"><span data-slate-leaf="true" data-offset-key="2105:0" data-first-offset="true"><span data-slate-string="true"> 取成对数函数的形式时，线性回归就演变为了逻辑回归。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2106"><span data-slate-object="text" data-key="2107"><span data-slate-leaf="true" data-offset-key="2107:0" data-first-offset="true"><span data-slate-string="true">在最简单的二分类问题中，分类的标记可以抽象为 0 和 1，因而线性回归中的实值输出需要映射为二进制的结果。逻辑回归中，实现这一映射是对数几率函数，也叫 Sigmoid 函数</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2108"><span><span><span aria-hidden="true"><span><span></span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>+</span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span>−</span><span>z</span></span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>+</span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span>−</span><span>(</span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span><span>)</span></span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2110"><span data-slate-object="text" data-key="2111"><span data-slate-leaf="true" data-offset-key="2111:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">之所以选择对数几率函数，是因为它具备良好的特性</span></span></span></span><span data-slate-object="text" data-key="2112"><span data-slate-leaf="true" data-offset-key="2112:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2113"><span data-slate-object="text" data-key="2114"><span data-slate-leaf="true" data-offset-key="2114:0" data-first-offset="true"><span data-slate-string="true">首先，对数几率函数能够将线性回归从负无穷到正无穷的输出范围压缩到 (0, 1) 之间，无疑更加符合对二分类任务的直观感觉。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2115"><span data-slate-object="text" data-key="2116"><span data-slate-leaf="true" data-offset-key="2116:0" data-first-offset="true"><span data-slate-string="true">其次，当线性回归的结果 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2117"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>z</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span></span></span><span data-slate-object="text" data-key="2119"><span data-slate-leaf="true" data-offset-key="2119:0" data-first-offset="true"><span data-slate-string="true"> 时，逻辑回归的结果 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2120"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>.</span><span>5</span></span></span></span></span></span><span data-slate-object="text" data-key="2122"><span data-slate-leaf="true" data-offset-key="2122:0" data-first-offset="true"><span data-slate-string="true">，这可以视为一个分界点：当 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2123"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>z</span><span></span><span>&gt;</span><span></span></span><span><span></span><span>0</span></span></span></span></span></span><span data-slate-object="text" data-key="2125"><span data-slate-leaf="true" data-offset-key="2125:0" data-first-offset="true"><span data-slate-string="true"> 时，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2126"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>y</span><span></span><span>&gt;</span><span></span></span><span><span></span><span>0</span><span>.</span><span>5</span></span></span></span></span></span><span data-slate-object="text" data-key="2128"><span data-slate-leaf="true" data-offset-key="2128:0" data-first-offset="true"><span data-slate-string="true">，此时逻辑回归的结果就可以判为正例；当 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2129"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>z</span><span></span><span>&lt;</span><span></span></span><span><span></span><span>0</span></span></span></span></span></span><span data-slate-object="text" data-key="2131"><span data-slate-leaf="true" data-offset-key="2131:0" data-first-offset="true"><span data-slate-string="true"> 时，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2132"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>y</span><span></span><span>&lt;</span><span></span></span><span><span></span><span>0</span><span>.</span><span>5</span></span></span></span></span></span><span data-slate-object="text" data-key="2134"><span data-slate-leaf="true" data-offset-key="2134:0" data-first-offset="true"><span data-slate-string="true">，逻辑回归的结果就可以判为反例。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2135"><span data-slate-object="text" data-key="2136"><span data-slate-leaf="true" data-offset-key="2136:0" data-first-offset="true"><span data-slate-string="true">显然，对数几率函数能够在线性回归和逻辑回归之间提供更好的可解释性。这种可解释性可以从数学的角度进一步诠释。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2137"><span data-slate-object="text" data-key="2138"><span data-slate-leaf="true" data-offset-key="2138:0" data-first-offset="true"><span data-slate-string="true">如果将对数几率函数的结果 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2139"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>y</span></span></span></span></span></span><span data-slate-object="text" data-key="2141"><span data-slate-leaf="true" data-offset-key="2141:0" data-first-offset="true"><span data-slate-string="true"> 视为样本 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2142"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>x</span></span></span></span></span></span></span><span data-slate-object="text" data-key="2144"><span data-slate-leaf="true" data-offset-key="2144:0" data-first-offset="true"><span data-slate-string="true"> 作为正例的可能性，则 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2145"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span>y</span></span></span></span></span></span><span data-slate-object="text" data-key="2147"><span data-slate-leaf="true" data-offset-key="2147:0" data-first-offset="true"><span data-slate-string="true"> 就是其作为反例的可能性，两者的比值 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2148"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>0</span><span></span><span>&lt;</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>−</span><span></span><span>y</span></span></span><span><span></span><span></span></span><span><span></span><span><span>y</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span></span><span>&lt;</span><span></span></span><span><span></span><span>+</span><span>∞</span></span></span></span></span></span><span data-slate-object="text" data-key="2150"><span data-slate-leaf="true" data-offset-key="2150:0" data-first-offset="true"><span data-slate-string="true"> 称为几率，体现的是样本作为正例的相对可能性。如果对几率函数取对数，并将前文中的公式代入，可以得到</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2151"><span><span><span aria-hidden="true"><span><span></span><span>ln</span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>−</span><span></span><span>y</span></span></span><span><span></span><span></span></span><span><span></span><span><span>y</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span></span><span>=</span><span></span></span><span><span></span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span><span></span><span>+</span><span></span></span><span><span></span><span>b</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2153"><span data-slate-object="text" data-key="2154"><span data-slate-leaf="true" data-offset-key="2154:0" data-first-offset="true"><span data-slate-string="true">由此可见，当利用逻辑回归模型解决分类任务时，线性回归的结果正是以对数几率的形式出现的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2155"><span data-slate-object="text" data-key="2156"><span data-slate-leaf="true" data-offset-key="2156:0" data-first-offset="true"><span data-slate-string="true">归根结底，逻辑回归模型由条件概率分布表示</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2157"><span><span><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>∣</span><span><span>x</span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>+</span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span><span>+</span><span>b</span></span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span><span>+</span><span>b</span></span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2159"><span><span><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>∣</span><span><span>x</span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>+</span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span><span>+</span><span>b</span></span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2161"><span data-slate-object="text" data-key="2162"><span data-slate-leaf="true" data-offset-key="2162:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">对于给定的实例，逻辑回归模型比较两个条件概率值的大小，并将实例划分到概率较大的分类之中</span></span></span></span><span data-slate-object="text" data-key="2163"><span data-slate-leaf="true" data-offset-key="2163:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2164"><span data-slate-object="text" data-key="2165"><span data-slate-leaf="true" data-offset-key="2165:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">学习时，逻辑回归模型在给定的训练数据集上应用最大似然估计法确定模型的参数</span></span></span></span><span data-slate-object="text" data-key="2166"><span data-slate-leaf="true" data-offset-key="2166:0" data-first-offset="true"><span data-slate-string="true">。对给定的数据集 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2167"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>(</span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span></span></span></span></span></span></span><span data-slate-object="text" data-key="2169"><span data-slate-leaf="true" data-offset-key="2169:0" data-first-offset="true"><span data-slate-string="true">，逻辑回归使每个样本属于其真实标记的概率最大化，以此为依据确定 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2170"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>w</span></span></span></span></span></span></span><span data-slate-object="text" data-key="2172"><span data-slate-leaf="true" data-offset-key="2172:0" data-first-offset="true"><span data-slate-string="true"> 的最优值。由于每个样本的输出 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2173"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="2175"><span data-slate-leaf="true" data-offset-key="2175:0" data-first-offset="true"><span data-slate-string="true"> 都满足两点分布，且不同的样本之间相互独立，因而似然函数可以表示为</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2176"><span><span><span aria-hidden="true"><span><span></span><span>L</span><span>(</span><span><span>w</span></span><span>∣</span><span><span>x</span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span>Π</span><span><span><span><span><span><span></span><span><span><span>i</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>N</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>[</span><span>p</span><span>(</span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>∣</span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>w</span></span><span>)</span><span><span>]</span><span><span><span><span><span><span></span><span><span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2178"><span><span><span aria-hidden="true"><span><span></span><span>⋅</span><span>[</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span>p</span><span>(</span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>∣</span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>w</span></span><span>)</span><span><span>]</span><span><span><span><span><span><span></span><span><span><span>1</span><span>−</span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2180"><span data-slate-object="text" data-key="2181"><span data-slate-leaf="true" data-offset-key="2181:0" data-first-offset="true"><span data-slate-string="true">利用对数操作将乘积转化为求和，就可以得到对数似然函数</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2182"><span><span><span aria-hidden="true"><span><span></span><span>lo<span>g</span></span><span></span><span>L</span><span>(</span><span><span>w</span></span><span>∣</span><span><span>x</span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>i</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∑</span></span></span><span><span></span><span><span>N</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>lo<span>g</span></span><span>[</span><span>p</span><span>(</span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>∣</span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>w</span></span><span>)</span><span>]</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2184"><span><span><span aria-hidden="true"><span><span></span><span>+</span><span>(</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span></span><span>lo<span>g</span></span><span>[</span><span>1</span><span></span><span>−</span><span></span></span><span><span></span><span>p</span><span>(</span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>∣</span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>w</span></span><span>)</span><span>]</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2186"><span data-slate-object="text" data-key="2187"><span data-slate-leaf="true" data-offset-key="2187:0" data-first-offset="true"><span data-slate-string="true">由于单个样本的标记 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2188"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="2190"><span data-slate-leaf="true" data-offset-key="2190:0" data-first-offset="true"><span data-slate-string="true"> 只能取得 0 或 1，因而上式中的两项中只有一个有非零的取值。将每个条件概率的对数几率函数形式代入上式，经过化简可以得到</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2191"><span><span><span aria-hidden="true"><span><span></span><span>lo<span>g</span></span><span></span><span>L</span><span>(</span><span><span>w</span></span><span>∣</span><span><span>x</span></span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>i</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∑</span></span></span><span><span></span><span><span>N</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>⋅</span><span></span></span><span><span></span><span>(</span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2193"><span><span><span aria-hidden="true"><span><span></span><span>−</span><span></span><span>lo<span>g</span></span><span>(</span><span>1</span><span></span><span>+</span><span></span></span><span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span><span>w</span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span>)</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2195"><span data-slate-object="text" data-key="2196"><span data-slate-leaf="true" data-offset-key="2196:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">寻找以上函数的最大值就是以对数似然函数为目标函数的最优化问题，通常通过 “梯度下降法” 或拟 “牛顿法” 求解</span></span></span></span><span data-slate-object="text" data-key="2197"><span data-slate-leaf="true" data-offset-key="2197:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2198"><span data-slate-object="text" data-key="2199"><span data-slate-leaf="true" data-offset-key="2199:0" data-first-offset="true"><span data-slate-string="true">当训练数据集是从所有数据中均匀抽取且数量较大时，以上结果还有一种信息论角度的阐释方式：</span></span></span><span data-slate-object="text" data-key="2200"><span data-slate-leaf="true" data-offset-key="2200:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">对数似然函数的最大化可以等效为待求模型与最大熵模型之间 KL 散度的最小化</span></span></span></span><span data-slate-object="text" data-key="2201"><span data-slate-leaf="true" data-offset-key="2201:0" data-first-offset="true"><span data-slate-string="true">。这意味着最优的估计对参数做出的额外假设是最少的，这无疑与最大熵原理不谋而合。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2202"><span data-slate-object="text" data-key="2203"><span data-slate-leaf="true" data-offset-key="2203:0" data-first-offset="true"><span data-slate-string="true">从数学角度看，线性回归和逻辑回归之间的渊源来源于非线性的对数似然函数；而从特征空间的角度看，两者的区别则在于数据判定边界的变化。判定边界可以类比为棋盘上的楚河汉界，边界两侧分别对应不同类型的数据。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2204"><span data-slate-object="text" data-key="2205"><span data-slate-leaf="true" data-offset-key="2205:0" data-first-offset="true"><span data-slate-string="true">以最简单的二维平面直角坐标系为例。受模型形式的限制，利用线性回归只能得到直线形式的判定边界；逻辑回归则在线性回归的基础上，通过对数似然函数的引入使判定边界的形状不再受限于直线，而是推广为更加复杂的曲线形式，更加精细的分类也就不在话下。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2206"><span data-slate-object="text" data-key="2207"><span data-slate-leaf="true" data-offset-key="2207:0" data-first-offset="true"><span data-slate-string="true">逻辑回归与线性回归的关系称得上系出同门，与朴素贝叶斯分类的关系则是殊途同归。两者虽然都可以利用条件概率 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2208"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>P</span><span>(</span><span>Y</span><span>∣</span><span>X</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2210"><span data-slate-leaf="true" data-offset-key="2210:0" data-first-offset="true"><span data-slate-string="true"> 完成分类任务，实现的路径却截然不同。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2211"><span data-slate-object="text" data-key="2212"><span data-slate-leaf="true" data-offset-key="2212:0" data-first-offset="true"><span data-slate-string="true">朴素贝叶斯分类器是生成模型的代表，</span></span><span data-slate-leaf="true" data-offset-key="2212:1"><span data-slate-object="annotation" data-annotation-key="gkann_5b026868" data-attr-id="30108" data-attr-name="public" data-annotation-type="public"><span data-slate-string="true">其思想是先由训练数据集估计出输入和输出的联合概率分布，</span></span></span><span data-slate-leaf="true" data-offset-key="2212:2"><span data-slate-string="true">再根据联合概率分布来生成符合条件的输出，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2213"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>P</span><span>(</span><span>Y</span><span>∣</span><span>X</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2215"><span data-slate-leaf="true" data-offset-key="2215:0" data-first-offset="true"><span data-slate-string="true"> 以后验概率的形式出现。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2216"><span data-slate-object="text" data-key="2217"><span data-slate-leaf="true" data-offset-key="2217:0" data-first-offset="true"><span data-slate-string="true">逻辑回归模型则是判别模型的代表，其思想是先由训练数据集估计出输入和输出的条件概率分布，再根据条件概率分布来判定对于给定的输入应该选择哪种输出，</span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2218"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>P</span><span>(</span><span>Y</span><span>∣</span><span>X</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2220"><span data-slate-leaf="true" data-offset-key="2220:0" data-first-offset="true"><span data-slate-string="true"> 以似然概率的形式出现。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2221"><span data-slate-object="text" data-key="2222"><span data-slate-leaf="true" data-offset-key="2222:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">即便原理不同，逻辑回归与朴素贝叶斯分类器在特定的条件下依然可以等效</span></span></span></span><span data-slate-object="text" data-key="2223"><span data-slate-leaf="true" data-offset-key="2223:0" data-first-offset="true"><span data-slate-string="true">。用朴素贝叶斯分类器处理二分类任务时，假设对每个 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2224"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="2226"><span data-slate-leaf="true" data-offset-key="2226:0" data-first-offset="true"><span data-slate-string="true">，属性条件概率 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2227"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>∣</span><span>Y</span><span></span><span>=</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>k</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2229"><span data-slate-leaf="true" data-offset-key="2229:0" data-first-offset="true"><span data-slate-string="true"> 都满足正态分布，且正态分布的标准差与输出标记 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2230"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>Y</span></span></span></span></span></span><span data-slate-object="text" data-key="2232"><span data-slate-leaf="true" data-offset-key="2232:0" data-first-offset="true"><span data-slate-string="true"> 无关，那么根据贝叶斯定理，后验概率就可以写成</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2233"><span><span><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>Y</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>∣</span><span>X</span><span>)</span><span></span><span>=</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2235"><span><span><span aria-hidden="true"><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>p</span><span>(</span><span>Y</span><span></span><span>=</span><span></span><span>1</span><span>)</span><span></span><span>⋅</span><span></span><span>p</span><span>(</span><span>X</span><span>∣</span><span>Y</span><span></span><span>=</span><span></span><span>1</span><span>)</span><span></span><span>+</span><span></span><span>p</span><span>(</span><span>Y</span><span></span><span>=</span><span></span><span>0</span><span>)</span><span></span><span>⋅</span><span></span><span>p</span><span>(</span><span>X</span><span>∣</span><span>Y</span><span></span><span>=</span><span></span><span>0</span><span>)</span></span></span><span><span></span><span></span></span><span><span></span><span><span>p</span><span>(</span><span>Y</span><span></span><span>=</span><span></span><span>0</span><span>)</span><span></span><span>⋅</span><span></span><span>p</span><span>(</span><span>X</span><span>∣</span><span>Y</span><span></span><span>=</span><span></span><span>0</span><span>)</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2237"><span><span><span aria-hidden="true"><span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>+</span><span></span><span>exp</span><span>(</span><span>ln</span><span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>p</span><span>(</span><span>Y</span><span>=</span><span>0</span><span>)</span><span>⋅</span><span>p</span><span>(</span><span>X</span><span>∣</span><span>Y</span><span>=</span><span>0</span><span>)</span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>p</span><span>(</span><span>Y</span><span>=</span><span>1</span><span>)</span><span>⋅</span><span>p</span><span>(</span><span>X</span><span>∣</span><span>Y</span><span>=</span><span>1</span><span>)</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span>)</span></span></span><span><span></span><span></span></span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2239"><span data-slate-object="text" data-key="2240"><span data-slate-leaf="true" data-offset-key="2240:0" data-first-offset="true"><span data-slate-string="true">根据朴素贝叶斯方法的假设，类条件概率可以表示为属性条件概率的乘积，因而令 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2241"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>Y</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span>p</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="2243"><span data-slate-leaf="true" data-offset-key="2243:0" data-first-offset="true"><span data-slate-string="true"> 并将满足正态分布的属性条件概率 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2244"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span><span><span>x</span></span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>∣</span><span>Y</span><span></span><span>=</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>k</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2246"><span data-slate-leaf="true" data-offset-key="2246:0" data-first-offset="true"><span data-slate-string="true"> 代入以上表达式中，经过一番计算就可以得到</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2247"><span><span><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>Y</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>∣</span><span>X</span><span>)</span><span></span><span>=</span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2249"><span><span><span aria-hidden="true"><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>1</span><span></span><span>+</span><span></span><span>exp</span><span>(</span><span>ln</span><span></span><span><span></span><span><span><span><span><span><span></span><span><span><span><span>p</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>1</span><span>−</span><span><span>p</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span></span><span>+</span><span></span><span><span><span><span><span><span></span><span><span>i</span></span></span><span><span></span><span><span>∑</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span>(</span><span><span></span><span><span><span><span><span><span></span><span><span><span><span>σ</span><span><span><span><span><span><span></span><span><span>i</span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span><span>μ</span><span><span><span><span><span><span></span><span><span><span>i</span><span>1</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>−</span><span><span>μ</span><span><span><span><span><span><span></span><span><span><span>i</span><span>0</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span><span>X</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span><span><span></span><span><span><span><span><span><span></span><span><span><span>2</span><span><span>σ</span><span><span><span><span><span><span></span><span><span>i</span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span><span>μ</span><span><span><span><span><span><span></span><span><span><span>i</span><span>0</span></span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>−</span><span><span>μ</span><span><span><span><span><span><span></span><span><span><span>i</span><span>1</span></span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span>)</span><span>)</span></span></span><span><span></span><span></span></span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2251"><span data-slate-object="text" data-key="2252"><span data-slate-leaf="true" data-offset-key="2252:0" data-first-offset="true"><span data-slate-string="true">不难看出，上式的形式和逻辑回归中条件概率 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2253"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>∣</span><span><span>x</span></span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2255"><span data-slate-leaf="true" data-offset-key="2255:0" data-first-offset="true"><span data-slate-string="true"> 的形式是完全一致的，这表明朴素贝叶斯方法和逻辑回归模型学习到的是同一个模型。实际上，在 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2256"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>x</span><span>∣</span><span>Y</span><span>)</span></span></span></span></span></span><span data-slate-object="text" data-key="2258"><span data-slate-leaf="true" data-offset-key="2258:0" data-first-offset="true"><span data-slate-string="true"> 的分布属于指数分布族这个更一般的假设下，类似的结论都是成立的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2259"><span data-slate-object="text" data-key="2260"><span data-slate-leaf="true" data-offset-key="2260:0" data-first-offset="true"><span data-slate-string="true">说完了联系，再来看看区别。</span></span></span><span data-slate-object="text" data-key="2261"><span data-slate-leaf="true" data-offset-key="2261:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">两者的区别在于当朴素贝叶斯分类的模型假设不成立时，逻辑回归和朴素贝叶斯方法通常会学习到不同的结果</span></span></span></span><span data-slate-object="text" data-key="2262"><span data-slate-leaf="true" data-offset-key="2262:0" data-first-offset="true"><span data-slate-string="true">。当训练样本数接近无穷大时，逻辑回归的渐近分类准确率要优于朴素贝叶斯方法。而且逻辑回归并不完全依赖于属性之间相互独立的假设，即使给定违反这一假设的数据，逻辑回归的条件似然最大化算法也会调整其参数以实现最大化的数据拟合。相比之下，逻辑回归的偏差更小，但方差更大。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2263"><span data-slate-object="text" data-key="2264"><span data-slate-leaf="true" data-offset-key="2264:0" data-first-offset="true"><span data-slate-string="true">除此之外，</span></span></span><span data-slate-object="text" data-key="2265"><span data-slate-leaf="true" data-offset-key="2265:0" data-first-offset="true"><span data-slate-object="annotation" data-annotation-key="gkann_4a98547e" data-attr-id="26817" data-attr-name="public" data-annotation-type="public"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">两者的区别还在于收敛速度的不同</span></span></span></span></span><span data-slate-object="text" data-key="2266"><span data-slate-leaf="true" data-offset-key="2266:0" data-first-offset="true"><span data-slate-object="annotation" data-annotation-key="gkann_4a98547e" data-attr-id="26817" data-attr-name="public" data-annotation-type="public"><span data-slate-string="true">。逻辑回归中参数估计的收敛速度要慢于朴素贝叶斯方法。当训练数据集的容量较大时，逻辑回归的性能优于朴素贝叶斯方法；但在训练数据稀缺时，两者的表现就会发生反转。</span></span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2267"><span data-slate-object="text" data-key="2268"><span data-slate-leaf="true" data-offset-key="2268:0" data-first-offset="true"><span data-slate-string="true">二分类任务只是特例，更通用的情形是多分类的问题，例如手写数字的识别。要让逻辑回归处理多分类问题，就要做出一些改进。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2269"><span data-slate-object="text" data-key="2270"><span data-slate-leaf="true" data-offset-key="2270:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">一种改进方式是通过多次二分类实现多个类别的标记</span></span></span></span><span data-slate-object="text" data-key="2271"><span data-slate-leaf="true" data-offset-key="2271:0" data-first-offset="true"><span data-slate-string="true">。这等效为直接将逻辑回归应用在每个类别之上，对每个类别都建立一个二分类器。如果输出的类别标记数目为 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2272"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>m</span></span></span></span></span></span><span data-slate-object="text" data-key="2274"><span data-slate-leaf="true" data-offset-key="2274:0" data-first-offset="true"><span data-slate-string="true">，就可以得到 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2275"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>m</span></span></span></span></span></span><span data-slate-object="text" data-key="2277"><span data-slate-leaf="true" data-offset-key="2277:0" data-first-offset="true"><span data-slate-string="true"> 个针对不同标记的二分类逻辑回归模型，而对一个实例的分类结果就是这 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2278"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>m</span></span></span></span></span></span><span data-slate-object="text" data-key="2280"><span data-slate-leaf="true" data-offset-key="2280:0" data-first-offset="true"><span data-slate-string="true"> 个分类函数中输出值最大的那个。在这种方式中，对一个实例执行分类需要多次使用逻辑回归算法，其效率显然比较低下。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2281"><span data-slate-object="text" data-key="2282"><span data-slate-leaf="true" data-offset-key="2282:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">另一种多分类的方式通过直接修改逻辑回归输出的似然概率，使之适应多分类问题，得到的模型就是 Softmax 回归</span></span></span></span><span data-slate-object="text" data-key="2283"><span data-slate-leaf="true" data-offset-key="2283:0" data-first-offset="true"><span data-slate-string="true">。Softmax 回归给出的是实例在每一种分类结果下出现的概率</span></span></span></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-slate-type="block-katex" data-slate-object="block" data-key="2284"><span><span><span aria-hidden="true"><span><span></span><span>p</span><span>(</span><span>Y</span><span></span><span>=</span><span></span></span><span><span></span><span>k</span><span>∣</span><span>x</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span><span><span><span><span><span></span><span><span><span>k</span><span>=</span><span>1</span></span></span></span><span><span></span><span><span>∑</span></span></span><span><span></span><span><span>K</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span><span><span>w</span><span><span><span><span><span><span></span><span><span>k</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span></span></span></span></span></span></span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>e</span><span><span><span><span><span><span></span><span><span><span><span><span><span>w</span><span><span><span><span><span><span></span><span><span>k</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span><span><span>x</span></span></span></span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span></span></span></span></span></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2286"><span data-slate-object="text" data-key="2287"><span data-slate-leaf="true" data-offset-key="2287:0" data-first-offset="true"><span data-slate-string="true">式中的 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2288"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span><span><span>w</span><span><span><span><span><span><span></span><span><span>k</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span></span></span><span data-slate-object="text" data-key="2290"><span data-slate-leaf="true" data-offset-key="2290:0" data-first-offset="true"><span data-slate-string="true"> 代表和类别 </span></span></span><span data-slate-type="inline-katex" data-slate-object="inline" data-key="2291"><span data-slate-leaf="true"><span data-slate-string="true"><span aria-hidden="true"><span><span></span><span>k</span></span></span></span></span></span><span data-slate-object="text" data-key="2293"><span data-slate-leaf="true" data-offset-key="2293:0" data-first-offset="true"><span data-slate-string="true"> 相关的权重参数。Softmax 回归模型的训练与逻辑回归模型类似，都可以转化为通过梯度下降法或者拟牛顿法解决最优化问题。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2294"><span data-slate-object="text" data-key="2295"><span data-slate-leaf="true" data-offset-key="2295:0" data-first-offset="true"><span data-slate-string="true">虽然都能实现多分类的任务，但两种方式的适用范围略有区别。当分类问题的所有类别之间明显互斥，即输出结果只能属于一个类别时，Softmax 分类器是更加高效的选择；当所有类别之间不存在互斥关系，可能有交叉的情况出现时，多个二分类逻辑回归模型就能够得到多个类别的标记。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2296"><span data-slate-object="text" data-key="2297"><span data-slate-leaf="true" data-offset-key="2297:0" data-first-offset="true"><span data-slate-string="true">今天我和你分享了机器学习基本算法之一的逻辑回归方法的基本原理，其要点如下：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="2298"><div data-slate-type="list-line" data-slate-object="block" data-key="2299"><span data-slate-object="text" data-key="2300"><span data-slate-leaf="true" data-offset-key="2300:0" data-first-offset="true"><span data-slate-string="true">逻辑回归模型是对线性回归的改进，用于解决分类问题；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="2301"><span data-slate-object="text" data-key="2302"><span data-slate-leaf="true" data-offset-key="2302:0" data-first-offset="true"><span data-slate-string="true">逻辑回归输出的是实例属于每个类别的似然概率，似然概率最大的类别就是分类结果；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="2303"><span data-slate-object="text" data-key="2304"><span data-slate-leaf="true" data-offset-key="2304:0" data-first-offset="true"><span data-slate-string="true">在一定条件下，逻辑回归模型与朴素贝叶斯分类器是等价的；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="2305"><span data-slate-object="text" data-key="2306"><span data-slate-leaf="true" data-offset-key="2306:0" data-first-offset="true"><span data-slate-string="true">多分类问题时可以通过多次使用二分类逻辑回归或者使用 Softmax 回归解决。</span></span></span></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2307"><span data-slate-object="text" data-key="2308"><span data-slate-leaf="true" data-offset-key="2308:0" data-first-offset="true"><span data-slate-string="true">前文对逻辑回归的分析都是在概率理论的基础上完成的。但在二分类任务中，逻辑回归的作用可以视为是在平面直角坐标系上划定一条数据分类的判定边界。那么逻辑回归的作用能不能从几何角度理解，并推广到高维空间呢？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="2309"><span data-slate-object="text" data-key="2310"><span data-slate-leaf="true" data-offset-key="2310:0" data-first-offset="true"><span data-slate-string="true">欢迎发表你的观点。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="2311"><div class="sr-rd-content-center"><img class="sr-rd-content-img-load" src="https://static001.geekbang.org/resource/image/d8/aa/d81794d22373b75dd79da8655adacdaa.jpg?wh=1110*1032"></div></div></div></div></div><div><div></div><div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><textarea placeholder="将学到的知识总结成笔记，方便日后快速查找及复习"></textarea></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div><div><div>确认放弃笔记？</div><div>放弃后所记笔记将不保留。</div></div><div><div>新功能上线，你的历史笔记已初始化为私密笔记，是否一键批量公开？</div><div>批量公开的笔记不会为你同步至部落</div></div><div></div></div><div><div><div>公开</div><div>同步至部落</div></div><div>取消</div><div>完成</div></div><div><span>0/2000</span></div></div><div><div><span>划线</span></div><div></div><div></div><div></div><div><span>笔记</span></div><div></div><div><span>复制</span></div></div></div><div><div><div><span></span></div><p><a href="javascript:void(0);">给文章提建议</a></p></div></div><div><span>©</span> 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 </div></div><div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div><div>Geek__653581f21177</div></div><div><textarea placeholder="由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。" rows="16"></textarea></div><div><div>Ctrl + Enter 发表</div><div>0/2000 字符</div><div>提交留言</div></div></div><div><h2 id="sr-toc-1">精选留言 (15)</h2><ul><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div></div><div><div><div><span>dianxin556</span></div></div><div>王老师，请问似然概率和后验概率的区别和联系？能否举例说明？谢谢！</div><div><p>作者回复：似然概率是由假设正推结果，后验概率是由结果倒推假设。
假如一种产品由不同的工厂 ABC 生产，每个工厂都有自己的次品率，那么 A 厂生产的产品占产品总数的比例就是先验概率，A 厂自己的次品率就是似然概率。
在一堆产品中抽出一件，检验发现是次品，那这件次品可能来源于 ABC 中任意的一个厂。已知产品是次品，推断这件次品来自 A 厂的概率，这就是后验概率。
</p></div><div><div>2018-01-24</div><div><div><i></i><span>4</span></div><div><i></i><span>19</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKmyUF0MWNDUWibma6ia6t6xrZDv93hiaNONp9FG4yyjz1JBCe5dmJ4zjOI3hZiazK17PMCKwIE69gacA/132"></div></div><div><div><div><span> 井中月</span></div></div><div>王老师，按文章最后一段所说，当一个样本同时属于多个类别时，是不是有几个类别就建立几个二分类模型，这样效率比较高？但是我曾经遇到过一个类似的问题，当时没有解决，想跟您请教。每个样本属于多个类别，这些类别加起来一共有将近 400 种，而且绝大多数类别都是严重不平衡的。这种情况下如果一个一个的建立模型是不是效率很低？这是一个文本分类的问题，文本是餐厅评论数据，类别是人工标注的评论主题。这些类别其实是可以合并的，但是合并之后意义不大。您怎么看这种情况？</div><div><p>作者回复：抛开问题不说，做多分类两种思路：一是所有类别两两配对，就是 1v2, 1v3,...,1vN,2v3,2v4,...2vN,3v4,... 依此类推；二是每个类别和其他所有类别配对，就是 1v 其他，2v 其他，…Nv 其他。第一种模型多，每个模型需要的数据少，第二种相反。
具体到你的问题，我觉得类别太多了，尤其是数据有限时，给 500 个数据分 400 个类是没有价值的。所以我认为应该先对类别做优化，当然，能不能行的通还要看实际情况。</p></div><div><div>2018-03-07</div><div><div><i></i></div><div><i></i><span>4</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/11/7a/42/9681595e.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 阿里 - 赤壁（羊宏飞）</span></div></div><div>王老师这个课 我认为是 机器学习入门者 非常好的 图谱 ，其中一些知识点还是要结合书本和实战。问题的讨论 知乎上回答的也非常详尽</div><div><div>2018-06-01</div><div><div><i></i><span></span></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/91/f5/abb7bfe3.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Jean</span></div></div><div>问下逻辑回归中的 “逻辑” 是什么意思，为什么叫逻辑，是怎么来的？</div><div><p>作者回复：逻辑是 logistic 的音译，logistic 函数就是文章里的 sigmoid 函数，也就是 S 曲线。</p></div><div><div>2018-03-01</div><div><div><i></i><span>2</span></div><div><i></i><span>2</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/10/4f/fe/cd166eb4.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 叶秋</span></div></div><div>可否推导一下逻辑回归的条件概率的推导过程</div><div><p>作者回复：在这里没法打出公式，你可以参考维基百科上逻辑回归的页面，或是推荐书目中周老师和李老师教材的相关章节。</p></div><div><div>2018-03-27</div><div><div><i></i></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKmyUF0MWNDUWibma6ia6t6xrZDv93hiaNONp9FG4yyjz1JBCe5dmJ4zjOI3hZiazK17PMCKwIE69gacA/132"></div></div><div><div><div><span> 井中月</span></div></div><div>谢谢您的回复。我当时设想的是第二种思路，每个类和其他所有类配对。当时的数据量是 50 多万条。按您的经验来说，一般做分类问题，类别控制在多少个容易取得较好的效果呢？</div><div><p>作者回复：这是取决于具体问题的，建议你也把类别数量作为一个变量试一试，看看类别多少时效果比较好。</p></div><div><div>2018-03-11</div><div><div><i></i></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/bc/66/abb7bfe3.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>MJ 小朋友</span></div></div><div>我好像发现了两个无伤大雅的错误，
S 型函数 b 好像漏了，后面推导有了，又没了
对数似然函数应该取自然对数，不然没底数不行</div><div><p>作者回复：感谢你的火眼金睛，这两个问题都是符号没有统一造成的。
第一个，没有常项 b 是因为把它看成 w 的一个分量 w_0，并让它和另一个常数 x_0=1 相乘，但是推导时候这样写又不方便，所以就把 b 拿出来了；
第二个是个习惯问题，这要归咎于平时书写并不规范，不写底数的 log 就默认是 ln 运算。在文章中，所有的运算全是自然对数运算。</p></div><div><div>2018-01-05</div><div><div><i></i></div><div><i></i><span>2</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/16/a0/3f/06b690ba.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 刘桢</span></div></div><div>打卡打卡</div><div><div>2020-03-22</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132"></div></div><div><div><div><span>杨家荣</span></div></div><div>极客时间
21 天打卡行动 8/21
&lt;&lt;人工智能基础课 10&gt;&gt; 逻辑回归
回答老师问题:
前文对逻辑回归的分析都是在概率理论的基础上完成的。但在二分类任务中，逻辑回归的作用可以视为是在平面直角坐标系上划定一条数据分类的判定边界。那么逻辑回归的作用能不能从几何角度理解，并推广到高维空间呢？
这个问题有点深奥，根据我自身的学习知识，在逻辑回归算法中，如果用几何去表达，显然平面几何是做不到的，以前我老师讲过一个升维的算法，在平面几何不能表达的回归图形中，假设这个图形不是二维的，是多维度的，在多维度的空间中，是能计算和描绘的；
今日所学：Logistic 回归 (逻辑回归), 这个算法本身是解决分类问题的，逻辑回归中，实现这一映射是对数几率函数，也叫 Sigmoid 函数；(Sigmoid 函数搜索较大的值，所有值将介于 0 和 1 之间), 而寻找以上函数的最大值就是以对数似然函数为目标函数的最优化问题，通常通过 “梯度下降法” 或拟 “牛顿法” 求解，另外对数似然函数的最大化可以等效为待求模型与最大熵模型之间 KL 散度的最小化。这意味着最优的估计对参数做出的额外假设是最少的，这无疑与最大熵原理不谋而合。
逻辑回归与朴素贝叶斯区别:
1, 逻辑回归与线性回归的关系称得上系出同门，与朴素贝叶斯分类的关系则是殊途同归。两者虽然都可以利用条件概率 P (Y|X) 完成分类任务，实现的路径却截然不同。
2, 朴素贝叶斯分类器是生成模型的代表，其思想是先由训练数据集估计出输入和输出的联合概率分布，再根据联合概率分布来生成符合条件的输出，P (Y|X) 以后验概率的形式出现。
3, 两者的区别在于当朴素贝叶斯分类的模型假设不成立时，逻辑回归和朴素贝叶斯方法通常会学习到不同的结果
4, 两者的区别还在于收敛速度的不同；
5, 朴素贝叶斯基于少量数据集更有优势
逻辑回归的改进：一种改进方式是通过多次二分类实现多个类别的标记；另一种多分类的方式通过直接修改逻辑回归输出的似然概率，使之适应多分类问题，得到的模型就是 Softmax 回归，Softmax 回归模型的训练与逻辑回归模型类似，都可以转化为通过梯度下降法或者拟牛顿法解决最优化问题。
说明：虽然都能实现多分类的任务，但两种方式的适用范围略有区别。当分类问题的所有类别之间明显互斥，即输出结果只能属于一个类别时，Softmax 分类器是更加高效的选择；当所有类别之间不存在互斥关系，可能有交叉的情况出现时，多个二分类逻辑回归模型就能够得到多个类别的标记。
总结: a, 逻辑回归模型是对线性回归的改进，用于解决分类问题；b, 逻辑回归输出的是实例属于每个类别的似然概率，似然概率最大的类别就是分类结果；c, 在一定条件下，逻辑回归模型与朴素贝叶斯分类器是等价的；d, 多分类问题时可以通过多次使用二分类逻辑回归或者使用 Softmax 回归解决。
</div><div><div>2019-12-26</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/13/2f/f4/2dede51a.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>小老鼠</span></div></div><div>各位是不是都是数学系毕业的，好难懂</div><div><div>2019-01-17</div><div><div><i></i><span>1</span></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/13/63/2c/2750bc59.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 历尽千帆</span></div></div><div>王老师，您好。我没有明白 “对数似然函数的最大化可以等效为待求模型与最大熵模型之间 KL 散度的最小化。这意味着最优的估计对参数做出的额外假设是最少的” 这句话，您可否再解释下？</div><div><div>2018-12-29</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="http://thirdwx.qlogo.cn/mmopen/vi_32/EvqrQ1wMs4SzC8dSBjAfVdEZ3yDT0bDUMicfRLq6BOSzjGFhCownt3S5MERXLpOpLmyJXCuyWbeOQG3ibzy0b4ibA/132"></div></div><div><div><div><span>jkhcw</span></div></div><div>逻辑回归在高纬模型下就是超平面</div><div><div>2018-12-16</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/11/55/44/024204e2.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>星运里的错</span></div></div><div>老师。我发现很多概念当时明白，过后就忘了，您是推荐从实战例子中去加深理解，还是反复的去看概念，知道看懂</div><div><p>作者回复：我认为结合起来才有效果，想办法理解例子是如何应用概念的。</p></div><div><div>2018-05-19</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKmyUF0MWNDUWibma6ia6t6xrZDv93hiaNONp9FG4yyjz1JBCe5dmJ4zjOI3hZiazK17PMCKwIE69gacA/132"></div></div><div><div><div><span>井中月</span></div></div><div>好的，谢谢老师</div><div><div>2018-03-15</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/71/45/abb7bfe3.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Andy</span></div></div><div>王老师您好，在逻辑回归中，代价函数为什么选用交叉熵代价函数，而不是选用最小二乘代价函数呢？</div><div><p>作者回复：不要被名字欺骗，逻辑回归的输出是离散值哟，离散变量用最小二乘就没意义了。</p></div><div><div>2018-01-05</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li></ul><div> 收起评论<span></span></div></div></sr-rd-content>
                            <toc-bg><toc style="width: initial;overflow: auto!important;"class="simpread-font simpread-theme-root" data-reactid=".y"><outline class="toc-level-h1" data-reactid=".y.0" style="width: 175px;"><active data-reactid=".y.0.0" ></active><a class="toc-outline-theme-github" href="#sr-toc-0" data-reactid=".y.0.1"><span data-reactid=".y.0.1.0">10 机器学习 | 衍化至繁：逻辑回归</span></a></outline><outline class="toc-level-h2" data-reactid=".y.1" style="width: 165px;"><active data-reactid=".y.1.0"></active><a class="toc-outline-theme-github" href="#sr-toc-1" data-reactid=".y.1.1"><span data-reactid=".y.1.1.0">精选留言 (15)</span></a></outline></toc></toc-bg>
                            <sr-rd-footer>
                                <sr-rd-footer-group>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                </sr-rd-footer-group>
                                <sr-rd-footer-copywrite>
                                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://time.geekbang.org/column/article/1867" target="_blank">原文地址 </a></div>
                                </sr-rd-footer-copywrite>
                            </sr-rd-footer>
                        </sr-read>
                    </body>
                </html>