
                <html lang="en" class="simpread-font simpread-theme-root" style=''>
                    <head>
                        <meta charset="utf-8">
                        <meta http-equiv="content-type" content="text/html; charset=UTF-8;charset=utf-8">
                        <meta http-equiv="X-UA-Compatible" content="IE=Edge">
                        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
                        <meta name="author" content="Kenshin"/>
                        <meta name="description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展" />
                        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, 简悦, 简阅, read mode, reading mode, reader view, firefox, firefox addon, userscript, safari, opera, tampermonkey"/>
                        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:title" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <meta property="og:type" content="website">
                        <meta property="og:local" content="zh_CN"/>
                        <meta property="og:url" content="http://ksria.com/simpread"/>
                        <meta property="og:image" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:image:type" content="image/png"/>
                        <meta property="og:image:width" content="960"/>
                        <meta property="og:image:height" content="355"/>
                        <meta property="og:site_name" content="http://ksria.com/simpread"/>
                        <meta property="og:description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <style type="text/css">.simpread-font{font:300 16px/1.8 -apple-system,PingFang SC,Microsoft Yahei,Lantinghei SC,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#333;text-rendering:optimizelegibility;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased}.simpread-hidden{display:none}.simpread-read-root{display:-webkit-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;margin:0;top:-1000px;left:0;width:100%;z-index:2147483646;overflow-x:hidden;opacity:0;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}.simpread-read-root-show{top:0}.simpread-read-root-hide{top:1000px}sr-read{display:-webkit-flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-flow:column nowrap;flex-flow:column;margin:20px 20%;min-width:400px;min-height:400px;text-align:center}read-process{position:fixed;top:0;left:0;height:3px;width:100%;background-color:#64b5f6;-webkit-transition:width 2s;transition:width 2s;z-index:20000}sr-rd-content-error{display:block;position:relative;margin:0;margin-bottom:30px;padding:25px;background-color:rgba(0,0,0,.05)}sr-rd-footer{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column;font-size:14px}sr-rd-footer,sr-rd-footer-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}sr-rd-footer-group{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-rd-footer-line{width:100%;border-top:1px solid #e0e0e0}sr-rd-footer-text{min-width:150px}sr-rd-footer-copywrite{margin:10px 0 0;color:inherit}sr-rd-footer-copywrite abbr{-webkit-font-feature-settings:normal;font-feature-settings:normal;font-variant:normal;text-decoration:none}sr-rd-footer-copywrite .second{margin:10px 0}sr-rd-footer-copywrite .third a:hover{border:none!important}sr-rd-footer-copywrite .third a:first-child{margin-right:50px}sr-rd-footer-copywrite .sr-icon{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:33px;height:33px;opacity:.8;-webkit-transition:opacity .5s ease;transition:opacity .5s ease;cursor:pointer}sr-rd-footer-copywrite .sr-icon:hover{opacity:1}sr-rd-footer-copywrite a,sr-rd-footer-copywrite a:link,sr-rd-footer-copywrite a:visited{margin:0;padding:0;color:inherit;background-color:transparent;font-size:inherit!important;line-height:normal;text-decoration:none;vertical-align:baseline;vertical-align:initial;border:none!important;box-sizing:border-box}sr-rd-footer-copywrite a:focus,sr-rd-footer-copywrite a:hover,sr-rd-footer a:active{color:inherit;text-decoration:none;border-bottom:1px dotted!important}.simpread-blocks{text-decoration:none!important}.simpread-blocks *{margin:0}.simpread-blocks a{padding:0;text-decoration:none!important}.simpread-blocks img{margin:0;padding:0;border:0;background:transparent;box-shadow:none}.simpread-focus-root{display:block;position:fixed;top:0;left:0;right:0;bottom:0;background-color:hsla(0,0%,92%,.9);z-index:2147483645;opacity:0;-webkit-transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms;transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms}.simpread-focus-highlight{position:relative;box-shadow:0 0 0 20px #fff;background-color:#fff;overflow:visible;z-index:2147483646}.sr-controlbar-bg sr-rd-crlbar,.sr-controlbar-bg sr-rd-crlbar fab{z-index:2147483647}sr-rd-crlbar.controlbar{position:fixed;right:0;bottom:0;width:100px;height:100%;opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}sr-rd-crlbar.controlbar:hover{opacity:1}sr-rd-crlbar fap *{box-sizing:border-box}@media (max-height:620px){fab{zoom:.8}}@media (max-height:783px){dialog-gp dialog-content{max-height:580px}dialog-gp dialog-footer{border-top:1px solid #e0e0e0}}.simpread-highlight-selector{outline:3px dashed #1976d2!important;cursor:pointer!important}.simpread-highlight-controlbar,.simpread-highlight-selector{background-color:#fafafa!important;opacity:.8!important;-webkit-transition:opacity .5s ease!important;transition:opacity .5s ease!important}.simpread-highlight-controlbar{position:relative!important;border:3px dashed #1976d2!important}simpread-highlight,sr-snapshot-ctlbar{position:fixed;top:0;left:0;right:0;padding:15px;height:50px;background-color:rgba(50,50,50,.9);box-shadow:0 2px 5px rgba(0,0,0,.26);box-sizing:border-box;z-index:2147483640}simpread-highlight,sr-highlight-ctl,sr-snapshot-ctlbar{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-highlight-ctl{margin:0 5px;width:50px;height:20px;color:#fff;background-color:#1976d2;border-radius:4px;box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12);cursor:pointer}toc-bg{position:fixed;left:0;top:0;width:50px;height:200px;font-size:medium}toc-bg:hover{z-index:3}.toc-bg-hidden{opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}.toc-bg-hidden:hover{opacity:1;z-index:3}.toc-bg-hidden:hover toc{width:180px}toc *{all:unset}toc{position:fixed;left:0;top:100px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;padding:10px;width:0;max-width:200px;max-height:500px;overflow-x:hidden;overflow-y:hidden;cursor:pointer;border:1px solid hsla(0,0%,62%,.22);-webkit-transition:width .5s;transition:width .5s}toc:hover{overflow-y:auto}toc.mini:hover{width:200px!important}toc::-webkit-scrollbar{width:3px}toc::-webkit-scrollbar-thumb{border-radius:10px;background-color:hsla(36,2%,54%,.5)}toc outline{position:relative;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;padding:2px 0;min-height:21px;line-height:21px;text-align:left}toc outline a,toc outline a:active,toc outline a:focus,toc outline a:visited{display:block;width:100%;color:inherit;font-size:11px;text-decoration:none!important;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}toc outline a:hover{font-weight:700!important}toc outline a.toc-outline-theme-dark,toc outline a.toc-outline-theme-night{color:#fff!important}.toc-level-h1{padding-left:5px}.toc-level-h2{padding-left:15px}.toc-level-h3{padding-left:25px}.toc-level-h4{padding-left:35px}.toc-outline-active{border-left:2px solid #f44336}toc outline active{position:absolute;left:0;top:0;bottom:0;padding:0 0 0 3px;border-left:2px solid #e8e8e8}sr-kbd{background:-webkit-gradient(linear,0 0,0 100%,from(#fff785),to(#ffc542));border:1px solid #e3be23;-o-border-image:none;border-image:none;-o-border-image:initial;border-image:initial;position:absolute;left:0;padding:1px 3px 0;font-size:11px!important;font-weight:700;box-shadow:0 3px 7px 0 rgba(0,0,0,.3);overflow:hidden;border-radius:3px}.sr-kbd-a{position:relative}kbd-mapping{position:fixed;left:5px;bottom:5px;-ms-flex-flow:row;flex-flow:row;width:250px;height:500px;background-color:#fff;border:1px solid hsla(0,0%,62%,.22);box-shadow:0 2px 5px rgba(0,0,0,.26);border-radius:3px}kbd-mapping,kbd-maps{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}kbd-maps{margin:40px 0 20px;width:100%;overflow-x:auto}kbd-maps::-webkit-scrollbar-thumb{background-clip:padding-box;border-radius:10px;border:2px solid transparent;background-color:rgba(85,85,85,.55)}kbd-maps::-webkit-scrollbar{width:10px;-webkit-transition:width .7s cubic-bezier(.4,0,.2,1);transition:width .7s cubic-bezier(.4,0,.2,1)}kbd-mapping kbd-map-title{position:absolute;margin:5px 0;width:100%;font-size:14px;font-weight:700}kbd-maps-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}kbd-maps-title{margin:5px 0;padding-left:53px;font-size:12px;font-weight:700}kbd-map kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fafbfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}kbd-map kbd-name{display:inline-block;text-align:right;width:50px}kbd-map kbd-desc{padding-left:3px}sharecard-bg{position:fixed;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,.4);z-index:2147483647}sharecard{max-width:450px;background-color:#64b5f6}sharecard,sharecard-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-head{margin:25px;color:#fff;border-radius:10px;box-shadow:0 2px 6px 0 rgba(0,0,0,.2),0 25px 50px 0 rgba(0,0,0,.15)}sharecard-card{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-card,sharecard-top{display:-webkit-box;display:-ms-flexbox;display:flex}sharecard-top{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:65px;background-color:#fff;color:#878787;font-size:25px;font-weight:500;border-top-left-radius:10px;border-top-right-radius:10px}sharecard-top span.logos{display:block;width:48px;height:48px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAMAAABg3Am1AAABU1BMVEUAAAAnNJMnNZI3Q5onNJInNJMnNJInNJMnNJI8SJ0tOZY/S55EUKAoNJI6RpwoNJNIU6InNJInNJImNJI7SJwmNJJ2fLUiMJFKVaNCTJ9faK1HUaJOWKVSXaUnNJNYY6pye7cmM5JXYKhwebMjMI8mL4719fW9vb0oNZP/UlLz8/QqN5TAwMAnNJPv7+/Pz8/q6+/p6enNzc3Kysry8vMsOJXc3env7/LU1uXo29vR0dHOzs7ExMTwjo73bW37XV3Aj1TCYELl5u3n5+fW2Obn6O7f4OrZ2+g0QJkxPpgvO5bh4uvS1OTP0ePCwsJQW6ZLVqTs7fHd3d3V1dXqv79VX6lET6A1TIxXUIBSgHxWQnpelHf+WVnopkXqbC7j5Ozi4uLDw8NGUaFATJ9SgH3r6+vGyd7BxNva2trX19ejqM2gpczHx8dze7Zha67Z2dlTgH1aXQeSAAAAJnRSTlMA6ff+497Y8NL+/fv49P379sqab/BeOiX06tzVy8m/tKqpalA7G6oKj0EAAAJlSURBVEjHndNXWxpBFIDhcS2ICRLAkt4Dx4WhLk0E6R0MYoIISrWX5P9f5cwSIRC2+T1czMV5n2FnZwn2eWONUqCAv3H2Uf5Ra1hx4+0WEXtDQW0fCPYJ1EffEfIV4CSROAE4jsePoTFsNmTJF/IeIHF2lgCIn57GodlqDWXBK7IwBYatVlMWFAildPKX7I3m74Z9fsCiQChoimoFQAz04Ad2gH1n9fv9n9hgMNDr9euLWD6fLxQKxaLfb7dTSlahbFVdEPwIQtrAihZQgyKCtCagbQe3xh0QFMgy5MR11+ewYY5/qlZ7vT2xu93ULKjbFLpiUxnIIwjgKmVTLDUFXMrAi2NJWCRLIthTBo4xyOLKpwyqU6CuDCI41hFBCVdOhyLw4FgJ1skCAiyl9BSHbCorgo6VJXTru5hrVCQS8Yr5xLzX59YJSFpVFwD9U0BGC3hGdFpATgRupTGe9R9I1b1ePBvXKDyvq/O/44LT4/E4BUbSCAwj8Evq6HlnOBprx6JhJz8Gktc7xeaP9ndY+0coQvCccFBD4JW60UIY50ciLOAODAQRVOeCHm4Q3Xks6uRDY+CQ+AR4T2wMYh6+jMCIQOp78CFoj0H7EQgIuhI3dGaHCrwgADwCPjJvA372GRigCJg49FUdk3D87pq3zp4SA5zc1Zh9DxfwkpjgUg5Mv+lbeE3McC8Lpu7SA3wk2xzcqL2tN5DfIsQC8HB7UamUy6FQOpTO5QKBQDZbKnWSyUzGjdWCwaDA8+7Le4BNgm3qQGWchYh9s5hNq6wVbBlbwhZYOp3OYOA4zmgEypnM2zj8ByIdedKrH8vDAAAAAElFTkSuQmCC");zoom:.8}sharecard-content{padding:15px;max-height:500px;font-size:20px;text-align:justify;background-color:#2196f3;overflow-x:hidden;overflow-y:auto}sharecard-via{padding:10px;font-size:10px;background-color:#2196f3}sharecard-footer{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:100px;background-color:#fff;color:#878787;font-size:15px;font-weight:500;border-bottom-left-radius:10px;border-bottom-right-radius:10px}sharecard-footer,sharecard-footer div{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sharecard-footer span.qrcode{display:block;width:100px;height:100px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,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")}sharecard-control{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 19px;height:80px;background-color:#fff}simpread-snapshot{width:100%;height:100%;cursor:move;z-index:2147483645}simpread-snapshot,sr-mask{position:fixed;left:0;top:0}sr-mask{background-color:rgba(0,0,0,.1)}.simpread-feedback,.simpread-urlscheme{position:fixed;right:20px;bottom:20px;z-index:2147483646}simpread-feedback,simpread-urlscheme{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;padding:20px 20px 0;width:500px;color:rgba(51,51,51,.87);background-color:#fff;border-radius:3px;box-shadow:0 0 2px rgba(0,0,0,.12),0 2px 2px rgba(0,0,0,.26);overflow:hidden;-webkit-transform-origin:bottom;transform-origin:bottom;-webkit-transition:all .6s ease;transition:all .6s ease}simpread-feedback *,simpread-urlscheme *{font-size:12px!important;box-sizing:border-box}simpread-feedback.active,simpread-urlscheme.active{-webkit-animation-name:srFadeInUp;animation-name:srFadeInUp;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback.hide,simpread-urlscheme.hide{-webkit-animation-name:srFadeInDown;animation-name:srFadeInDown;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback sr-fb-label,simpread-urlscheme sr-urls-label{width:100%}simpread-feedback sr-fb-head,simpread-urlscheme sr-urls-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:5px;width:100%}simpread-feedback sr-fb-content,simpread-urlscheme sr-urls-content{margin-bottom:5px;width:100%}simpread-feedback sr-urls-footer,simpread-urlscheme sr-urls-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-fb-a,simpread-urlscheme sr-urls-a{color:#2163f7;cursor:pointer}simpread-feedback text-field-state,simpread-urlscheme text-field-state{border-top:none rgba(34,101,247,.8)!important;border-left:none rgba(34,101,247,.8)!important;border-right:none rgba(34,101,247,.8)!important;border-bottom:2px solid rgba(34,101,247,.8)!important}simpread-feedback switch,simpread-urlscheme switch{margin-top:0!important}@-webkit-keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@-webkit-keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}@keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}simpread-feedback sr-fb-head{font-weight:700}simpread-feedback sr-fb-content{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column}simpread-feedback sr-fb-content,simpread-feedback sr-fb-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}simpread-feedback sr-fb-footer{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-close{position:absolute;right:20px;cursor:pointer;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s;z-index:200}simpread-feedback sr-close:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin-top:10px}simpread-feedback sr-stars i{margin-right:10px;cursor:pointer}simpread-feedback sr-stars i svg{-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}simpread-feedback sr-stars i svg:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars i.active svg{-webkit-transform:rotate(0) scale(1);transform:rotate(0) scale(1)}simpread-feedback sr-emojis{display:block;height:100px;overflow:hidden}simpread-feedback sr-emoji{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:.3s;transition:.3s}simpread-feedback sr-emoji>svg{margin:15px 0;width:70px;height:70px;-ms-flex-negative:0;flex-shrink:0}simpread-feedback sr-stars-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin:10px 0 20px}</style>
                        <style type="text/css">.simpread-theme-root{font-size:62.5%!important}sr-rd-content,sr-rd-desc,sr-rd-title{width:100%}sr-rd-title{display:-webkit-box;margin:1em 0 .5em;overflow:hidden;text-overflow:ellipsis;text-rendering:optimizelegibility;-webkit-line-clamp:3;-webkit-box-orient:vertical}sr-rd-content{text-align:left;word-break:break-word}sr-rd-desc{text-align:justify;line-height:2.4;margin:0 0 1.2em;box-sizing:border-box}sr-rd-content{font-size:25.6px;font-size:1.6rem;line-height:1.6}sr-rd-content h1,sr-rd-content h1 *,sr-rd-content h2,sr-rd-content h2 *,sr-rd-content h3,sr-rd-content h3 *,sr-rd-content h4,sr-rd-content h4 *,sr-rd-content h5,sr-rd-content h5 *,sr-rd-content h6,sr-rd-content h6 *{word-break:break-all}sr-rd-content div,sr-rd-content p{display:block;float:inherit;line-height:1.6;font-size:25.6px;font-size:1.6rem}sr-rd-content div,sr-rd-content p,sr-rd-content pre,sr-rd-content sr-blockquote{margin:0 0 1.2em;word-break:break-word}sr-rd-content a{padding:0 5px;vertical-align:baseline;vertical-align:initial}sr-rd-content a,sr-rd-content a:link{color:inherit;font-size:inherit;font-weight:inherit;border:none}sr-rd-content a:hover{background:transparent}sr-rd-content img{margin:10px;padding:5px;max-width:100%;background:#fff;border:1px solid #bbb;box-shadow:1px 1px 3px #d4d4d4}sr-rd-content figcaption{text-align:center;font-size:14px}sr-rd-content sr-blockquote{display:block;position:relative;padding:15px 25px;text-align:left;line-height:inherit}sr-rd-content sr-blockquote:before{position:absolute}sr-rd-content sr-blockquote *{margin:0;font-size:inherit}sr-rd-content table{width:100%;margin:0 0 1.2em;word-break:keep-all;word-break:normal;overflow:auto;border:none}sr-rd-content table td,sr-rd-content table th{border:none}sr-rd-content ul{margin:0 0 1.2em;margin-left:1.3em;padding:0;list-style:disc}sr-rd-content ol{list-style:decimal;margin:0;padding:0}sr-rd-content ol li,sr-rd-content ul li{font-size:inherit;list-style:disc;margin:0 0 1.2em}sr-rd-content ol li{list-style:decimal;margin-left:1.3em}sr-rd-content ol li *,sr-rd-content ul li *{margin:0;text-align:left;text-align:initial}sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em}sr-rd-content li ul{list-style:circle}sr-rd-content pre{font-family:Consolas,Monaco,Andale Mono,Source Code Pro,Liberation Mono,Courier,monospace;display:block;padding:15px;line-height:1.5;word-break:break-all;word-wrap:break-word;white-space:pre;overflow:auto}sr-rd-content pre,sr-rd-content pre *,sr-rd-content pre div{font-size:17.6px;font-size:1.1rem}sr-rd-content li pre code,sr-rd-content p pre code,sr-rd-content pre{background-color:transparent;border:none}sr-rd-content pre code{margin:0;padding:0}sr-rd-content pre code,sr-rd-content pre code *{font-size:17.6px;font-size:1.1rem}sr-rd-content pre p{margin:0;padding:0;color:inherit;font-size:inherit;line-height:inherit}sr-rd-content li code,sr-rd-content p code{margin:0 4px;padding:2px 4px;font-size:17.6px;font-size:1.1rem}sr-rd-content mark{margin:0 5px;padding:2px;background:#fffdd1;border-bottom:1px solid #ffedce}.sr-rd-content-img{width:90%;height:auto}.sr-rd-content-img-load{width:48px;height:48px;margin:0;padding:0;border-style:none;border-width:0;background-repeat:no-repeat;background-image:url(data:image/gif;base64,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)}.sr-rd-content-center{text-align:center;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;-webkit-box-orient:vertical}.sr-rd-content-center-small{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.sr-rd-content-center-small img{margin:0;padding:0;border:0;box-shadow:none}img.simpread-img-broken{cursor:pointer}.sr-rd-content-nobeautify{margin:0;padding:0;border:0;box-shadow:0 0 0}sr-rd-mult{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin:0 0 16px;padding:16px 0 24px;width:100%;background-color:#fff;border-radius:4px;box-shadow:0 1px 2px 0 rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}sr-rd-mult:hover{-webkit-transition:all .45s 0ms;transition:all .45s 0ms;box-shadow:1px 1px 8px rgba(0,0,0,.16)}sr-rd-mult sr-rd-mult-content{padding:0 16px;overflow:auto}sr-rd-mult sr-rd-mult-avatar,sr-rd-mult sr-rd-mult-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sr-rd-mult sr-rd-mult-avatar{-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 15px}sr-rd-mult sr-rd-mult-avatar span{display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;max-width:75px;overflow:hidden;text-overflow:ellipsis;text-align:left;font-size:16px;font-size:1rem}sr-rd-mult sr-rd-mult-avatar img{margin-bottom:0;max-width:50px;max-height:50px;width:50px;height:50px;border-radius:50%}sr-rd-mult sr-rd-mult-content img{max-width:80%}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center{margin:0}sr-page{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;width:100%}</style>
                        <style type="text/css">sr-rd-theme-github{display:none}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{position:relative;margin-top:1em;margin-bottom:1pc;font-weight:700;line-height:1.4;text-align:left;color:#363636}sr-rd-content h1{padding-bottom:.3em;font-size:57.6px;font-size:3.6rem;line-height:1.2}sr-rd-content h2{padding-bottom:.3em;font-size:44.8px;font-size:2.8rem;line-height:1.225}sr-rd-content h3{font-size:38.4px;font-size:2.4rem;line-height:1.43}sr-rd-content h4{font-size:32px;font-size:2rem}sr-rd-content h5,sr-rd-content h6{font-size:25.6px;font-size:1.6rem}sr-rd-content h6{color:#777}sr-rd-content ol,sr-rd-content ul{list-style-type:disc;padding:0;padding-left:2em}sr-rd-content ol ol,sr-rd-content ul ol{list-style-type:lower-roman}sr-rd-content ol ol ol,sr-rd-content ol ul ol,sr-rd-content ul ol ol,sr-rd-content ul ul ol{list-style-type:lower-alpha}sr-rd-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all}sr-rd-content table th{font-weight:700}sr-rd-content table td,sr-rd-content table th{padding:6px 13px;border:1px solid #ddd}sr-rd-content table tr{background-color:#fff;border-top:1px solid #ccc}sr-rd-content table tr:nth-child(2n){background-color:#f8f8f8}sr-rd-content sr-blockquote{border-left:4px solid #ddd}.simpread-theme-root{background-color:#fff;color:#333}sr-rd-title{font-family:PT Sans,SF UI Display,\.PingFang SC,PingFang SC,Neue Haas Grotesk Text Pro,Arial Nova,Segoe UI,Microsoft YaHei,Microsoft JhengHei,Helvetica Neue,Source Han Sans SC,Noto Sans CJK SC,Source Han Sans CN,Noto Sans SC,Source Han Sans TC,Noto Sans CJK TC,Hiragino Sans GB,sans-serif;font-size:54.4px;font-size:3.4rem;font-weight:700;line-height:1.3}sr-rd-desc{position:relative;margin:0;margin-bottom:30px;padding:25px;padding-left:56px;font-size:28.8px;font-size:1.8rem;color:#777;background-color:rgba(0,0,0,.05);box-sizing:border-box}sr-rd-desc:before{content:"\201C";position:absolute;top:-28px;left:16px;font-size:80px;font-family:Arial;color:rgba(0,0,0,.15)}sr-rd-content,sr-rd-content *,sr-rd-content div,sr-rd-content p{color:#363636;font-weight:400;line-height:1.8}sr-rd-content b *,sr-rd-content strong,sr-rd-content strong * sr-rd-content b{-webkit-animation:none 0s ease 0s 1 normal none running;animation:none 0s ease 0s 1 normal none running;-webkit-backface-visibility:visible;backface-visibility:visible;background:transparent none repeat 0 0/auto auto padding-box border-box scroll;border:medium none currentColor;border-collapse:separate;-o-border-image:none;border-image:none;border-radius:0;border-spacing:0;bottom:auto;box-shadow:none;box-sizing:content-box;caption-side:top;clear:none;clip:auto;color:#000;-webkit-columns:auto;-moz-columns:auto;columns:auto;-webkit-column-count:auto;-moz-column-count:auto;column-count:auto;-webkit-column-fill:balance;-moz-column-fill:balance;column-fill:balance;-webkit-column-gap:normal;-moz-column-gap:normal;column-gap:normal;-webkit-column-rule:medium none currentColor;-moz-column-rule:medium none currentColor;column-rule:medium none currentColor;-webkit-column-span:1;-moz-column-span:1;column-span:1;-webkit-column-width:auto;-moz-column-width:auto;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;direction:ltr;display:inline;empty-cells:show;float:none;font-family:serif;font-size:medium;font-style:normal;font-variant:normal;font-weight:400;font-stretch:normal;line-height:normal;height:auto;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;left:auto;letter-spacing:normal;list-style:disc outside none;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;opacity:1;orphans:2;outline:medium none invert;overflow:visible;overflow-x:visible;overflow-y:visible;padding:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;-webkit-perspective:none;perspective:none;-webkit-perspective-origin:50% 50%;perspective-origin:50% 50%;position:static;right:auto;-moz-tab-size:8;-o-tab-size:8;tab-size:8;table-layout:auto;text-align:left;text-align-last:auto;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;top:auto;-webkit-transform:none;transform:none;-webkit-transform-origin:50% 50% 0;transform-origin:50% 50% 0;-webkit-transform-style:flat;transform-style:flat;-webkit-transition:none 0s ease 0s;transition:none 0s ease 0s;unicode-bidi:normal;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;word-spacing:normal;z-index:auto;all:initial}sr-rd-content a,sr-rd-content a:link{color:#4183c4;text-decoration:none}sr-rd-content a:active,sr-rd-content a:focus,sr-rd-content a:hover{color:#4183c4;text-decoration:underline}sr-rd-content pre{background-color:#f7f7f7;border-radius:3px}sr-rd-content li code,sr-rd-content p code{background-color:rgba(0,0,0,.04);border-radius:3px}.simpread-multi-root{background:#f8f9fa}</style>
                        <style type="text/css"></style>
                        <style type="text/css">@media (pointer:coarse){sr-read{margin:20px 5%!important;min-width:0!important;max-width:90%!important}sr-rd-title{margin-top:0;font-size:2.7rem}sr-rd-content sr-blockquote,sr-rd-desc{margin:10 0!important;padding:0 0 0 10px!important;width:90%;font-size:1.8rem;font-style:normal;line-height:1.7;text-align:justify}sr-rd-content{font-size:1.75rem;font-weight:300}sr-rd-content figure{margin:0;padding:0;text-align:center}sr-rd-content a,sr-rd-content a:link,sr-rd-content li code,sr-rd-content p code{font-size:inherit}sr-rd-footer{margin-top:20px}sr-blockquote,sr-blockquote *{margin:5px!important;padding:5px!important}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6,sr-rd-title{font-family:PingFang SC,Verdana,Helvetica Neue,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;font-weight:100;line-height:1.35}sr-rd-content-h1,sr-rd-content-h2,sr-rd-content-h3,sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}sr-rd-content-h1,sr-rd-content h1{font-size:1.8em}sr-rd-content-h2,sr-rd-content h2{font-size:1.6em}sr-rd-content-h3,sr-rd-content h3{font-size:1.4em}sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{font-size:1.2em}sr-rd-content-ul,sr-rd-content ul{margin-left:1.3em!important;list-style:disc}sr-rd-content-ol,sr-rd-content ol{list-style:decimal;margin-left:1.9em!important}sr-rd-content-ol ol,sr-rd-content-ol ul,sr-rd-content-ul ol,sr-rd-content-ul ul,sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em!important}sr-rd-content img{margin:0;padding:0;border:0;max-width:100%!important;height:auto;box-shadow:0 20px 20px -10px rgba(0,0,0,.1)}sr-rd-mult{min-width:0;background-color:#fff;box-shadow:0 1px 6px rgba(32,33,36,.28);border-radius:8px}sr-rd-mult sr-rd-mult-avatar div{margin:0}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center-small{margin:7px 0!important}sr-rd-mult sr-rd-mult-avatar span{display:block}sr-rd-mult sr-rd-mult-content{padding-left:0}@media only screen and (max-device-width:1024px){.simpread-theme-root,html.simpread-theme-root{font-size:80%!important}sr-rd-mult sr-rd-mult-avatar img{width:50px;height:50px;min-width:50px;min-height:50px}toc-bg toc{width:10px!important}toc-bg:hover toc{width:auto!important}}@media only screen and (max-device-width:414px){.simpread-theme-root,html.simpread-theme-root{font-size:70%!important}sr-rd-mult sr-rd-mult-avatar img{width:30px;height:30px;min-width:30px;min-height:30px}}@media only screen and (max-device-width:320px){.simpread-theme-root,html.simpread-theme-root{font-size:90%!important}sr-rd-content p{margin-bottom:.5em}}}</style>
                        <style type="text/css">undefinedsr-rd-content *, sr-rd-content p, sr-rd-content div {}sr-rd-content pre code, sr-rd-content pre code * {}sr-rd-desc {}sr-rd-content pre {}sr-rd-title {}</style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css">sr-rd-content *, sr-rd-content p, sr-rd-content div {
        font-size: 15px;
    }

    .annote-perview, .annote-perview * {
        color: rgb(85, 85, 85);
        font-weight: 400;
        line-height: 1.8;
    }</style>
                        
                        
                        <script>setTimeout(()=>{const e=location.hash.replace("#id=","");let t,a=!1;const n=t=>{for(let n of t){let t;if((t=e.length>6?n.getAttribute("data-id"):n.getAttribute("data-idx"))==e){n.scrollIntoView({behavior:"smooth",block:"start",inline:"nearest"}),a=!0;break}}};e&&(0==(t=document.getElementsByClassName("sr-unread-card")).length&&(t=document.getElementsByTagName("sr-annote")),n(t),a||n(t=document.getElementsByClassName("sr-annote")))},500);</script>
                        <script>document.addEventListener("DOMContentLoaded",function(){if("localhost"==location.hostname){const t=document.getElementsByTagName("img");for(let o of t){const t=o.src;t.startsWith("http")&&(o.src=location.origin+"/proxy?url="+t)}}},!1);</script>
                        <style>toc a {font-size: inherit!important;font-weight: 300!important;}</style><script>setTimeout(()=>{const max=document.getElementsByTagName('sr-annote-note-tip').length;for(let i=0;i<max;i++){const target=document.getElementsByTagName('sr-annote-note-tip')[i],value=target.dataset.value;value&&(target.innerText=value)}},1000);</script><title>简悦 | 24 | 文本分类：如何使用 BERT 构建文本分类模型？</title>
                    </head>
                    <body>
                        <sr-read style='font-family: "LXGW WenKai Screen";'>
                            <sr-rd-title>24 | 文本分类：如何使用 BERT 构建文本分类模型？</sr-rd-title>
                    <sr-rd-desc style="margin: 0;padding-top: 0;padding-bottom: 0;font-style: normal;font-size: 18px;">今天我们一起剖析分布式训练的原理，然后一起学习一个分布式训练的实战项目。</sr-rd-desc>
                    <sr-rd-content><h1 id="sr-toc-0">24 | 文本分类：如何使用 BERT 构建文本分类模型？</h1><div><span>方远</span> <span> 2021-12-06</span></div><div><div><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/03/1c/037a002d74175b6a8518bccd1998ec1c.jpg"></div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADEAAAABCAYAAAB35kaxAAAAAXNSR0IArs4c6QAAAChJREFUGFdjfPfu3X8GKBAUFASz3r9/DxNiQBbDxcamn1yzSLEDZi8A2agny86FR+IAAAAASUVORK5CYII="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAABCAYAAAA8TpVcAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFCYtjkAcT9D8ti7hUOAAAAAElFTkSuQmCC"></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD0AAAABCAYAAABt2qY/AAAAAXNSR0IArs4c6QAAACdJREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULy2PQQK0YLewiZCQDhUS3LBhDf1QAAAABJRU5ErkJggg=="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAABCAYAAAA4u0VhAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULyAF6lD8tbqYWOAAAAAElFTkSuQmCC"></div></div></div><div><div><div></div></div><div><div><div><div><div><div>00:00</div></div><div></div></div></div><a href="javascript:;"> 1.0x <i><span></span></i></a></div><div><span>讲述：方远</span><span>大小：14.36M</span><span> 时长：15:43</span></div></div><audio title="24 | 文本分类：如何使用BERT构建文本分类模型？" src="https://res001.geekbang.org/media/audio/a4/2e/a4305e8e07eccfc78f347a6a5bb4172e/ld/ld.m3u8" __idm_id__="221189"></audio></div><div><div><div><div data-slate-editor="true" data-key="4439" autocorrect="off" spellcheck="false" data-gramm="false"><div data-slate-type="paragraph" data-slate-object="block" data-key="4440"><span data-slate-object="text" data-key="4441"><span data-slate-leaf="true" data-offset-key="4441:0" data-first-offset="true"><span data-slate-string="true">你好，我是方远。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4442"><span data-slate-object="text" data-key="4443"><span data-slate-leaf="true" data-offset-key="4443:0" data-first-offset="true"><span data-slate-string="true">在第 22 节课我们一起学习了不少文本处理方面的理论，其实文本分类在机器学习领域的应用也非常广泛。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4444"><span data-slate-object="text" data-key="4445"><span data-slate-leaf="true" data-offset-key="4445:0" data-first-offset="true"><span data-slate-string="true">比如说你现在是一个 NLP 研发工程师，老板啪地一下甩给你一大堆新闻文本数据，它们可能来源于不同的领域，比如体育、政治、经济、社会等类型。这时我们就需要对文本分类处理，方便用户快速查询自己感兴趣的内容，甚至按用户的需要定向推荐某类内容。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4446"><span data-slate-object="text" data-key="4447"><span data-slate-leaf="true" data-offset-key="4447:0" data-first-offset="true"><span data-slate-string="true">这样的需求就非常适合用 PyTorch + BERT 处理。为什么会选择 BERT 呢？因为 BERT 是比较典型的深度学习 NLP 算法模型，也是业界使用最广泛的模型之一。接下来，我们就一起来搭建这个文本分类模型，相信我，它的效果表现非常强悍。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4448" id="sr-toc-1"><span data-slate-object="text" data-key="4449"><span data-slate-leaf="true" data-offset-key="4449:0" data-first-offset="true"><span data-slate-string="true">问题背景与分析</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4450"><span data-slate-object="text" data-key="4451"><span data-slate-leaf="true" data-offset-key="4451:0" data-first-offset="true"><span data-slate-string="true">正式动手之前，我们不妨回顾一下历史。文本分类问题有很多经典解决办法。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4452"><span data-slate-object="text" data-key="4453"><span data-slate-leaf="true" data-offset-key="4453:0" data-first-offset="true"><span data-slate-string="true">开始时就是最简单粗暴的关键词统计方法。之后又有了基于贝叶斯概率的分类方法，通过某些条件发生的概率推断某个类别的概率大小，并作为最终分类的决策依据。尽管这个思想很简单，但是意义重大，时至今日，贝叶斯方法仍旧是非常多应用场景下的好选择。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4454"><span data-slate-object="text" data-key="4455"><span data-slate-leaf="true" data-offset-key="4455:0" data-first-offset="true"><span data-slate-string="true">之后还有支持向量机（SVM），很长一段时间，其变体和应用都在 NLP 算法应用的问题场景下占据统治地位。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4456"><span data-slate-object="text" data-key="4457"><span data-slate-leaf="true" data-offset-key="4457:0" data-first-offset="true"><span data-slate-string="true">随着计算设备性能的提升、新的算法理论的产生等进步，一大批的诸如随机森林、LDA 主题模型、神经网络等方法纷纷涌现，可谓百家争鸣。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4458"><span data-slate-object="text" data-key="4459"><span data-slate-leaf="true" data-offset-key="4459:0" data-first-offset="true"><span data-slate-string="true">既然有这么多方法，为什么这里我们这里推荐选用 BERT 呢？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4460"><span data-slate-object="text" data-key="4461"><span data-slate-leaf="true" data-offset-key="4461:0" data-first-offset="true"><span data-slate-string="true">因为在很多情况下，尤其是一些复杂场景下的文本，像 BERT 这样具有强大处理能力的工具才能应对。比如说新闻文本就不好分类，因为它存在后面这些问题。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4462"><span data-slate-object="text" data-key="4463"><span data-slate-leaf="true" data-offset-key="4463:0" data-first-offset="true"><span data-slate-string="true">1.</span></span></span><span data-slate-object="text" data-key="4464"><span data-slate-leaf="true" data-offset-key="4464:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true"> 类别多</span></span></span></span><span data-slate-object="text" data-key="4465"><span data-slate-leaf="true" data-offset-key="4465:0" data-first-offset="true"><span data-slate-string="true">。在新闻资讯 App 中，新闻的种类是非常多的，需要产品经理按照统计、实用的原则进行文章分类体系的设计，使其类别能够覆盖所有的文本，一般来说都有 50 种甚至以上。不过为了让你把握重点，咱们先简化问题，假定文本的分类体系已经确定。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4466"><span data-slate-object="text" data-key="4467"><span data-slate-leaf="true" data-offset-key="4467:0" data-first-offset="true"><span data-slate-string="true">2.</span></span></span><span data-slate-object="text" data-key="4468"><span data-slate-leaf="true" data-offset-key="4468:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true"> 数据不平衡</span></span></span></span><span data-slate-object="text" data-key="4469"><span data-slate-leaf="true" data-offset-key="4469:0" data-first-offset="true"><span data-slate-string="true">。不难理解，在新闻中，社会、经济、体育、娱乐等类别的文章数量相对来说是比较多的，占据了很大的比例；而少儿、医疗等类别则相对较少，有的时候一天也没有几篇对应的文章。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4470"><span data-slate-object="text" data-key="4471"><span data-slate-leaf="true" data-offset-key="4471:0" data-first-offset="true"><span data-slate-string="true">3.</span></span></span><span data-slate-object="text" data-key="4472"><span data-slate-leaf="true" data-offset-key="4472:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true"> 多语言。</span></span></span></span><span data-slate-object="text" data-key="4473"><span data-slate-leaf="true" data-offset-key="4473:0" data-first-offset="true"><span data-slate-string="true">一般来说，咱们主要的语言除了中文，应该是大多数人只会英语了，不过为了考虑到新闻来源的广泛性，咱们也假定这批文本是多语言的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4474"><span data-slate-object="text" data-key="4475"><span data-slate-leaf="true" data-offset-key="4475:0" data-first-offset="true"><span data-slate-string="true">刚才提到了，因为 Bert 是比较典型的深度学习 NLP 算法模型，也是业界使用最广泛的模型之一。如果拿下这么有代表性的模型，以后你学习和使用基于 Attention 的模型你也能举一反三，比如 GPT 等。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4476"><span data-slate-object="text" data-key="4477"><span data-slate-leaf="true" data-offset-key="4477:0" data-first-offset="true"><span data-slate-string="true">想要用好 BERT，我们需要先了解它有哪些特点。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4478" id="sr-toc-2"><span data-slate-object="text" data-key="4479"><span data-slate-leaf="true" data-offset-key="4479:0" data-first-offset="true"><span data-slate-string="true">BERT 原理与特点分析</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4480"><span data-slate-object="text" data-key="4481"><span data-slate-leaf="true" data-offset-key="4481:0" data-first-offset="true"><span data-slate-string="true">BERT 的全称是 Bidirectional Encoder Representation from Transformers，即双向 Transformer 的 Encoder。作为一种基于 Attention 方法的模型，它最开始出现的时候可以说是抢尽了风头，在文本分类、自动对话、语义理解等十几项 NLP 任务上拿到了历史最好成绩。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4482"><span data-slate-object="text" data-key="4483"><span data-slate-leaf="true" data-offset-key="4483:0" data-first-offset="true"><span data-slate-string="true">在</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="4484"><span data-slate-object="text" data-key="4485"><span data-slate-leaf="true" data-offset-key="4485:0" data-first-offset="true"><span data-slate-string="true">第 22 节课</span></span></span></a><span data-slate-object="text" data-key="4486"><span data-slate-leaf="true" data-offset-key="4486:0" data-first-offset="true"><span data-slate-string="true">（如果不熟悉可以回看），我们已经了解了 Attention 的基本原理，有了这个知识做基础，我们很容易就能快速掌握 BERT 的原理。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4487"><span data-slate-object="text" data-key="4488"><span data-slate-leaf="true" data-offset-key="4488:0" data-first-offset="true"><span data-slate-string="true">这里我再快速给你回顾一下，BERT 的理论框架主要是基于论文《Attention is all you need》中提出的 Transformer，而后者的原理则是刚才提到的 Attention。</span></span></span><span data-slate-object="text" data-key="4489"><span data-slate-leaf="true" data-offset-key="4489:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">其最为明显的特点，就是摒弃了传统的 RNN 和 CNN 逻辑，有效解决了 NLP 中的长期依赖问题。</span></span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4490"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/57/e7/57129ea84051eaf5985535dcb97c1fe7.jpg?wh=1920x1269"></div><div>图片来源：https://arxiv.org/abs/1706.03762</div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4491"><span data-slate-object="text" data-key="4492"><span data-slate-leaf="true" data-offset-key="4492:0" data-first-offset="true"><span data-slate-string="true">在 BERT 中，它的输入部分，也就是图片的左边，其实是由 N 个多头 Attention 组合而成。多头 Attention 是将模型分为多个头，形成多个子空间，可以让模型去关注不同方面的信息，这有助于网络捕捉到更丰富的特征或者信息。（具体原理，一定要查阅</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="4493"><span data-slate-object="text" data-key="4494"><span data-slate-leaf="true" data-offset-key="4494:0" data-first-offset="true"><span data-slate-string="true">《Attention is all you need》</span></span></span></a><span data-slate-object="text" data-key="4495"><span data-slate-leaf="true" data-offset-key="4495:0" data-first-offset="true"><span data-slate-string="true">哦）。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4496"><span data-slate-object="text" data-key="4497"><span data-slate-leaf="true" data-offset-key="4497:0" data-first-offset="true"><span data-slate-string="true">结合上图我们要注意的是，BERT 采用了基于 MLM 的模型训练方式，即 Mask Language Model。因为 BERT 是 Transformer 的一部分，即 encoder 环节，所以没有 decoder 的部分（其实就是 GPT）。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4498"><span data-slate-object="text" data-key="4499"><span data-slate-leaf="true" data-offset-key="4499:0" data-first-offset="true"><span data-slate-string="true">为了解决这个问题，MLM 方式应运而生。它的思想也非常简单，就是在</span></span></span><span data-slate-object="text" data-key="4500"><span data-slate-leaf="true" data-offset-key="4500:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">训练之前，随机将文本中一部分的词语（token）进行屏蔽（mask），然后在训练的过程中，使用其他没有被屏蔽的 token 对被屏蔽的 token 进行预测</span></span></span></span><span data-slate-object="text" data-key="4501"><span data-slate-leaf="true" data-offset-key="4501:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4502"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/ae/84/aeed42d94750436f1dyye31f92c96584.jpg?wh=1920x700"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4503"><span data-slate-object="text" data-key="4504"><span data-slate-leaf="true" data-offset-key="4504:0" data-first-offset="true"><span data-slate-string="true">用过 Word2Vec 的小伙伴应该比较清楚，在 Word2Vec 中，对于同一个词语，它的向量表示是固定的，这也就是为什么会有那个经典的 “</span></span></span><span data-slate-object="text" data-key="4505"><span data-slate-leaf="true" data-offset-key="4505:0" data-first-offset="true"><span data-slate-type="italic" data-slate-object="mark"><span data-slate-string="true">国王 - 男人 + 女人 = 皇后</span></span></span></span><span data-slate-object="text" data-key="4506"><span data-slate-leaf="true" data-offset-key="4506:0" data-first-offset="true"><span data-slate-string="true">” 计算式了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4507"><span data-slate-object="text" data-key="4508"><span data-slate-leaf="true" data-offset-key="4508:0" data-first-offset="true"><span data-slate-string="true">但是有一个问题，“苹果” 这个词，有可能是水果的苹果，也可能是电子产品的品牌，如果还是用同一个向量表示，这样就有可能产生偏差。而在 BERT 中则不一样，根据上下文的不同，对于同一个 token 给出的词向量是动态变化的，更加灵活。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4509"><span data-slate-object="text" data-key="4510"><span data-slate-leaf="true" data-offset-key="4510:0" data-first-offset="true"><span data-slate-string="true">此外，BERT 还有多语言的优势。在以前的算法中，比如 SVM，如果要做多语言的模型，就要涉及分词、提取关键词等操作，而这些操作要求你对该语言有所了解。像阿拉伯文、日语等语言，咱们大概率是看不懂的，这会对我们最后的模型效果产生极大影响。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4511"><span data-slate-object="text" data-key="4512"><span data-slate-leaf="true" data-offset-key="4512:0" data-first-offset="true"><span data-slate-string="true">BERT 则不需要担心这个问题，通过基于字符、字符片段、单词等不同粒度的 token 覆盖并作 WordPiece，能够覆盖上百种语言，甚至可以说，只要你能够发明出一种逻辑上自洽的语言，BERT 就能够处理。有关 WordPiece 的介绍，你可以通过</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="4513"><span data-slate-object="text" data-key="4514"><span data-slate-leaf="true" data-offset-key="4514:0" data-first-offset="true"><span data-slate-string="true">这里</span></span></span></a><span data-slate-object="text" data-key="4515"><span data-slate-leaf="true" data-offset-key="4515:0" data-first-offset="true"><span data-slate-string="true">做拓展阅读。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4516"><span data-slate-object="text" data-key="4517"><span data-slate-leaf="true" data-offset-key="4517:0" data-first-offset="true"><span data-slate-string="true">好，说了这么多，集高效、准确、灵活再加上用途广泛于一体的 BERT，自然而然就成为了咱们的首选，下面咱们开始正式构建一个文本分类模型。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4518" id="sr-toc-3"><span data-slate-object="text" data-key="4519"><span data-slate-leaf="true" data-offset-key="4519:0" data-first-offset="true"><span data-slate-string="true">安装与准备</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4520"><span data-slate-object="text" data-key="4521"><span data-slate-leaf="true" data-offset-key="4521:0" data-first-offset="true"><span data-slate-string="true">工欲善其事，必先利其器，在开始构建模型之前，我们要安装相应的工具，然后下载对应的预先训练好的模型，同时还要了解数据的格式。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4522" id="sr-toc-4"><span data-slate-object="text" data-key="4523"><span data-slate-leaf="true" data-offset-key="4523:0" data-first-offset="true"><span data-slate-string="true">环境准备</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4524"><span data-slate-object="text" data-key="4525"><span data-slate-leaf="true" data-offset-key="4525:0" data-first-offset="true"><span data-slate-string="true">因为咱们要做的是一个基于 PyTorch 的 BERT 模型，那么就要安装对应的 python 包，这里我选择的是 hugging face 的 PyTorch 版本的 Transformers 包。你可以通过 pip 命令直接安装。</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="4526"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4527"><span data-slate-object="text" data-key="4528"><span data-slate-leaf="true" data-offset-key="4528:0" data-first-offset="true"><span data-slate-string="true">pip install Transformers</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4529" id="sr-toc-5"><span data-slate-object="text" data-key="4530"><span data-slate-leaf="true" data-offset-key="4530:0" data-first-offset="true"><span data-slate-string="true">模型准备</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4531"><span data-slate-object="text" data-key="4532"><span data-slate-leaf="true" data-offset-key="4532:0" data-first-offset="true"><span data-slate-string="true">安装之后，我们打开 Transformers 的 </span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="4533"><span data-slate-object="text" data-key="4534"><span data-slate-leaf="true" data-offset-key="4534:0" data-first-offset="true"><span data-slate-string="true">git 页面</span></span></span></a><span data-slate-object="text" data-key="4535"><span data-slate-leaf="true" data-offset-key="4535:0" data-first-offset="true"><span data-slate-string="true">，并找到如下的文件夹。</span></span></span></div><div data-code-language="css" data-slate-type="pre" data-slate-object="block" data-key="4536"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4537"><span data-slate-object="text" data-key="4538"><span data-slate-leaf="true" data-offset-key="4538:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">src</span></span></span></span><span data-slate-object="text" data-key="4539"><span data-slate-leaf="true" data-offset-key="4539:0" data-first-offset="true"><span data-slate-string="true">/Transformers/models/BERT</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4540"><span data-slate-object="text" data-key="4541"><span data-slate-leaf="true" data-offset-key="4541:0" data-first-offset="true"><span data-slate-string="true">从这个文件夹里，我们需要找到两个很重要的文件，分别是 convert_BERT_original_tf2_checkpoint_to_PyTorch.py 和 modeling_BERT.py 文件。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4542"><span data-slate-object="text" data-key="4543"><span data-slate-leaf="true" data-offset-key="4543:0" data-first-offset="true"><span data-slate-string="true">先来看第一个文件，你看看名字，是不是就能猜出来，它大概是用来做什么的了？没错，就是用来将原来通过 TensorfFlow 预训练的模型转换为 PyTorch 的模型。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4544"><span data-slate-object="text" data-key="4545"><span data-slate-leaf="true" data-offset-key="4545:0" data-first-offset="true"><span data-slate-string="true">然后是 modeling_BERT.py 文件，这个文件实际上是给了你一个使用 BERT 的范例。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4546"><span data-slate-object="text" data-key="4547"><span data-slate-leaf="true" data-offset-key="4547:0" data-first-offset="true"><span data-slate-string="true">下面，咱们开始准备模型，打开</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="4548"><span data-slate-object="text" data-key="4549"><span data-slate-leaf="true" data-offset-key="4549:0" data-first-offset="true"><span data-slate-string="true">这个地址</span></span></span></a><span data-slate-object="text" data-key="4550"><span data-slate-leaf="true" data-offset-key="4550:0" data-first-offset="true"><span data-slate-string="true">，你会发现在这个页面中，有几个预训练好的模型。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4551"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/f7/a9/f7429816e9c736d99be4b55c67bac6a9.png?wh=1920x956"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4552"><span data-slate-object="text" data-key="4553"><span data-slate-leaf="true" data-offset-key="4553:0" data-first-offset="true"><span data-slate-string="true">对照这节课的任务，我们选择的是 “BERT-Base, Multilingual Cased” 的版本。从 GitHub 的介绍可以看出，这个版本的 checkpoint 支持 104 种语言，是不是很厉害？当然，如果你没有多语言的需求，也可以选择其他版本的，它们的区别主要是网络的体积不同。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4554"><span data-slate-object="text" data-key="4555"><span data-slate-leaf="true" data-offset-key="4555:0" data-first-offset="true"><span data-slate-string="true">转换完模型之后，你会发现你的本地多了三个文件，分别是 config.json、pytorch_model.bin 和 vocab.txt。我来分别给你说一说。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4556"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/a8/00/a85bfecfb02108cf7e46d5bef74efe00.jpg?wh=1920x228"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4557"><span data-slate-object="text" data-key="4558"><span data-slate-leaf="true" data-offset-key="4558:0" data-first-offset="true"><span data-slate-string="true">1.config.json：顾名思义，该文件就是 BERT 模型的配置文件，里面记录了所有用于训练的参数设置。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4559"><span data-slate-object="text" data-key="4560"><span data-slate-leaf="true" data-offset-key="4560:0" data-first-offset="true"><span data-slate-string="true">2.PyTorch_model.bin：模型文件本身。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4561"><span data-slate-object="text" data-key="4562"><span data-slate-leaf="true" data-offset-key="4562:0" data-first-offset="true"><span data-slate-string="true">3.vocab.txt：词表文件。尽管 BERT 可以处理一百多种语言，但是它仍旧需要词表文件用于识别所支持语言的字符、字符串或者单词。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4563" id="sr-toc-6"><span data-slate-object="text" data-key="4564"><span data-slate-leaf="true" data-offset-key="4564:0" data-first-offset="true"><span data-slate-string="true">格式准备</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4565"><span data-slate-object="text" data-key="4566"><span data-slate-leaf="true" data-offset-key="4566:0" data-first-offset="true"><span data-slate-string="true">现在模型准备好了，我们还要看看跟模型匹配的格式。BERT 的输入不算复杂，但是也需要了解其形式。在训练的时候，我们输入的数据不能是直接把词塞到模型里，而是要转化成后面这三种向量。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4567"><span data-slate-object="text" data-key="4568"><span data-slate-leaf="true" data-offset-key="4568:0" data-first-offset="true"><span data-slate-string="true">1.</span></span></span><span data-slate-object="text" data-key="4569"><span data-slate-leaf="true" data-offset-key="4569:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">Token embeddings</span></span></span></span><span data-slate-object="text" data-key="4570"><span data-slate-leaf="true" data-offset-key="4570:0" data-first-offset="true"><span data-slate-string="true">：词向量。这里需要注意的是，Token embeddings 的第一个开头的 token 一定得是 “[CLS]”。[CLS] 作为整篇文本的语义表示，用于文本分类等任务。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4571"><span data-slate-object="text" data-key="4572"><span data-slate-leaf="true" data-offset-key="4572:0" data-first-offset="true"><span data-slate-string="true">2.</span></span></span><span data-slate-object="text" data-key="4573"><span data-slate-leaf="true" data-offset-key="4573:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">Segment embeddings</span></span></span></span><span data-slate-object="text" data-key="4574"><span data-slate-leaf="true" data-offset-key="4574:0" data-first-offset="true"><span data-slate-string="true">。这个向量主要是用来将两句话进行区分，比如问答任务，会有问句和答句同时输入，这就需要一个能够区分两句话的操作。不过在咱们此次的分类任务中，只有一个句子。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4575"><span data-slate-object="text" data-key="4576"><span data-slate-leaf="true" data-offset-key="4576:0" data-first-offset="true"><span data-slate-string="true">3.</span></span></span><span data-slate-object="text" data-key="4577"><span data-slate-leaf="true" data-offset-key="4577:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">Position embeddings</span></span></span></span><span data-slate-object="text" data-key="4578"><span data-slate-leaf="true" data-offset-key="4578:0" data-first-offset="true"><span data-slate-string="true">。记录了单词的位置信息。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4579" id="sr-toc-7"><span data-slate-object="text" data-key="4580"><span data-slate-leaf="true" data-offset-key="4580:0" data-first-offset="true"><span data-slate-string="true">模型构建</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4581"><span data-slate-object="text" data-key="4582"><span data-slate-leaf="true" data-offset-key="4582:0" data-first-offset="true"><span data-slate-string="true">准备工作已经一切就绪，我们这就来搭建一个基于 BERT 的文本分类网络模型。这包括了</span></span></span><span data-slate-object="text" data-key="4583"><span data-slate-leaf="true" data-offset-key="4583:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">网络的设计、配置、以及数据准备，这个过程也是咱们的核心过程</span></span></span></span><span data-slate-object="text" data-key="4584"><span data-slate-leaf="true" data-offset-key="4584:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4585" id="sr-toc-8"><span data-slate-object="text" data-key="4586"><span data-slate-leaf="true" data-offset-key="4586:0" data-first-offset="true"><span data-slate-string="true">网络设计</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4587"><span data-slate-object="text" data-key="4588"><span data-slate-leaf="true" data-offset-key="4588:0" data-first-offset="true"><span data-slate-string="true">从上面提到的 modeling_BERT.py 文件中，我们可以看到，作者实际上已经给我们提供了很多种类的 NLP 任务的示例代码，咱们找到其中的 “BERTForSequenceClassification”，这个分类网络我们可以直接使用，它也是最最基础的 BERT 文本分类的流程。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4589"><span data-slate-object="text" data-key="4590"><span data-slate-leaf="true" data-offset-key="4590:0" data-first-offset="true"><span data-slate-string="true">这个过程包括了利用 </span></span></span><span data-slate-object="text" data-key="4591"><span data-slate-leaf="true" data-offset-key="4591:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">BERT 得到文本的 embedding 表示</span></span></span></span><span data-slate-object="text" data-key="4592"><span data-slate-leaf="true" data-offset-key="4592:0" data-first-offset="true"><span data-slate-string="true">、</span></span></span><span data-slate-object="text" data-key="4593"><span data-slate-leaf="true" data-offset-key="4593:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">将 embedding 放入全连接层得到分类结果</span></span></span></span><span data-slate-object="text" data-key="4594"><span data-slate-leaf="true" data-offset-key="4594:0" data-first-offset="true"><span data-slate-string="true">两部分。我们具体看一下代码。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4595"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div><div data-code-line-number="18"></div><div data-code-line-number="19"></div><div data-code-line-number="20"></div><div data-code-line-number="21"></div><div data-code-line-number="22"></div><div data-code-line-number="23"></div><div data-code-line-number="24"></div><div data-code-line-number="25"></div><div data-code-line-number="26"></div><div data-code-line-number="27"></div><div data-code-line-number="28"></div><div data-code-line-number="29"></div><div data-code-line-number="30"></div><div data-code-line-number="31"></div><div data-code-line-number="32"></div><div data-code-line-number="33"></div><div data-code-line-number="34"></div><div data-code-line-number="35"></div><div data-code-line-number="36"></div><div data-code-line-number="37"></div><div data-code-line-number="38"></div><div data-code-line-number="39"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4596"><span data-slate-object="text" data-key="4597"><span data-slate-leaf="true" data-offset-key="4597:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">class</span></span></span></span><span data-slate-object="text" data-key="4598"><span data-slate-leaf="true" data-offset-key="4598:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4599"><span data-slate-leaf="true" data-offset-key="4599:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">BERTForSequenceClassification</span></span></span></span><span data-slate-object="text" data-key="4600"><span data-slate-leaf="true" data-offset-key="4600:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4601"><span data-slate-leaf="true" data-offset-key="4601:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">BERTPreTrainedModel</span></span></span></span><span data-slate-object="text" data-key="4602"><span data-slate-leaf="true" data-offset-key="4602:0" data-first-offset="true"><span data-slate-string="true">):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4603"><span data-slate-object="text" data-key="4604"><span data-slate-leaf="true" data-offset-key="4604:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4605"><span data-slate-leaf="true" data-offset-key="4605:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">def</span></span></span></span><span data-slate-object="text" data-key="4606"><span data-slate-leaf="true" data-offset-key="4606:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4607"><span data-slate-leaf="true" data-offset-key="4607:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">__init__</span></span></span></span><span data-slate-object="text" data-key="4608"><span data-slate-leaf="true" data-offset-key="4608:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4609"><span data-slate-leaf="true" data-offset-key="4609:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">self, config</span></span></span></span><span data-slate-object="text" data-key="4610"><span data-slate-leaf="true" data-offset-key="4610:0" data-first-offset="true"><span data-slate-string="true">):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4611"><span data-slate-object="text" data-key="4612"><span data-slate-leaf="true" data-offset-key="4612:0" data-first-offset="true"><span data-slate-string="true">        </span></span></span><span data-slate-object="text" data-key="4613"><span data-slate-leaf="true" data-offset-key="4613:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">super</span></span></span></span><span data-slate-object="text" data-key="4614"><span data-slate-leaf="true" data-offset-key="4614:0" data-first-offset="true"><span data-slate-string="true">().__init__(config)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4615"><span data-slate-object="text" data-key="4616"><span data-slate-leaf="true" data-offset-key="4616:0" data-first-offset="true"><span data-slate-string="true">        self.num_labels = config.num_labels// 类别标签数量</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4617"><span data-slate-object="text" data-key="4618"><span data-slate-leaf="true" data-offset-key="4618:0" data-first-offset="true"><span data-slate-string="true">        self.bert = BertModel(config)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4619"><span data-slate-object="text" data-key="4620"><span data-slate-leaf="true" data-offset-key="4620:0" data-first-offset="true"><span data-slate-string="true">        self.dropout = nn.Dropout (config.hidden_dropout_prob)// 还记得 Dropout 是用来做什么的吗？对，可以一定程度防止过拟合。</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4621"><span data-slate-object="text" data-key="4622"><span data-slate-leaf="true" data-offset-key="4622:0" data-first-offset="true"><span data-slate-string="true">        self.classifier = nn.Linear (config.hidden_size, config.num_labels)//BERT 输出的 embedding 传入一个 MLP 层做分类。</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4623"><span data-slate-object="text" data-key="4624"><span data-slate-leaf="true" data-offset-key="4624:0" data-first-offset="true"><span data-slate-string="true">        self.init_weights()</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4625"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4626"><span data-slate-object="text" data-key="4627"><span data-slate-leaf="true" data-offset-key="4627:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4628"><span data-slate-leaf="true" data-offset-key="4628:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">def</span></span></span></span><span data-slate-object="text" data-key="4629"><span data-slate-leaf="true" data-offset-key="4629:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4630"><span data-slate-leaf="true" data-offset-key="4630:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">forward</span></span></span></span><span data-slate-object="text" data-key="4631"><span data-slate-leaf="true" data-offset-key="4631:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4632"><span data-slate-object="text" data-key="4633"><span data-slate-leaf="true" data-offset-key="4633:0" data-first-offset="true"><span data-slate-string="true">        self,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4634"><span data-slate-object="text" data-key="4635"><span data-slate-leaf="true" data-offset-key="4635:0" data-first-offset="true"><span data-slate-string="true">        input_ids=</span></span></span><span data-slate-object="text" data-key="4636"><span data-slate-leaf="true" data-offset-key="4636:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4637"><span data-slate-leaf="true" data-offset-key="4637:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4638"><span data-slate-object="text" data-key="4639"><span data-slate-leaf="true" data-offset-key="4639:0" data-first-offset="true"><span data-slate-string="true">        attention_mask=</span></span></span><span data-slate-object="text" data-key="4640"><span data-slate-leaf="true" data-offset-key="4640:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4641"><span data-slate-leaf="true" data-offset-key="4641:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4642"><span data-slate-object="text" data-key="4643"><span data-slate-leaf="true" data-offset-key="4643:0" data-first-offset="true"><span data-slate-string="true">        token_type_ids=</span></span></span><span data-slate-object="text" data-key="4644"><span data-slate-leaf="true" data-offset-key="4644:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4645"><span data-slate-leaf="true" data-offset-key="4645:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4646"><span data-slate-object="text" data-key="4647"><span data-slate-leaf="true" data-offset-key="4647:0" data-first-offset="true"><span data-slate-string="true">        position_ids=</span></span></span><span data-slate-object="text" data-key="4648"><span data-slate-leaf="true" data-offset-key="4648:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4649"><span data-slate-leaf="true" data-offset-key="4649:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4650"><span data-slate-object="text" data-key="4651"><span data-slate-leaf="true" data-offset-key="4651:0" data-first-offset="true"><span data-slate-string="true">        head_mask=</span></span></span><span data-slate-object="text" data-key="4652"><span data-slate-leaf="true" data-offset-key="4652:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4653"><span data-slate-leaf="true" data-offset-key="4653:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4654"><span data-slate-object="text" data-key="4655"><span data-slate-leaf="true" data-offset-key="4655:0" data-first-offset="true"><span data-slate-string="true">        inputs_embeds=</span></span></span><span data-slate-object="text" data-key="4656"><span data-slate-leaf="true" data-offset-key="4656:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4657"><span data-slate-leaf="true" data-offset-key="4657:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4658"><span data-slate-object="text" data-key="4659"><span data-slate-leaf="true" data-offset-key="4659:0" data-first-offset="true"><span data-slate-string="true">        labels=</span></span></span><span data-slate-object="text" data-key="4660"><span data-slate-leaf="true" data-offset-key="4660:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4661"><span data-slate-leaf="true" data-offset-key="4661:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4662"><span data-slate-object="text" data-key="4663"><span data-slate-leaf="true" data-offset-key="4663:0" data-first-offset="true"><span data-slate-string="true">        output_attentions=</span></span></span><span data-slate-object="text" data-key="4664"><span data-slate-leaf="true" data-offset-key="4664:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4665"><span data-slate-leaf="true" data-offset-key="4665:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4666"><span data-slate-object="text" data-key="4667"><span data-slate-leaf="true" data-offset-key="4667:0" data-first-offset="true"><span data-slate-string="true">        output_hidden_states=</span></span></span><span data-slate-object="text" data-key="4668"><span data-slate-leaf="true" data-offset-key="4668:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4669"><span data-slate-leaf="true" data-offset-key="4669:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4670"><span data-slate-object="text" data-key="4671"><span data-slate-leaf="true" data-offset-key="4671:0" data-first-offset="true"><span data-slate-string="true">        return_dict=</span></span></span><span data-slate-object="text" data-key="4672"><span data-slate-leaf="true" data-offset-key="4672:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4673"><span data-slate-leaf="true" data-offset-key="4673:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4674"><span data-slate-object="text" data-key="4675"><span data-slate-leaf="true" data-offset-key="4675:0" data-first-offset="true"><span data-slate-string="true">    ):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4676"><span data-slate-object="text" data-key="4677"><span data-slate-leaf="true" data-offset-key="4677:0" data-first-offset="true"><span data-slate-string="true">        outputs = self.bert(</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4678"><span data-slate-object="text" data-key="4679"><span data-slate-leaf="true" data-offset-key="4679:0" data-first-offset="true"><span data-slate-string="true">            input_ids,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4680"><span data-slate-object="text" data-key="4681"><span data-slate-leaf="true" data-offset-key="4681:0" data-first-offset="true"><span data-slate-string="true">            attention_mask=attention_mask,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4682"><span data-slate-object="text" data-key="4683"><span data-slate-leaf="true" data-offset-key="4683:0" data-first-offset="true"><span data-slate-string="true">            token_type_ids=token_type_ids,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4684"><span data-slate-object="text" data-key="4685"><span data-slate-leaf="true" data-offset-key="4685:0" data-first-offset="true"><span data-slate-string="true">            position_ids=position_ids,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4686"><span data-slate-object="text" data-key="4687"><span data-slate-leaf="true" data-offset-key="4687:0" data-first-offset="true"><span data-slate-string="true">            head_mask=head_mask,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4688"><span data-slate-object="text" data-key="4689"><span data-slate-leaf="true" data-offset-key="4689:0" data-first-offset="true"><span data-slate-string="true">            inputs_embeds=inputs_embeds,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4690"><span data-slate-object="text" data-key="4691"><span data-slate-leaf="true" data-offset-key="4691:0" data-first-offset="true"><span data-slate-string="true">            output_attentions=output_attentions,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4692"><span data-slate-object="text" data-key="4693"><span data-slate-leaf="true" data-offset-key="4693:0" data-first-offset="true"><span data-slate-string="true">            output_hidden_states=output_hidden_states,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4694"><span data-slate-object="text" data-key="4695"><span data-slate-leaf="true" data-offset-key="4695:0" data-first-offset="true"><span data-slate-string="true">            return_dict=return_dict,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4696"><span data-slate-object="text" data-key="4697"><span data-slate-leaf="true" data-offset-key="4697:0" data-first-offset="true"><span data-slate-string="true">        )</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4698"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4699"><span data-slate-object="text" data-key="4700"><span data-slate-leaf="true" data-offset-key="4700:0" data-first-offset="true"><span data-slate-string="true">        pooled_output = outputs[</span></span></span><span data-slate-object="text" data-key="4701"><span data-slate-leaf="true" data-offset-key="4701:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="4702"><span data-slate-leaf="true" data-offset-key="4702:0" data-first-offset="true"><span data-slate-string="true">]// 这个就是经过 BERT 得到的中间输出。</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4703"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4704"><span data-slate-object="text" data-key="4705"><span data-slate-leaf="true" data-offset-key="4705:0" data-first-offset="true"><span data-slate-string="true">        pooled_output = self.dropout (pooled_output)// 对，就是为了减少过拟合和增加网络的健壮性。</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4706"><span data-slate-object="text" data-key="4707"><span data-slate-leaf="true" data-offset-key="4707:0" data-first-offset="true"><span data-slate-string="true">        logits = self.classifier (pooled_output)// 多层 MLP 输出最后的分类结果。</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4708"></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4709"><span data-slate-object="text" data-key="4710"><span data-slate-leaf="true" data-offset-key="4710:0" data-first-offset="true"><span data-slate-string="true">对照前面的代码，可以发现，接收到输入信息之后，BERT 返回了一个 outputs，outputs 包括了模型计算之后的全部结果，不仅有每个 token 的信息，也有整个文本的信息，这个输出具体包括以下信息。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4711"><span data-slate-object="text" data-key="4712"><span data-slate-leaf="true" data-offset-key="4712:0" data-first-offset="true"><span data-slate-string="true">last_hidden_state 是模型最后一层输出的隐藏层状态序列。shape 是 (batch_size, sequence_length, hidden_size)。其中 hidden_size=768，这个部分的状态，就相当于利用 sequence_length * 768 维度的矩阵，记录了整个文本的计算之后的每一个 token 的结果信息。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4713"><span data-slate-object="text" data-key="4714"><span data-slate-leaf="true" data-offset-key="4714:0" data-first-offset="true"><span data-slate-string="true">pooled_output，代表序列的第一个 token 的最后一个隐藏层的状态。shape 是 (batch_size, hidden_size)。所谓的第一个 token，就是咱们刚才提到的 [CLS] 标签。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4715"><span data-slate-object="text" data-key="4716"><span data-slate-leaf="true" data-offset-key="4716:0" data-first-offset="true"><span data-slate-string="true">除了上面两个信息，还有 hidden_states、attentions、cross attentions。有兴趣的小伙伴可以去查一下，它们有何用途。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4717"><span data-slate-object="text" data-key="4718"><span data-slate-leaf="true" data-offset-key="4718:0" data-first-offset="true"><span data-slate-string="true">通常的任务中，我们用得比较多的是 last_hidden_state 对应的信息，我们可以用 pooled_output = outputs [1] 来进行获取。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4719"><span data-slate-object="text" data-key="4720"><span data-slate-leaf="true" data-offset-key="4720:0" data-first-offset="true"><span data-slate-string="true">至此，我们已经有了经过 BERT 计算的文本向量表示，然后我们将其输入到一个 linear 层中进行分类，就可以得到最后的分类结果了。</span></span></span><span data-slate-object="text" data-key="4721"><span data-slate-leaf="true" data-offset-key="4721:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">为了提高模型的表现，我们往往会在 linear 层之前，加入一个 dropout 层，这样可以减少网络的过拟合的可能性，同时增强神经元的独立性</span></span></span></span><span data-slate-object="text" data-key="4722"><span data-slate-leaf="true" data-offset-key="4722:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4723" id="sr-toc-9"><span data-slate-object="text" data-key="4724"><span data-slate-leaf="true" data-offset-key="4724:0" data-first-offset="true"><span data-slate-string="true">模型配置</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4725"><span data-slate-object="text" data-key="4726"><span data-slate-leaf="true" data-offset-key="4726:0" data-first-offset="true"><span data-slate-string="true">设计好网络，我们还要对模型进行配置。还记得刚才提到的 config.json 文件么？这里面就记录了 BERT 模型所需的所有配置信息，我们需要对其中的几个内容进行调整，这样模型就能知道我们到底是要做什么事情了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4727"><span data-slate-object="text" data-key="4728"><span data-slate-leaf="true" data-offset-key="4728:0" data-first-offset="true"><span data-slate-string="true">后面这几个字段我专门说一下。</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="4729"><div data-slate-type="list-line" data-slate-object="block" data-key="4730"><span data-slate-object="text" data-key="4731"><span data-slate-leaf="true" data-offset-key="4731:0" data-first-offset="true"><span data-slate-string="true">id2label：这个字段记录了类别标签和类别名称的映射关系。</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4732"><span data-slate-object="text" data-key="4733"><span data-slate-leaf="true" data-offset-key="4733:0" data-first-offset="true"><span data-slate-string="true">label2id：这个字段记录了类别名称和类别标签的映射关系。</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4734"><span data-slate-object="text" data-key="4735"><span data-slate-leaf="true" data-offset-key="4735:0" data-first-offset="true"><span data-slate-string="true">num_labels_cate：类别的数量。</span></span></span></div></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4736" id="sr-toc-10"><span data-slate-object="text" data-key="4737"><span data-slate-leaf="true" data-offset-key="4737:0" data-first-offset="true"><span data-slate-string="true">数据准备</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4738"><span data-slate-object="text" data-key="4739"><span data-slate-leaf="true" data-offset-key="4739:0" data-first-offset="true"><span data-slate-string="true">模型网络设计好了，配置文件也搞定了，下面我们就要开始数据准备这一步了。这里的数据准备是指将文本转换为 BERT 能够识别的形式，即前面提到的三种向量，在代码中，对应的就是 input_ids、token_type_ids、attention_mask。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4740"><span data-slate-object="text" data-key="4741"><span data-slate-leaf="true" data-offset-key="4741:0" data-first-offset="true"><span data-slate-string="true">为了生成这些数据，我们需要在 git 中找到 “src/Transformers/data/processors/utils.py” 文件，在这个文件中，我们要用到以下几个内容。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4742"><span data-slate-object="text" data-key="4743"><span data-slate-leaf="true" data-offset-key="4743:0" data-first-offset="true"><span data-slate-string="true">1.InputExample：它用于记录单个训练数据的文本内容的结构。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4744"><span data-slate-object="text" data-key="4745"><span data-slate-leaf="true" data-offset-key="4745:0" data-first-offset="true"><span data-slate-string="true">2.DataProcessor：通过这个类中的函数，我们可以将训练数据集的文本，表示为多个 InputExample 组成的数据集合。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4746"><span data-slate-object="text" data-key="4747"><span data-slate-leaf="true" data-offset-key="4747:0" data-first-offset="true"><span data-slate-string="true">3.get_features：用于把 InputExample 数据转换成 BERT 能够理解的数据结构的关键函数。我们具体来看一下各个数据都怎么生成的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4748"><span data-slate-object="text" data-key="4749"><span data-slate-leaf="true" data-offset-key="4749:0" data-first-offset="true"><span data-slate-string="true">input_ids 记录了输入 token 对应在 vocab.txt 的 id 序号，它是通过如下的代码得到的。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4750"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4751"><span data-slate-object="text" data-key="4752"><span data-slate-leaf="true" data-offset-key="4752:0" data-first-offset="true"><span data-slate-string="true">input_ids = tokenizer.encode(</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4753"><span data-slate-object="text" data-key="4754"><span data-slate-leaf="true" data-offset-key="4754:0" data-first-offset="true"><span data-slate-string="true">                  example.text_a,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4755"><span data-slate-object="text" data-key="4756"><span data-slate-leaf="true" data-offset-key="4756:0" data-first-offset="true"><span data-slate-string="true">                  add_special_tokens=</span></span></span><span data-slate-object="text" data-key="4757"><span data-slate-leaf="true" data-offset-key="4757:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">True</span></span></span></span><span data-slate-object="text" data-key="4758"><span data-slate-leaf="true" data-offset-key="4758:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4759"><span data-slate-object="text" data-key="4760"><span data-slate-leaf="true" data-offset-key="4760:0" data-first-offset="true"><span data-slate-string="true">                  max_length=</span></span></span><span data-slate-object="text" data-key="4761"><span data-slate-leaf="true" data-offset-key="4761:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">min</span></span></span></span><span data-slate-object="text" data-key="4762"><span data-slate-leaf="true" data-offset-key="4762:0" data-first-offset="true"><span data-slate-string="true">(max_length, tokenizer.max_len),</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4763"><span data-slate-object="text" data-key="4764"><span data-slate-leaf="true" data-offset-key="4764:0" data-first-offset="true"><span data-slate-string="true">              )</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4765"><span data-slate-object="text" data-key="4766"><span data-slate-leaf="true" data-offset-key="4766:0" data-first-offset="true"><span data-slate-string="true">而 attention_mask 记录了属于第一个句子的 token 信息，通过如下代码得到。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4767"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4768"><span data-slate-object="text" data-key="4769"><span data-slate-leaf="true" data-offset-key="4769:0" data-first-offset="true"><span data-slate-string="true">attention_mask = [</span></span></span><span data-slate-object="text" data-key="4770"><span data-slate-leaf="true" data-offset-key="4770:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="4771"><span data-slate-leaf="true" data-offset-key="4771:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4772"><span data-slate-leaf="true" data-offset-key="4772:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">if</span></span></span></span><span data-slate-object="text" data-key="4773"><span data-slate-leaf="true" data-offset-key="4773:0" data-first-offset="true"><span data-slate-string="true"> mask_padding_with_zero </span></span></span><span data-slate-object="text" data-key="4774"><span data-slate-leaf="true" data-offset-key="4774:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">else</span></span></span></span><span data-slate-object="text" data-key="4775"><span data-slate-leaf="true" data-offset-key="4775:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4776"><span data-slate-leaf="true" data-offset-key="4776:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4777"><span data-slate-leaf="true" data-offset-key="4777:0" data-first-offset="true"><span data-slate-string="true">] * </span></span></span><span data-slate-object="text" data-key="4778"><span data-slate-leaf="true" data-offset-key="4778:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">len</span></span></span></span><span data-slate-object="text" data-key="4779"><span data-slate-leaf="true" data-offset-key="4779:0" data-first-offset="true"><span data-slate-string="true">(input_ids)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4780"><span data-slate-object="text" data-key="4781"><span data-slate-leaf="true" data-offset-key="4781:0" data-first-offset="true"><span data-slate-string="true">attention_mask = attention_mask + ([</span></span></span><span data-slate-object="text" data-key="4782"><span data-slate-leaf="true" data-offset-key="4782:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4783"><span data-slate-leaf="true" data-offset-key="4783:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4784"><span data-slate-leaf="true" data-offset-key="4784:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">if</span></span></span></span><span data-slate-object="text" data-key="4785"><span data-slate-leaf="true" data-offset-key="4785:0" data-first-offset="true"><span data-slate-string="true"> mask_padding_with_zero </span></span></span><span data-slate-object="text" data-key="4786"><span data-slate-leaf="true" data-offset-key="4786:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">else</span></span></span></span><span data-slate-object="text" data-key="4787"><span data-slate-leaf="true" data-offset-key="4787:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4788"><span data-slate-leaf="true" data-offset-key="4788:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="4789"><span data-slate-leaf="true" data-offset-key="4789:0" data-first-offset="true"><span data-slate-string="true">] * padding_length)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4790"><span data-slate-object="text" data-key="4791"><span data-slate-leaf="true" data-offset-key="4791:0" data-first-offset="true"><span data-slate-string="true">另外，不要忘记记录文本类别的信息（label）。你可以自己想想看，能否按照 utils.py 文件中的声明方式，构建出对应的 label 信息呢？</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4792" id="sr-toc-11"><span data-slate-object="text" data-key="4793"><span data-slate-leaf="true" data-offset-key="4793:0" data-first-offset="true"><span data-slate-string="true">模型训练</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4794"><span data-slate-object="text" data-key="4795"><span data-slate-leaf="true" data-offset-key="4795:0" data-first-offset="true"><span data-slate-string="true">到目前为止，我们有了网络结构定义（BERTForSequenceClassification）、数据集合（get_features），现在就可以开始编写实现训练过程的代码了。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4796" id="sr-toc-12"><span data-slate-object="text" data-key="4797"><span data-slate-leaf="true" data-offset-key="4797:0" data-first-offset="true"><span data-slate-string="true">选择优化器</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4798"><span data-slate-object="text" data-key="4799"><span data-slate-leaf="true" data-offset-key="4799:0" data-first-offset="true"><span data-slate-string="true">首先我们来选择优化器，代码如下。我们要对网络中的所有权重参数进行设置，这样优化器就可以知道哪些参数是要进行优化的。然后我们将参数 list 放到优化器中，BERT 使用的是 AdamW 优化器。</span></span></span></div><div data-code-language="rust" data-slate-type="pre" data-slate-object="block" data-key="4800"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4801"><span data-slate-object="text" data-key="4802"><span data-slate-leaf="true" data-offset-key="4802:0" data-first-offset="true"><span data-slate-string="true">param_optimizer = </span></span></span><span data-slate-object="text" data-key="4803"><span data-slate-leaf="true" data-offset-key="4803:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">list</span></span></span></span><span data-slate-object="text" data-key="4804"><span data-slate-leaf="true" data-offset-key="4804:0" data-first-offset="true"><span data-slate-string="true">(model.</span></span></span><span data-slate-object="text" data-key="4805"><span data-slate-leaf="true" data-offset-key="4805:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">named_parameters</span></span></span></span><span data-slate-object="text" data-key="4806"><span data-slate-leaf="true" data-offset-key="4806:0" data-first-offset="true"><span data-slate-string="true">())</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4807"><span data-slate-object="text" data-key="4808"><span data-slate-leaf="true" data-offset-key="4808:0" data-first-offset="true"><span data-slate-string="true">no_decay = [</span></span></span><span data-slate-object="text" data-key="4809"><span data-slate-leaf="true" data-offset-key="4809:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'bias</span></span></span></span><span data-slate-object="text" data-key="4810"><span data-slate-leaf="true" data-offset-key="4810:0" data-first-offset="true"><span data-slate-string="true">', </span></span></span><span data-slate-object="text" data-key="4811"><span data-slate-leaf="true" data-offset-key="4811:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'LayerNorm</span></span></span></span><span data-slate-object="text" data-key="4812"><span data-slate-leaf="true" data-offset-key="4812:0" data-first-offset="true"><span data-slate-string="true">.bias', </span></span></span><span data-slate-object="text" data-key="4813"><span data-slate-leaf="true" data-offset-key="4813:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'LayerNorm</span></span></span></span><span data-slate-object="text" data-key="4814"><span data-slate-leaf="true" data-offset-key="4814:0" data-first-offset="true"><span data-slate-string="true">.weight']</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4815"><span data-slate-object="text" data-key="4816"><span data-slate-leaf="true" data-offset-key="4816:0" data-first-offset="true"><span data-slate-string="true">optimizer_grouped_parameters = [</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4817"><span data-slate-object="text" data-key="4818"><span data-slate-leaf="true" data-offset-key="4818:0" data-first-offset="true"><span data-slate-string="true">            {</span></span></span><span data-slate-object="text" data-key="4819"><span data-slate-leaf="true" data-offset-key="4819:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'params</span></span></span></span><span data-slate-object="text" data-key="4820"><span data-slate-leaf="true" data-offset-key="4820:0" data-first-offset="true"><span data-slate-string="true">': [p </span></span></span><span data-slate-object="text" data-key="4821"><span data-slate-leaf="true" data-offset-key="4821:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">for</span></span></span></span><span data-slate-object="text" data-key="4822"><span data-slate-leaf="true" data-offset-key="4822:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4823"><span data-slate-leaf="true" data-offset-key="4823:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">n</span></span></span></span><span data-slate-object="text" data-key="4824"><span data-slate-leaf="true" data-offset-key="4824:0" data-first-offset="true"><span data-slate-string="true">, p </span></span></span><span data-slate-object="text" data-key="4825"><span data-slate-leaf="true" data-offset-key="4825:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4826"><span data-slate-leaf="true" data-offset-key="4826:0" data-first-offset="true"><span data-slate-string="true"> param_optimizer </span></span></span><span data-slate-object="text" data-key="4827"><span data-slate-leaf="true" data-offset-key="4827:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">if</span></span></span></span><span data-slate-object="text" data-key="4828"><span data-slate-leaf="true" data-offset-key="4828:0" data-first-offset="true"><span data-slate-string="true"> not </span></span></span><span data-slate-object="text" data-key="4829"><span data-slate-leaf="true" data-offset-key="4829:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">any</span></span></span></span><span data-slate-object="text" data-key="4830"><span data-slate-leaf="true" data-offset-key="4830:0" data-first-offset="true"><span data-slate-string="true">(nd </span></span></span><span data-slate-object="text" data-key="4831"><span data-slate-leaf="true" data-offset-key="4831:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4832"><span data-slate-leaf="true" data-offset-key="4832:0" data-first-offset="true"><span data-slate-string="true"> n </span></span></span><span data-slate-object="text" data-key="4833"><span data-slate-leaf="true" data-offset-key="4833:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">for</span></span></span></span><span data-slate-object="text" data-key="4834"><span data-slate-leaf="true" data-offset-key="4834:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4835"><span data-slate-leaf="true" data-offset-key="4835:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">nd</span></span></span></span><span data-slate-object="text" data-key="4836"><span data-slate-leaf="true" data-offset-key="4836:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4837"><span data-slate-leaf="true" data-offset-key="4837:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4838"><span data-slate-leaf="true" data-offset-key="4838:0" data-first-offset="true"><span data-slate-string="true"> no_decay)], </span></span></span><span data-slate-object="text" data-key="4839"><span data-slate-leaf="true" data-offset-key="4839:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'weight_decay</span></span></span></span><span data-slate-object="text" data-key="4840"><span data-slate-leaf="true" data-offset-key="4840:0" data-first-offset="true"><span data-slate-string="true">': </span></span></span><span data-slate-object="text" data-key="4841"><span data-slate-leaf="true" data-offset-key="4841:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.01</span></span></span></span><span data-slate-object="text" data-key="4842"><span data-slate-leaf="true" data-offset-key="4842:0" data-first-offset="true"><span data-slate-string="true">},</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4843"><span data-slate-object="text" data-key="4844"><span data-slate-leaf="true" data-offset-key="4844:0" data-first-offset="true"><span data-slate-string="true">            {</span></span></span><span data-slate-object="text" data-key="4845"><span data-slate-leaf="true" data-offset-key="4845:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'params</span></span></span></span><span data-slate-object="text" data-key="4846"><span data-slate-leaf="true" data-offset-key="4846:0" data-first-offset="true"><span data-slate-string="true">': [p </span></span></span><span data-slate-object="text" data-key="4847"><span data-slate-leaf="true" data-offset-key="4847:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">for</span></span></span></span><span data-slate-object="text" data-key="4848"><span data-slate-leaf="true" data-offset-key="4848:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4849"><span data-slate-leaf="true" data-offset-key="4849:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">n</span></span></span></span><span data-slate-object="text" data-key="4850"><span data-slate-leaf="true" data-offset-key="4850:0" data-first-offset="true"><span data-slate-string="true">, p </span></span></span><span data-slate-object="text" data-key="4851"><span data-slate-leaf="true" data-offset-key="4851:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4852"><span data-slate-leaf="true" data-offset-key="4852:0" data-first-offset="true"><span data-slate-string="true"> param_optimizer </span></span></span><span data-slate-object="text" data-key="4853"><span data-slate-leaf="true" data-offset-key="4853:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">if</span></span></span></span><span data-slate-object="text" data-key="4854"><span data-slate-leaf="true" data-offset-key="4854:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4855"><span data-slate-leaf="true" data-offset-key="4855:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">any</span></span></span></span><span data-slate-object="text" data-key="4856"><span data-slate-leaf="true" data-offset-key="4856:0" data-first-offset="true"><span data-slate-string="true">(nd </span></span></span><span data-slate-object="text" data-key="4857"><span data-slate-leaf="true" data-offset-key="4857:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4858"><span data-slate-leaf="true" data-offset-key="4858:0" data-first-offset="true"><span data-slate-string="true"> n </span></span></span><span data-slate-object="text" data-key="4859"><span data-slate-leaf="true" data-offset-key="4859:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">for</span></span></span></span><span data-slate-object="text" data-key="4860"><span data-slate-leaf="true" data-offset-key="4860:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4861"><span data-slate-leaf="true" data-offset-key="4861:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">nd</span></span></span></span><span data-slate-object="text" data-key="4862"><span data-slate-leaf="true" data-offset-key="4862:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4863"><span data-slate-leaf="true" data-offset-key="4863:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4864"><span data-slate-leaf="true" data-offset-key="4864:0" data-first-offset="true"><span data-slate-string="true"> no_decay)], </span></span></span><span data-slate-object="text" data-key="4865"><span data-slate-leaf="true" data-offset-key="4865:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'weight_decay</span></span></span></span><span data-slate-object="text" data-key="4866"><span data-slate-leaf="true" data-offset-key="4866:0" data-first-offset="true"><span data-slate-string="true">': </span></span></span><span data-slate-object="text" data-key="4867"><span data-slate-leaf="true" data-offset-key="4867:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0.0</span></span></span></span><span data-slate-object="text" data-key="4868"><span data-slate-leaf="true" data-offset-key="4868:0" data-first-offset="true"><span data-slate-string="true">}</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4869"><span data-slate-object="text" data-key="4870"><span data-slate-leaf="true" data-offset-key="4870:0" data-first-offset="true"><span data-slate-string="true">        ]</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4871"><span data-slate-object="text" data-key="4872"><span data-slate-leaf="true" data-offset-key="4872:0" data-first-offset="true"><span data-slate-string="true">optimizer = </span></span></span><span data-slate-object="text" data-key="4873"><span data-slate-leaf="true" data-offset-key="4873:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">AdamW</span></span></span></span><span data-slate-object="text" data-key="4874"><span data-slate-leaf="true" data-offset-key="4874:0" data-first-offset="true"><span data-slate-string="true">(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4875"><span data-slate-object="text" data-key="4876"><span data-slate-leaf="true" data-offset-key="4876:0" data-first-offset="true"><span data-slate-string="true">这部分的代码，主要是为了选择一个合适咱们模型任务的优化器，并将网络中的参数设定好学习率。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4877" id="sr-toc-13"><span data-slate-object="text" data-key="4878"><span data-slate-leaf="true" data-offset-key="4878:0" data-first-offset="true"><span data-slate-string="true">构建训练过程逻辑</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4879"><span data-slate-object="text" data-key="4880"><span data-slate-leaf="true" data-offset-key="4880:0" data-first-offset="true"><span data-slate-string="true">训练的过程逻辑是非常简单的，只需要两个 for 循环，分别代表 epoch 和 batch，然后在最内部增加</span></span></span><span data-slate-object="text" data-key="4881"><span data-slate-leaf="true" data-offset-key="4881:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">一个训练核心语句，</span></span></span></span><span data-slate-object="text" data-key="4882"><span data-slate-leaf="true" data-offset-key="4882:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">以及</span></span></span></span><span data-slate-object="text" data-key="4883"><span data-slate-leaf="true" data-offset-key="4883:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">一个梯度更新语句</span></span></span></span><span data-slate-object="text" data-key="4884"><span data-slate-leaf="true" data-offset-key="4884:0" data-first-offset="true"><span data-slate-string="true">，这就足够了。可以看到，PyTorch 在工程代码的实现上，封装得非常完善和简练。</span></span></span></div><div data-code-language="css" data-slate-type="pre" data-slate-object="block" data-key="4885"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4886"><span data-slate-object="text" data-key="4887"><span data-slate-leaf="true" data-offset-key="4887:0" data-first-offset="true"><span data-slate-string="true">for epoch in trange(</span></span></span><span data-slate-object="text" data-key="4888"><span data-slate-leaf="true" data-offset-key="4888:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4889"><span data-slate-leaf="true" data-offset-key="4889:0" data-first-offset="true"><span data-slate-string="true">, args</span></span></span><span data-slate-object="text" data-key="4890"><span data-slate-leaf="true" data-offset-key="4890:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">.num_train_epochs</span></span></span></span><span data-slate-object="text" data-key="4891"><span data-slate-leaf="true" data-offset-key="4891:0" data-first-offset="true"><span data-slate-string="true">):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4892"><span data-slate-object="text" data-key="4893"><span data-slate-leaf="true" data-offset-key="4893:0" data-first-offset="true"><span data-slate-string="true">  model.</span></span></span><span data-slate-object="text" data-key="4894"><span data-slate-leaf="true" data-offset-key="4894:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">train</span></span></span></span><span data-slate-object="text" data-key="4895"><span data-slate-leaf="true" data-offset-key="4895:0" data-first-offset="true"><span data-slate-string="true">()// 一定别忘了要把模型设置为训练状态。</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4896"><span data-slate-object="text" data-key="4897"><span data-slate-leaf="true" data-offset-key="4897:0" data-first-offset="true"><span data-slate-string="true">  for step, batch in </span></span></span><span data-slate-object="text" data-key="4898"><span data-slate-leaf="true" data-offset-key="4898:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">enumerate</span></span></span></span><span data-slate-object="text" data-key="4899"><span data-slate-leaf="true" data-offset-key="4899:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4900"><span data-slate-leaf="true" data-offset-key="4900:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">tqdm</span></span></span></span><span data-slate-object="text" data-key="4901"><span data-slate-leaf="true" data-offset-key="4901:0" data-first-offset="true"><span data-slate-string="true">(train_dataLoader, desc=</span></span></span><span data-slate-object="text" data-key="4902"><span data-slate-leaf="true" data-offset-key="4902:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'Iteration'</span></span></span></span><span data-slate-object="text" data-key="4903"><span data-slate-leaf="true" data-offset-key="4903:0" data-first-offset="true"><span data-slate-string="true">)):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4904"><span data-slate-object="text" data-key="4905"><span data-slate-leaf="true" data-offset-key="4905:0" data-first-offset="true"><span data-slate-string="true">    step_loss = </span></span></span><span data-slate-object="text" data-key="4906"><span data-slate-leaf="true" data-offset-key="4906:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">training_step</span></span></span></span><span data-slate-object="text" data-key="4907"><span data-slate-leaf="true" data-offset-key="4907:0" data-first-offset="true"><span data-slate-string="true">(batch)// 训练的核心环节</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4908"><span data-slate-object="text" data-key="4909"><span data-slate-leaf="true" data-offset-key="4909:0" data-first-offset="true"><span data-slate-string="true">    tr_loss += step_loss[</span></span></span><span data-slate-object="text" data-key="4910"><span data-slate-leaf="true" data-offset-key="4910:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4911"><span data-slate-leaf="true" data-offset-key="4911:0" data-first-offset="true"><span data-slate-string="true">]</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4912"><span data-slate-object="text" data-key="4913"><span data-slate-leaf="true" data-offset-key="4913:0" data-first-offset="true"><span data-slate-string="true">    optimizer.</span></span></span><span data-slate-object="text" data-key="4914"><span data-slate-leaf="true" data-offset-key="4914:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">step</span></span></span></span><span data-slate-object="text" data-key="4915"><span data-slate-leaf="true" data-offset-key="4915:0" data-first-offset="true"><span data-slate-string="true">()</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4916"><span data-slate-object="text" data-key="4917"><span data-slate-leaf="true" data-offset-key="4917:0" data-first-offset="true"><span data-slate-string="true">    optimizer.</span></span></span><span data-slate-object="text" data-key="4918"><span data-slate-leaf="true" data-offset-key="4918:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">zero_grad</span></span></span></span><span data-slate-object="text" data-key="4919"><span data-slate-leaf="true" data-offset-key="4919:0" data-first-offset="true"><span data-slate-string="true">()</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4920" id="sr-toc-14"><span data-slate-object="text" data-key="4921"><span data-slate-leaf="true" data-offset-key="4921:0" data-first-offset="true"><span data-slate-string="true">训练的核心环节</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4922"><span data-slate-object="text" data-key="4923"><span data-slate-leaf="true" data-offset-key="4923:0" data-first-offset="true"><span data-slate-string="true">训练的核心环节，你需要关注两个部分，分别是</span></span></span><span data-slate-object="text" data-key="4924"><span data-slate-leaf="true" data-offset-key="4924:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">通过网络得到预测输出</span></span></span></span><span data-slate-object="text" data-key="4925"><span data-slate-leaf="true" data-offset-key="4925:0" data-first-offset="true"><span data-slate-string="true">，也就是 logits，以及</span></span></span><span data-slate-object="text" data-key="4926"><span data-slate-leaf="true" data-offset-key="4926:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">基于 logits 计算得到的 loss</span></span></span></span><span data-slate-object="text" data-key="4927"><span data-slate-leaf="true" data-offset-key="4927:0" data-first-offset="true"><span data-slate-string="true">，loss 是整个模型使用梯度更新需要用到的数据。</span></span></span></div><div data-code-language="css" data-slate-type="pre" data-slate-object="block" data-key="4928"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4929"><span data-slate-object="text" data-key="4930"><span data-slate-leaf="true" data-offset-key="4930:0" data-first-offset="true"><span data-slate-string="true">def training_step(batch):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4931"><span data-slate-object="text" data-key="4932"><span data-slate-leaf="true" data-offset-key="4932:0" data-first-offset="true"><span data-slate-string="true">  input_ids, token_type_ids, attention_mask, labels = batch</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4933"><span data-slate-object="text" data-key="4934"><span data-slate-leaf="true" data-offset-key="4934:0" data-first-offset="true"><span data-slate-string="true">  input_ids = input_ids.</span></span></span><span data-slate-object="text" data-key="4935"><span data-slate-leaf="true" data-offset-key="4935:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">to</span></span></span></span><span data-slate-object="text" data-key="4936"><span data-slate-leaf="true" data-offset-key="4936:0" data-first-offset="true"><span data-slate-string="true">(device)// 将数据发送到 GPU</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4937"><span data-slate-object="text" data-key="4938"><span data-slate-leaf="true" data-offset-key="4938:0" data-first-offset="true"><span data-slate-string="true">  token_type_ids = token_type_ids.</span></span></span><span data-slate-object="text" data-key="4939"><span data-slate-leaf="true" data-offset-key="4939:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">to</span></span></span></span><span data-slate-object="text" data-key="4940"><span data-slate-leaf="true" data-offset-key="4940:0" data-first-offset="true"><span data-slate-string="true">(device)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4941"><span data-slate-object="text" data-key="4942"><span data-slate-leaf="true" data-offset-key="4942:0" data-first-offset="true"><span data-slate-string="true">  attention_mask = attention_mask.</span></span></span><span data-slate-object="text" data-key="4943"><span data-slate-leaf="true" data-offset-key="4943:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">to</span></span></span></span><span data-slate-object="text" data-key="4944"><span data-slate-leaf="true" data-offset-key="4944:0" data-first-offset="true"><span data-slate-string="true">(device)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4945"><span data-slate-object="text" data-key="4946"><span data-slate-leaf="true" data-offset-key="4946:0" data-first-offset="true"><span data-slate-string="true">  labels = labels_voc.</span></span></span><span data-slate-object="text" data-key="4947"><span data-slate-leaf="true" data-offset-key="4947:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">to</span></span></span></span><span data-slate-object="text" data-key="4948"><span data-slate-leaf="true" data-offset-key="4948:0" data-first-offset="true"><span data-slate-string="true">(device)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4949"><span data-slate-object="text" data-key="4950"><span data-slate-leaf="true" data-offset-key="4950:0" data-first-offset="true"><span data-slate-string="true">        </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4951"><span data-slate-object="text" data-key="4952"><span data-slate-leaf="true" data-offset-key="4952:0" data-first-offset="true"><span data-slate-string="true">  logits = </span></span></span><span data-slate-object="text" data-key="4953"><span data-slate-leaf="true" data-offset-key="4953:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">model</span></span></span></span><span data-slate-object="text" data-key="4954"><span data-slate-leaf="true" data-offset-key="4954:0" data-first-offset="true"><span data-slate-string="true">(input_ids,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4955"><span data-slate-object="text" data-key="4956"><span data-slate-leaf="true" data-offset-key="4956:0" data-first-offset="true"><span data-slate-string="true">        token_type_ids=token_type_ids, </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4957"><span data-slate-object="text" data-key="4958"><span data-slate-leaf="true" data-offset-key="4958:0" data-first-offset="true"><span data-slate-string="true">        attention_mask=attention_mask, </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4959"><span data-slate-object="text" data-key="4960"><span data-slate-leaf="true" data-offset-key="4960:0" data-first-offset="true"><span data-slate-string="true">        labels=labels)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4961"><span data-slate-object="text" data-key="4962"><span data-slate-leaf="true" data-offset-key="4962:0" data-first-offset="true"><span data-slate-string="true">  loss_fct = </span></span></span><span data-slate-object="text" data-key="4963"><span data-slate-leaf="true" data-offset-key="4963:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">BCEWithLogitsLoss</span></span></span></span><span data-slate-object="text" data-key="4964"><span data-slate-leaf="true" data-offset-key="4964:0" data-first-offset="true"><span data-slate-string="true">()</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4965"><span data-slate-object="text" data-key="4966"><span data-slate-leaf="true" data-offset-key="4966:0" data-first-offset="true"><span data-slate-string="true">  loss = </span></span></span><span data-slate-object="text" data-key="4967"><span data-slate-leaf="true" data-offset-key="4967:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">loss_fct</span></span></span></span><span data-slate-object="text" data-key="4968"><span data-slate-leaf="true" data-offset-key="4968:0" data-first-offset="true"><span data-slate-string="true">(logits.</span></span></span><span data-slate-object="text" data-key="4969"><span data-slate-leaf="true" data-offset-key="4969:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">view</span></span></span></span><span data-slate-object="text" data-key="4970"><span data-slate-leaf="true" data-offset-key="4970:0" data-first-offset="true"><span data-slate-string="true">(-</span></span></span><span data-slate-object="text" data-key="4971"><span data-slate-leaf="true" data-offset-key="4971:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="4972"><span data-slate-leaf="true" data-offset-key="4972:0" data-first-offset="true"><span data-slate-string="true">, num_labels_cate), labels.</span></span></span><span data-slate-object="text" data-key="4973"><span data-slate-leaf="true" data-offset-key="4973:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">view</span></span></span></span><span data-slate-object="text" data-key="4974"><span data-slate-leaf="true" data-offset-key="4974:0" data-first-offset="true"><span data-slate-string="true">(-</span></span></span><span data-slate-object="text" data-key="4975"><span data-slate-leaf="true" data-offset-key="4975:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="4976"><span data-slate-leaf="true" data-offset-key="4976:0" data-first-offset="true"><span data-slate-string="true">, num_labels_cate).</span></span></span><span data-slate-object="text" data-key="4977"><span data-slate-leaf="true" data-offset-key="4977:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">float</span></span></span></span><span data-slate-object="text" data-key="4978"><span data-slate-leaf="true" data-offset-key="4978:0" data-first-offset="true"><span data-slate-string="true">())</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4979"><span data-slate-object="text" data-key="4980"><span data-slate-leaf="true" data-offset-key="4980:0" data-first-offset="true"><span data-slate-string="true">  loss.</span></span></span><span data-slate-object="text" data-key="4981"><span data-slate-leaf="true" data-offset-key="4981:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">backward</span></span></span></span><span data-slate-object="text" data-key="4982"><span data-slate-leaf="true" data-offset-key="4982:0" data-first-offset="true"><span data-slate-string="true">()</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4983"><span data-slate-object="text" data-key="4984"><span data-slate-leaf="true" data-offset-key="4984:0" data-first-offset="true"><span data-slate-string="true">至此，咱们已经快速构建出了一个 BERT 分类器所需的所有关键代码。但是仍旧有一些小小的环节需要你来完善，比如 training_step 代码块中的 device，是怎么得到的呢？回顾一下咱们之前学习的内容，相信你一定可以做得到。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4985" id="sr-toc-15"><span data-slate-object="text" data-key="4986"><span data-slate-leaf="true" data-offset-key="4986:0" data-first-offset="true"><span data-slate-string="true">小结</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4987"><span data-slate-object="text" data-key="4988"><span data-slate-leaf="true" data-offset-key="4988:0" data-first-offset="true"><span data-slate-string="true">恭喜你完成了这节课的学习，尽管现在 GitHub 上已经有了很多已经封装得非常完善的 BERT 代码，你也可以很快实现一个最基本的 NLP 算法流程，但是我仍希望你能够抽出时间，好好看一下 Transformer 中的模型代码，这会对你的技术提升有非常大的助益。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4989"><span data-slate-object="text" data-key="4990"><span data-slate-leaf="true" data-offset-key="4990:0" data-first-offset="true"><span data-slate-string="true">这节课我们学习了如何用 PyTorch 快速构建一个基本的文本分类模型，想要实现这个过程，你需要了解 BERT 的预训练模型的获取以及转化、分类网络的设计方法、训练过程的编写。整个过程不难，但是却可以让你快速上手，了解 PyTorch 在 NLP 方面如何应用。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4991"><span data-slate-object="text" data-key="4992"><span data-slate-leaf="true" data-offset-key="4992:0" data-first-offset="true"><span data-slate-string="true">除了技术本身，业务方面的考虑我们也要注意。比如新闻文本的多语言、数据不平衡等问题，模型有时不能解决所有的问题，因此你还需要学习一些</span></span></span><span data-slate-object="text" data-key="4993"><span data-slate-leaf="true" data-offset-key="4993:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">数据预处理的技巧</span></span></span></span><span data-slate-object="text" data-key="4994"><span data-slate-leaf="true" data-offset-key="4994:0" data-first-offset="true"><span data-slate-string="true">，这包括很多技术和算法方面的内容。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4995"><span data-slate-object="text" data-key="4996"><span data-slate-leaf="true" data-offset-key="4996:0" data-first-offset="true"><span data-slate-string="true">即使我列出一份长长的学习清单，也可能会挂一漏万，所以数据预处理方面的知识我建议你重点关注以下内容：建议你需要花一些时间去学习 NumPy 和 Pandas 的使用，这样才能更加得心应手地处理数据；你还可以多学习一些常见的数据挖掘算法（比如决策树、KNN、支持向量机等）；另外，深度学习的广泛使用，其实仍旧非常需要传统机器学习算法的背后支撑，也建议你多多了解。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4997" id="sr-toc-16"><span data-slate-object="text" data-key="4998"><span data-slate-leaf="true" data-offset-key="4998:0" data-first-offset="true"><span data-slate-string="true">思考题</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4999"><span data-slate-object="text" data-key="5000"><span data-slate-leaf="true" data-offset-key="5000:0" data-first-offset="true"><span data-slate-string="true">BERT 处理文本是有最大长度要求的（512），那么遇到长文本，该怎么办呢？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="5001"><span data-slate-object="text" data-key="5002"><span data-slate-leaf="true" data-offset-key="5002:0" data-first-offset="true"><span data-slate-string="true">也欢迎你在留言区记录你的疑问或者收获，也推荐你把这节课分享给你的朋友。</span></span></span></div></div></div></div><div><div></div><div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><textarea placeholder="将学到的知识总结成笔记，方便日后快速查找及复习"></textarea></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div><div><div>确认放弃笔记？</div><div>放弃后所记笔记将不保留。</div></div><div><div>新功能上线，你的历史笔记已初始化为私密笔记，是否一键批量公开？</div><div>批量公开的笔记不会为你同步至部落</div></div><div></div></div><div><div><div>公开</div><div>同步至部落</div></div><div>取消</div><div>完成</div></div><div><span>0/2000</span></div></div><div><div><span>划线</span></div><div></div><div></div><div></div><div><span>笔记</span></div><div></div><div><span>复制</span></div></div></div><div><div><div><span></span></div><p><a href="javascript:void(0);">给文章提建议</a></p></div></div><div><span>©</span> 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 </div></div><div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div><div>Geek__653581f21177</div></div><div><textarea placeholder="由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。" rows="16"></textarea></div><div><div>Ctrl + Enter 发表</div><div>0/2000 字符</div><div>提交留言</div></div></div><div><h2 id="sr-toc-17">精选留言 (8)</h2><ul><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132"></div></div><div><div><div><span>vcjmhg</span></div></div><div>1. 截断法
截断法是非常常用办法，大致分为三种，head 截断，tail 截断，head+tail 截断。
head 截断即从文本开头直到限制的字数。
tail 截断是从结尾开始往前截断。
head+tail 截断，开头和结尾各保留一部分，比例参数是一个可以调节超参数。
缺点：处理方法较为暴力，不是太长的文本
2.Pooling 法，缺点性能较差
3. 压缩法，提取文本中有限 segment，但压缩效果可能会很有限。</div><div><p>作者回复: 👍🏻👍🏻👍🏻👍🏻^^</p></div><div><div>2021-12-09</div><div><div><i></i></div><div><i></i><span>3</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span> 亚林</span></div></div><div>我觉得这篇的主角是 huggingface</div><div><div>2022-06-07</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>亚林</span></div></div><div>预训练模型地址失效了：
https://github.com/google-research/bert/blob/master/multilingual.md</div><div><p>作者回复: hi，没有失效，可能是你的网络问题</p></div><div><div>2022-06-07</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>亚林</span></div></div><div>上一节提到的 pipelines 能否解决长文本的办法</div><div><p>作者回复: hello pipelines 不是解决长文本问题的。</p></div><div><div>2022-06-02</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>Geek_709f77</span></div></div><div>“转换完模型之后，你会发现你的本地多了三个文件” 这个转换完成模型是怎么做的？另外，老师给的链接有的打开后跟文章中内容不一样，代码下载也不对，能不能把所有代码放在一个地方，让我们下载运行？</div><div><p>作者回复：你好，感谢你的留言。
模型的转换需要 transformers 中提供的 convert_tf_checkpoint_to_pytorch.py 文件的帮忙，具体的使用方法会随着版本的更新而有所不同，但是好在用法都在该文件的 main 函数中进行了介绍。你可以看一下。
链接与文章中内容不一样的问题，我刚才看了一下 git 中的代码，他三天前更新了。
按照文章中的流程，代码基本都是可以实现的 ^^。</p></div><div><div>2022-04-15</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div></div><div><div><div><span>向坤</span></div></div><div>请问有完整的训练代码链接吗</div><div><p>作者回复：你好，向坤，感谢你的留言。
按照文章里的一步步来就是可以运行的。</p></div><div><div>2022-04-13</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/26/8a/0b/ac84669e.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>(●—●)</span></div></div><div>请问怎么转换模型？</div><div><p>作者回复：你好，不好意思，没太看明白。
转什么模型？从哪里转？</p></div><div><div>2022-03-26</div><div><div><i></i><span>3</span></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/55/b5/12c67a82.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>xiaolan</span></div></div><div>请问 bert 模型的用处是不是跟 word2vec 一样？</div><div><p>作者回复: hello，感谢留言。
他们不一样。可以一样用，但是 bert 更强大，还有别的功能。</p></div><div><div>2022-01-24</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li></ul><div> 收起评论<span></span></div></div></sr-rd-content>
                            <toc-bg><toc style="width: initial;overflow: auto!important;"class="simpread-font simpread-theme-root" data-reactid=".p"><outline class="toc-level-h1" data-reactid=".p.0" style="width: 175px;"><active data-reactid=".p.0.0" ></active><a class="toc-outline-theme-github" href="#sr-toc-0" data-reactid=".p.0.1"><span data-reactid=".p.0.1.0">24 | 文本分类：如何使用 BERT 构建文本分类模型？</span></a></outline><outline class="toc-level-h2" data-reactid=".p.1" style="width: 165px;"><active data-reactid=".p.1.0"></active><a class="toc-outline-theme-github" href="#sr-toc-1" data-reactid=".p.1.1"><span data-reactid=".p.1.1.0">问题背景与分析</span></a></outline><outline class="toc-level-h2" data-reactid=".p.2" style="width: 165px;"><active data-reactid=".p.2.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-2" data-reactid=".p.2.1"><span data-reactid=".p.2.1.0">BERT 原理与特点分析</span></a></outline><outline class="toc-level-h2" data-reactid=".p.3" style="width: 165px;"><active data-reactid=".p.3.0"></active><a class="toc-outline-theme-github" href="#sr-toc-3" data-reactid=".p.3.1"><span data-reactid=".p.3.1.0">安装与准备</span></a></outline><outline class="toc-level-h3" data-reactid=".p.4" style="width: 155px;"><active data-reactid=".p.4.0"></active><a class="toc-outline-theme-github" href="#sr-toc-4" data-reactid=".p.4.1"><span data-reactid=".p.4.1.0">环境准备</span></a></outline><outline class="toc-level-h3" data-reactid=".p.5" style="width: 155px;"><active data-reactid=".p.5.0"></active><a class="toc-outline-theme-github" href="#sr-toc-5" data-reactid=".p.5.1"><span data-reactid=".p.5.1.0">模型准备</span></a></outline><outline class="toc-level-h3" data-reactid=".p.6" style="width: 155px;"><active data-reactid=".p.6.0"></active><a class="toc-outline-theme-github" href="#sr-toc-6" data-reactid=".p.6.1"><span data-reactid=".p.6.1.0">格式准备</span></a></outline><outline class="toc-level-h2" data-reactid=".p.7" style="width: 165px;"><active data-reactid=".p.7.0"></active><a class="toc-outline-theme-github" href="#sr-toc-7" data-reactid=".p.7.1"><span data-reactid=".p.7.1.0">模型构建</span></a></outline><outline class="toc-level-h3" data-reactid=".p.8" style="width: 155px;"><active data-reactid=".p.8.0"></active><a class="toc-outline-theme-github" href="#sr-toc-8" data-reactid=".p.8.1"><span data-reactid=".p.8.1.0">网络设计</span></a></outline><outline class="toc-level-h3" data-reactid=".p.9" style="width: 155px;"><active data-reactid=".p.9.0"></active><a class="toc-outline-theme-github" href="#sr-toc-9" data-reactid=".p.9.1"><span data-reactid=".p.9.1.0">模型配置</span></a></outline><outline class="toc-level-h2" data-reactid=".p.a" style="width: 165px;"><active data-reactid=".p.a.0"></active><a class="toc-outline-theme-github" href="#sr-toc-10" data-reactid=".p.a.1"><span data-reactid=".p.a.1.0">数据准备</span></a></outline><outline class="toc-level-h2" data-reactid=".p.b" style="width: 165px;"><active data-reactid=".p.b.0"></active><a class="toc-outline-theme-github" href="#sr-toc-11" data-reactid=".p.b.1"><span data-reactid=".p.b.1.0">模型训练</span></a></outline><outline class="toc-level-h3" data-reactid=".p.c" style="width: 155px;"><active data-reactid=".p.c.0"></active><a class="toc-outline-theme-github" href="#sr-toc-12" data-reactid=".p.c.1"><span data-reactid=".p.c.1.0">选择优化器</span></a></outline><outline class="toc-level-h3" data-reactid=".p.d" style="width: 155px;"><active data-reactid=".p.d.0"></active><a class="toc-outline-theme-github" href="#sr-toc-13" data-reactid=".p.d.1"><span data-reactid=".p.d.1.0">构建训练过程逻辑</span></a></outline><outline class="toc-level-h3" data-reactid=".p.e" style="width: 155px;"><active data-reactid=".p.e.0"></active><a class="toc-outline-theme-github" href="#sr-toc-14" data-reactid=".p.e.1"><span data-reactid=".p.e.1.0">训练的核心环节</span></a></outline><outline class="toc-level-h2" data-reactid=".p.f" style="width: 165px;"><active data-reactid=".p.f.0"></active><a class="toc-outline-theme-github" href="#sr-toc-15" data-reactid=".p.f.1"><span data-reactid=".p.f.1.0">小结</span></a></outline><outline class="toc-level-h2" data-reactid=".p.g" style="width: 165px;"><active data-reactid=".p.g.0"></active><a class="toc-outline-theme-github" href="#sr-toc-16" data-reactid=".p.g.1"><span data-reactid=".p.g.1.0">思考题</span></a></outline><outline class="toc-level-h2" data-reactid=".p.h" style="width: 165px;"><active data-reactid=".p.h.0"></active><a class="toc-outline-theme-github" href="#sr-toc-17" data-reactid=".p.h.1"><span data-reactid=".p.h.1.0">精选留言 (8)</span></a></outline></toc></toc-bg>
                            <sr-rd-footer>
                                <sr-rd-footer-group>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                </sr-rd-footer-group>
                                <sr-rd-footer-copywrite>
                                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://time.geekbang.org/column/article/464152" target="_blank">原文地址 </a></div>
                                </sr-rd-footer-copywrite>
                            </sr-rd-footer>
                        </sr-read>
                    </body>
                </html>