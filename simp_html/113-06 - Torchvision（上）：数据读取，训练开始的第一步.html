
                <html lang="en" class="simpread-font simpread-theme-root" style=''>
                    <head>
                        <meta charset="utf-8">
                        <meta http-equiv="content-type" content="text/html; charset=UTF-8;charset=utf-8">
                        <meta http-equiv="X-UA-Compatible" content="IE=Edge">
                        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=1">
                        <meta name="author" content="Kenshin"/>
                        <meta name="description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展" />
                        <meta name="keywords" content="Chrome extension, Chrome 扩展, 阅读模式, 沉浸式阅读, 简悦, 简阅, read mode, reading mode, reader view, firefox, firefox addon, userscript, safari, opera, tampermonkey"/>
                        <meta name="thumbnail" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:title" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <meta property="og:type" content="website">
                        <meta property="og:local" content="zh_CN"/>
                        <meta property="og:url" content="http://ksria.com/simpread"/>
                        <meta property="og:image" content="https://simpread-1254315611.cos.ap-shanghai.myqcloud.com/static/introduce-2.png"/>
                        <meta property="og:image:type" content="image/png"/>
                        <meta property="og:image:width" content="960"/>
                        <meta property="og:image:height" content="355"/>
                        <meta property="og:site_name" content="http://ksria.com/simpread"/>
                        <meta property="og:description" content="简悦 SimpRead - 如杂志般沉浸式阅读体验的扩展"/>
                        <style type="text/css">.simpread-font{font:300 16px/1.8 -apple-system,PingFang SC,Microsoft Yahei,Lantinghei SC,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#333;text-rendering:optimizelegibility;-webkit-text-size-adjust:100%;-webkit-font-smoothing:antialiased}.simpread-hidden{display:none}.simpread-read-root{display:-webkit-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;margin:0;top:-1000px;left:0;width:100%;z-index:2147483646;overflow-x:hidden;opacity:0;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}.simpread-read-root-show{top:0}.simpread-read-root-hide{top:1000px}sr-read{display:-webkit-flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-flow:column nowrap;flex-flow:column;margin:20px 20%;min-width:400px;min-height:400px;text-align:center}read-process{position:fixed;top:0;left:0;height:3px;width:100%;background-color:#64b5f6;-webkit-transition:width 2s;transition:width 2s;z-index:20000}sr-rd-content-error{display:block;position:relative;margin:0;margin-bottom:30px;padding:25px;background-color:rgba(0,0,0,.05)}sr-rd-footer{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column;font-size:14px}sr-rd-footer,sr-rd-footer-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}sr-rd-footer-group{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-rd-footer-line{width:100%;border-top:1px solid #e0e0e0}sr-rd-footer-text{min-width:150px}sr-rd-footer-copywrite{margin:10px 0 0;color:inherit}sr-rd-footer-copywrite abbr{-webkit-font-feature-settings:normal;font-feature-settings:normal;font-variant:normal;text-decoration:none}sr-rd-footer-copywrite .second{margin:10px 0}sr-rd-footer-copywrite .third a:hover{border:none!important}sr-rd-footer-copywrite .third a:first-child{margin-right:50px}sr-rd-footer-copywrite .sr-icon{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:33px;height:33px;opacity:.8;-webkit-transition:opacity .5s ease;transition:opacity .5s ease;cursor:pointer}sr-rd-footer-copywrite .sr-icon:hover{opacity:1}sr-rd-footer-copywrite a,sr-rd-footer-copywrite a:link,sr-rd-footer-copywrite a:visited{margin:0;padding:0;color:inherit;background-color:transparent;font-size:inherit!important;line-height:normal;text-decoration:none;vertical-align:baseline;vertical-align:initial;border:none!important;box-sizing:border-box}sr-rd-footer-copywrite a:focus,sr-rd-footer-copywrite a:hover,sr-rd-footer a:active{color:inherit;text-decoration:none;border-bottom:1px dotted!important}.simpread-blocks{text-decoration:none!important}.simpread-blocks *{margin:0}.simpread-blocks a{padding:0;text-decoration:none!important}.simpread-blocks img{margin:0;padding:0;border:0;background:transparent;box-shadow:none}.simpread-focus-root{display:block;position:fixed;top:0;left:0;right:0;bottom:0;background-color:hsla(0,0%,92%,.9);z-index:2147483645;opacity:0;-webkit-transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms;transition:opacity 1s cubic-bezier(.23,1,.32,1) 0ms}.simpread-focus-highlight{position:relative;box-shadow:0 0 0 20px #fff;background-color:#fff;overflow:visible;z-index:2147483646}.sr-controlbar-bg sr-rd-crlbar,.sr-controlbar-bg sr-rd-crlbar fab{z-index:2147483647}sr-rd-crlbar.controlbar{position:fixed;right:0;bottom:0;width:100px;height:100%;opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}sr-rd-crlbar.controlbar:hover{opacity:1}sr-rd-crlbar fap *{box-sizing:border-box}@media (max-height:620px){fab{zoom:.8}}@media (max-height:783px){dialog-gp dialog-content{max-height:580px}dialog-gp dialog-footer{border-top:1px solid #e0e0e0}}.simpread-highlight-selector{outline:3px dashed #1976d2!important;cursor:pointer!important}.simpread-highlight-controlbar,.simpread-highlight-selector{background-color:#fafafa!important;opacity:.8!important;-webkit-transition:opacity .5s ease!important;transition:opacity .5s ease!important}.simpread-highlight-controlbar{position:relative!important;border:3px dashed #1976d2!important}simpread-highlight,sr-snapshot-ctlbar{position:fixed;top:0;left:0;right:0;padding:15px;height:50px;background-color:rgba(50,50,50,.9);box-shadow:0 2px 5px rgba(0,0,0,.26);box-sizing:border-box;z-index:2147483640}simpread-highlight,sr-highlight-ctl,sr-snapshot-ctlbar{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sr-highlight-ctl{margin:0 5px;width:50px;height:20px;color:#fff;background-color:#1976d2;border-radius:4px;box-shadow:0 3px 1px -2px rgba(0,0,0,.2),0 2px 2px 0 rgba(0,0,0,.14),0 1px 5px 0 rgba(0,0,0,.12);cursor:pointer}toc-bg{position:fixed;left:0;top:0;width:50px;height:200px;font-size:medium}toc-bg:hover{z-index:3}.toc-bg-hidden{opacity:0;-webkit-transition:opacity .5s ease;transition:opacity .5s ease}.toc-bg-hidden:hover{opacity:1;z-index:3}.toc-bg-hidden:hover toc{width:180px}toc *{all:unset}toc{position:fixed;left:0;top:100px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;padding:10px;width:0;max-width:200px;max-height:500px;overflow-x:hidden;overflow-y:hidden;cursor:pointer;border:1px solid hsla(0,0%,62%,.22);-webkit-transition:width .5s;transition:width .5s}toc:hover{overflow-y:auto}toc.mini:hover{width:200px!important}toc::-webkit-scrollbar{width:3px}toc::-webkit-scrollbar-thumb{border-radius:10px;background-color:hsla(36,2%,54%,.5)}toc outline{position:relative;display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;overflow:hidden;text-overflow:ellipsis;padding:2px 0;min-height:21px;line-height:21px;text-align:left}toc outline a,toc outline a:active,toc outline a:focus,toc outline a:visited{display:block;width:100%;color:inherit;font-size:11px;text-decoration:none!important;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}toc outline a:hover{font-weight:700!important}toc outline a.toc-outline-theme-dark,toc outline a.toc-outline-theme-night{color:#fff!important}.toc-level-h1{padding-left:5px}.toc-level-h2{padding-left:15px}.toc-level-h3{padding-left:25px}.toc-level-h4{padding-left:35px}.toc-outline-active{border-left:2px solid #f44336}toc outline active{position:absolute;left:0;top:0;bottom:0;padding:0 0 0 3px;border-left:2px solid #e8e8e8}sr-kbd{background:-webkit-gradient(linear,0 0,0 100%,from(#fff785),to(#ffc542));border:1px solid #e3be23;-o-border-image:none;border-image:none;-o-border-image:initial;border-image:initial;position:absolute;left:0;padding:1px 3px 0;font-size:11px!important;font-weight:700;box-shadow:0 3px 7px 0 rgba(0,0,0,.3);overflow:hidden;border-radius:3px}.sr-kbd-a{position:relative}kbd-mapping{position:fixed;left:5px;bottom:5px;-ms-flex-flow:row;flex-flow:row;width:250px;height:500px;background-color:#fff;border:1px solid hsla(0,0%,62%,.22);box-shadow:0 2px 5px rgba(0,0,0,.26);border-radius:3px}kbd-mapping,kbd-maps{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}kbd-maps{margin:40px 0 20px;width:100%;overflow-x:auto}kbd-maps::-webkit-scrollbar-thumb{background-clip:padding-box;border-radius:10px;border:2px solid transparent;background-color:rgba(85,85,85,.55)}kbd-maps::-webkit-scrollbar{width:10px;-webkit-transition:width .7s cubic-bezier(.4,0,.2,1);transition:width .7s cubic-bezier(.4,0,.2,1)}kbd-mapping kbd-map-title{position:absolute;margin:5px 0;width:100%;font-size:14px;font-weight:700}kbd-maps-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}kbd-maps-title{margin:5px 0;padding-left:53px;font-size:12px;font-weight:700}kbd-map kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#444d56;vertical-align:middle;background-color:#fafbfc;border:1px solid #c6cbd1;border-bottom-color:#959da5;border-radius:3px;box-shadow:inset 0 -1px 0 #959da5}kbd-map kbd-name{display:inline-block;text-align:right;width:50px}kbd-map kbd-desc{padding-left:3px}sharecard-bg{position:fixed;top:0;left:0;width:100%;height:100%;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(0,0,0,.4);z-index:2147483647}sharecard{max-width:450px;background-color:#64b5f6}sharecard,sharecard-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-head{margin:25px;color:#fff;border-radius:10px;box-shadow:0 2px 6px 0 rgba(0,0,0,.2),0 25px 50px 0 rgba(0,0,0,.15)}sharecard-card{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sharecard-card,sharecard-top{display:-webkit-box;display:-ms-flexbox;display:flex}sharecard-top{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:65px;background-color:#fff;color:#878787;font-size:25px;font-weight:500;border-top-left-radius:10px;border-top-right-radius:10px}sharecard-top span.logos{display:block;width:48px;height:48px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAMAAABg3Am1AAABU1BMVEUAAAAnNJMnNZI3Q5onNJInNJMnNJInNJMnNJI8SJ0tOZY/S55EUKAoNJI6RpwoNJNIU6InNJInNJImNJI7SJwmNJJ2fLUiMJFKVaNCTJ9faK1HUaJOWKVSXaUnNJNYY6pye7cmM5JXYKhwebMjMI8mL4719fW9vb0oNZP/UlLz8/QqN5TAwMAnNJPv7+/Pz8/q6+/p6enNzc3Kysry8vMsOJXc3env7/LU1uXo29vR0dHOzs7ExMTwjo73bW37XV3Aj1TCYELl5u3n5+fW2Obn6O7f4OrZ2+g0QJkxPpgvO5bh4uvS1OTP0ePCwsJQW6ZLVqTs7fHd3d3V1dXqv79VX6lET6A1TIxXUIBSgHxWQnpelHf+WVnopkXqbC7j5Ozi4uLDw8NGUaFATJ9SgH3r6+vGyd7BxNva2trX19ejqM2gpczHx8dze7Zha67Z2dlTgH1aXQeSAAAAJnRSTlMA6ff+497Y8NL+/fv49P379sqab/BeOiX06tzVy8m/tKqpalA7G6oKj0EAAAJlSURBVEjHndNXWxpBFIDhcS2ICRLAkt4Dx4WhLk0E6R0MYoIISrWX5P9f5cwSIRC2+T1czMV5n2FnZwn2eWONUqCAv3H2Uf5Ra1hx4+0WEXtDQW0fCPYJ1EffEfIV4CSROAE4jsePoTFsNmTJF/IeIHF2lgCIn57GodlqDWXBK7IwBYatVlMWFAildPKX7I3m74Z9fsCiQChoimoFQAz04Ad2gH1n9fv9n9hgMNDr9euLWD6fLxQKxaLfb7dTSlahbFVdEPwIQtrAihZQgyKCtCagbQe3xh0QFMgy5MR11+ewYY5/qlZ7vT2xu93ULKjbFLpiUxnIIwjgKmVTLDUFXMrAi2NJWCRLIthTBo4xyOLKpwyqU6CuDCI41hFBCVdOhyLw4FgJ1skCAiyl9BSHbCorgo6VJXTru5hrVCQS8Yr5xLzX59YJSFpVFwD9U0BGC3hGdFpATgRupTGe9R9I1b1ePBvXKDyvq/O/44LT4/E4BUbSCAwj8Evq6HlnOBprx6JhJz8Gktc7xeaP9ndY+0coQvCccFBD4JW60UIY50ciLOAODAQRVOeCHm4Q3Xks6uRDY+CQ+AR4T2wMYh6+jMCIQOp78CFoj0H7EQgIuhI3dGaHCrwgADwCPjJvA372GRigCJg49FUdk3D87pq3zp4SA5zc1Zh9DxfwkpjgUg5Mv+lbeE3McC8Lpu7SA3wk2xzcqL2tN5DfIsQC8HB7UamUy6FQOpTO5QKBQDZbKnWSyUzGjdWCwaDA8+7Le4BNgm3qQGWchYh9s5hNq6wVbBlbwhZYOp3OYOA4zmgEypnM2zj8ByIdedKrH8vDAAAAAElFTkSuQmCC");zoom:.8}sharecard-content{padding:15px;max-height:500px;font-size:20px;text-align:justify;background-color:#2196f3;overflow-x:hidden;overflow-y:auto}sharecard-via{padding:10px;font-size:10px;background-color:#2196f3}sharecard-footer{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding-right:5px;height:100px;background-color:#fff;color:#878787;font-size:15px;font-weight:500;border-bottom-left-radius:10px;border-bottom-right-radius:10px}sharecard-footer,sharecard-footer div{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}sharecard-footer span.qrcode{display:block;width:100px;height:100px;margin:5px;background-repeat:no-repeat;background-position:50%;background-image:url("data:image/png;base64,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")}sharecard-control{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:0 19px;height:80px;background-color:#fff}simpread-snapshot{width:100%;height:100%;cursor:move;z-index:2147483645}simpread-snapshot,sr-mask{position:fixed;left:0;top:0}sr-mask{background-color:rgba(0,0,0,.1)}.simpread-feedback,.simpread-urlscheme{position:fixed;right:20px;bottom:20px;z-index:2147483646}simpread-feedback,simpread-urlscheme{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;padding:20px 20px 0;width:500px;color:rgba(51,51,51,.87);background-color:#fff;border-radius:3px;box-shadow:0 0 2px rgba(0,0,0,.12),0 2px 2px rgba(0,0,0,.26);overflow:hidden;-webkit-transform-origin:bottom;transform-origin:bottom;-webkit-transition:all .6s ease;transition:all .6s ease}simpread-feedback *,simpread-urlscheme *{font-size:12px!important;box-sizing:border-box}simpread-feedback.active,simpread-urlscheme.active{-webkit-animation-name:srFadeInUp;animation-name:srFadeInUp;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback.hide,simpread-urlscheme.hide{-webkit-animation-name:srFadeInDown;animation-name:srFadeInDown;-webkit-animation-duration:.45s;animation-duration:.45s;-webkit-animation-fill-mode:both;animation-fill-mode:both}simpread-feedback sr-fb-label,simpread-urlscheme sr-urls-label{width:100%}simpread-feedback sr-fb-head,simpread-urlscheme sr-urls-head{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin-bottom:5px;width:100%}simpread-feedback sr-fb-content,simpread-urlscheme sr-urls-content{margin-bottom:5px;width:100%}simpread-feedback sr-urls-footer,simpread-urlscheme sr-urls-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-fb-a,simpread-urlscheme sr-urls-a{color:#2163f7;cursor:pointer}simpread-feedback text-field-state,simpread-urlscheme text-field-state{border-top:none rgba(34,101,247,.8)!important;border-left:none rgba(34,101,247,.8)!important;border-right:none rgba(34,101,247,.8)!important;border-bottom:2px solid rgba(34,101,247,.8)!important}simpread-feedback switch,simpread-urlscheme switch{margin-top:0!important}@-webkit-keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@keyframes srFadeInUp{0%{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}to{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}}@-webkit-keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}@keyframes srFadeInDown{0%{opacity:1;-webkit-transform:translateY(0);transform:translateY(0)}to{opacity:0;-webkit-transform:translateY(100px);transform:translateY(100px)}}simpread-feedback sr-fb-head{font-weight:700}simpread-feedback sr-fb-content{-webkit-box-orient:vertical;-ms-flex-direction:column;flex-direction:column}simpread-feedback sr-fb-content,simpread-feedback sr-fb-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-direction:normal}simpread-feedback sr-fb-footer{-webkit-box-orient:horizontal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;width:100%}simpread-feedback sr-close{position:absolute;right:20px;cursor:pointer;-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s;z-index:200}simpread-feedback sr-close:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin-top:10px}simpread-feedback sr-stars i{margin-right:10px;cursor:pointer}simpread-feedback sr-stars i svg{-webkit-transition:all 1s cubic-bezier(.23,1,.32,1) .1s;transition:all 1s cubic-bezier(.23,1,.32,1) .1s}simpread-feedback sr-stars i svg:hover{-webkit-transform:rotate(-15deg) scale(1.3);transform:rotate(-15deg) scale(1.3)}simpread-feedback sr-stars i.active svg{-webkit-transform:rotate(0) scale(1);transform:rotate(0) scale(1)}simpread-feedback sr-emojis{display:block;height:100px;overflow:hidden}simpread-feedback sr-emoji{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-transition:.3s;transition:.3s}simpread-feedback sr-emoji>svg{margin:15px 0;width:70px;height:70px;-ms-flex-negative:0;flex-shrink:0}simpread-feedback sr-stars-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;margin:10px 0 20px}</style>
                        <style type="text/css">.simpread-theme-root{font-size:62.5%!important}sr-rd-content,sr-rd-desc,sr-rd-title{width:100%}sr-rd-title{display:-webkit-box;margin:1em 0 .5em;overflow:hidden;text-overflow:ellipsis;text-rendering:optimizelegibility;-webkit-line-clamp:3;-webkit-box-orient:vertical}sr-rd-content{text-align:left;word-break:break-word}sr-rd-desc{text-align:justify;line-height:2.4;margin:0 0 1.2em;box-sizing:border-box}sr-rd-content{font-size:25.6px;font-size:1.6rem;line-height:1.6}sr-rd-content h1,sr-rd-content h1 *,sr-rd-content h2,sr-rd-content h2 *,sr-rd-content h3,sr-rd-content h3 *,sr-rd-content h4,sr-rd-content h4 *,sr-rd-content h5,sr-rd-content h5 *,sr-rd-content h6,sr-rd-content h6 *{word-break:break-all}sr-rd-content div,sr-rd-content p{display:block;float:inherit;line-height:1.6;font-size:25.6px;font-size:1.6rem}sr-rd-content div,sr-rd-content p,sr-rd-content pre,sr-rd-content sr-blockquote{margin:0 0 1.2em;word-break:break-word}sr-rd-content a{padding:0 5px;vertical-align:baseline;vertical-align:initial}sr-rd-content a,sr-rd-content a:link{color:inherit;font-size:inherit;font-weight:inherit;border:none}sr-rd-content a:hover{background:transparent}sr-rd-content img{margin:10px;padding:5px;max-width:100%;background:#fff;border:1px solid #bbb;box-shadow:1px 1px 3px #d4d4d4}sr-rd-content figcaption{text-align:center;font-size:14px}sr-rd-content sr-blockquote{display:block;position:relative;padding:15px 25px;text-align:left;line-height:inherit}sr-rd-content sr-blockquote:before{position:absolute}sr-rd-content sr-blockquote *{margin:0;font-size:inherit}sr-rd-content table{width:100%;margin:0 0 1.2em;word-break:keep-all;word-break:normal;overflow:auto;border:none}sr-rd-content table td,sr-rd-content table th{border:none}sr-rd-content ul{margin:0 0 1.2em;margin-left:1.3em;padding:0;list-style:disc}sr-rd-content ol{list-style:decimal;margin:0;padding:0}sr-rd-content ol li,sr-rd-content ul li{font-size:inherit;list-style:disc;margin:0 0 1.2em}sr-rd-content ol li{list-style:decimal;margin-left:1.3em}sr-rd-content ol li *,sr-rd-content ul li *{margin:0;text-align:left;text-align:initial}sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em}sr-rd-content li ul{list-style:circle}sr-rd-content pre{font-family:Consolas,Monaco,Andale Mono,Source Code Pro,Liberation Mono,Courier,monospace;display:block;padding:15px;line-height:1.5;word-break:break-all;word-wrap:break-word;white-space:pre;overflow:auto}sr-rd-content pre,sr-rd-content pre *,sr-rd-content pre div{font-size:17.6px;font-size:1.1rem}sr-rd-content li pre code,sr-rd-content p pre code,sr-rd-content pre{background-color:transparent;border:none}sr-rd-content pre code{margin:0;padding:0}sr-rd-content pre code,sr-rd-content pre code *{font-size:17.6px;font-size:1.1rem}sr-rd-content pre p{margin:0;padding:0;color:inherit;font-size:inherit;line-height:inherit}sr-rd-content li code,sr-rd-content p code{margin:0 4px;padding:2px 4px;font-size:17.6px;font-size:1.1rem}sr-rd-content mark{margin:0 5px;padding:2px;background:#fffdd1;border-bottom:1px solid #ffedce}.sr-rd-content-img{width:90%;height:auto}.sr-rd-content-img-load{width:48px;height:48px;margin:0;padding:0;border-style:none;border-width:0;background-repeat:no-repeat;background-image:url(data:image/gif;base64,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)}.sr-rd-content-center{text-align:center;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;-webkit-box-orient:vertical}.sr-rd-content-center-small{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.sr-rd-content-center-small img{margin:0;padding:0;border:0;box-shadow:none}img.simpread-img-broken{cursor:pointer}.sr-rd-content-nobeautify{margin:0;padding:0;border:0;box-shadow:0 0 0}sr-rd-mult{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;margin:0 0 16px;padding:16px 0 24px;width:100%;background-color:#fff;border-radius:4px;box-shadow:0 1px 2px 0 rgba(60,64,67,.3),0 2px 6px 2px rgba(60,64,67,.15)}sr-rd-mult:hover{-webkit-transition:all .45s 0ms;transition:all .45s 0ms;box-shadow:1px 1px 8px rgba(0,0,0,.16)}sr-rd-mult sr-rd-mult-content{padding:0 16px;overflow:auto}sr-rd-mult sr-rd-mult-avatar,sr-rd-mult sr-rd-mult-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}sr-rd-mult sr-rd-mult-avatar{-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 15px}sr-rd-mult sr-rd-mult-avatar span{display:-webkit-box;-webkit-line-clamp:1;-webkit-box-orient:vertical;max-width:75px;overflow:hidden;text-overflow:ellipsis;text-align:left;font-size:16px;font-size:1rem}sr-rd-mult sr-rd-mult-avatar img{margin-bottom:0;max-width:50px;max-height:50px;width:50px;height:50px;border-radius:50%}sr-rd-mult sr-rd-mult-content img{max-width:80%}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center{margin:0}sr-page{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;width:100%}</style>
                        <style type="text/css">sr-rd-theme-github{display:none}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{position:relative;margin-top:1em;margin-bottom:1pc;font-weight:700;line-height:1.4;text-align:left;color:#363636}sr-rd-content h1{padding-bottom:.3em;font-size:57.6px;font-size:3.6rem;line-height:1.2}sr-rd-content h2{padding-bottom:.3em;font-size:44.8px;font-size:2.8rem;line-height:1.225}sr-rd-content h3{font-size:38.4px;font-size:2.4rem;line-height:1.43}sr-rd-content h4{font-size:32px;font-size:2rem}sr-rd-content h5,sr-rd-content h6{font-size:25.6px;font-size:1.6rem}sr-rd-content h6{color:#777}sr-rd-content ol,sr-rd-content ul{list-style-type:disc;padding:0;padding-left:2em}sr-rd-content ol ol,sr-rd-content ul ol{list-style-type:lower-roman}sr-rd-content ol ol ol,sr-rd-content ol ul ol,sr-rd-content ul ol ol,sr-rd-content ul ul ol{list-style-type:lower-alpha}sr-rd-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all}sr-rd-content table th{font-weight:700}sr-rd-content table td,sr-rd-content table th{padding:6px 13px;border:1px solid #ddd}sr-rd-content table tr{background-color:#fff;border-top:1px solid #ccc}sr-rd-content table tr:nth-child(2n){background-color:#f8f8f8}sr-rd-content sr-blockquote{border-left:4px solid #ddd}.simpread-theme-root{background-color:#fff;color:#333}sr-rd-title{font-family:PT Sans,SF UI Display,\.PingFang SC,PingFang SC,Neue Haas Grotesk Text Pro,Arial Nova,Segoe UI,Microsoft YaHei,Microsoft JhengHei,Helvetica Neue,Source Han Sans SC,Noto Sans CJK SC,Source Han Sans CN,Noto Sans SC,Source Han Sans TC,Noto Sans CJK TC,Hiragino Sans GB,sans-serif;font-size:54.4px;font-size:3.4rem;font-weight:700;line-height:1.3}sr-rd-desc{position:relative;margin:0;margin-bottom:30px;padding:25px;padding-left:56px;font-size:28.8px;font-size:1.8rem;color:#777;background-color:rgba(0,0,0,.05);box-sizing:border-box}sr-rd-desc:before{content:"\201C";position:absolute;top:-28px;left:16px;font-size:80px;font-family:Arial;color:rgba(0,0,0,.15)}sr-rd-content,sr-rd-content *,sr-rd-content div,sr-rd-content p{color:#363636;font-weight:400;line-height:1.8}sr-rd-content b *,sr-rd-content strong,sr-rd-content strong * sr-rd-content b{-webkit-animation:none 0s ease 0s 1 normal none running;animation:none 0s ease 0s 1 normal none running;-webkit-backface-visibility:visible;backface-visibility:visible;background:transparent none repeat 0 0/auto auto padding-box border-box scroll;border:medium none currentColor;border-collapse:separate;-o-border-image:none;border-image:none;border-radius:0;border-spacing:0;bottom:auto;box-shadow:none;box-sizing:content-box;caption-side:top;clear:none;clip:auto;color:#000;-webkit-columns:auto;-moz-columns:auto;columns:auto;-webkit-column-count:auto;-moz-column-count:auto;column-count:auto;-webkit-column-fill:balance;-moz-column-fill:balance;column-fill:balance;-webkit-column-gap:normal;-moz-column-gap:normal;column-gap:normal;-webkit-column-rule:medium none currentColor;-moz-column-rule:medium none currentColor;column-rule:medium none currentColor;-webkit-column-span:1;-moz-column-span:1;column-span:1;-webkit-column-width:auto;-moz-column-width:auto;column-width:auto;content:normal;counter-increment:none;counter-reset:none;cursor:auto;direction:ltr;display:inline;empty-cells:show;float:none;font-family:serif;font-size:medium;font-style:normal;font-variant:normal;font-weight:400;font-stretch:normal;line-height:normal;height:auto;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;left:auto;letter-spacing:normal;list-style:disc outside none;margin:0;max-height:none;max-width:none;min-height:0;min-width:0;opacity:1;orphans:2;outline:medium none invert;overflow:visible;overflow-x:visible;overflow-y:visible;padding:0;page-break-after:auto;page-break-before:auto;page-break-inside:auto;-webkit-perspective:none;perspective:none;-webkit-perspective-origin:50% 50%;perspective-origin:50% 50%;position:static;right:auto;-moz-tab-size:8;-o-tab-size:8;tab-size:8;table-layout:auto;text-align:left;text-align-last:auto;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;top:auto;-webkit-transform:none;transform:none;-webkit-transform-origin:50% 50% 0;transform-origin:50% 50% 0;-webkit-transform-style:flat;transform-style:flat;-webkit-transition:none 0s ease 0s;transition:none 0s ease 0s;unicode-bidi:normal;vertical-align:baseline;visibility:visible;white-space:normal;widows:2;width:auto;word-spacing:normal;z-index:auto;all:initial}sr-rd-content a,sr-rd-content a:link{color:#4183c4;text-decoration:none}sr-rd-content a:active,sr-rd-content a:focus,sr-rd-content a:hover{color:#4183c4;text-decoration:underline}sr-rd-content pre{background-color:#f7f7f7;border-radius:3px}sr-rd-content li code,sr-rd-content p code{background-color:rgba(0,0,0,.04);border-radius:3px}.simpread-multi-root{background:#f8f9fa}</style>
                        <style type="text/css"></style>
                        <style type="text/css">@media (pointer:coarse){sr-read{margin:20px 5%!important;min-width:0!important;max-width:90%!important}sr-rd-title{margin-top:0;font-size:2.7rem}sr-rd-content sr-blockquote,sr-rd-desc{margin:10 0!important;padding:0 0 0 10px!important;width:90%;font-size:1.8rem;font-style:normal;line-height:1.7;text-align:justify}sr-rd-content{font-size:1.75rem;font-weight:300}sr-rd-content figure{margin:0;padding:0;text-align:center}sr-rd-content a,sr-rd-content a:link,sr-rd-content li code,sr-rd-content p code{font-size:inherit}sr-rd-footer{margin-top:20px}sr-blockquote,sr-blockquote *{margin:5px!important;padding:5px!important}sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6,sr-rd-title{font-family:PingFang SC,Verdana,Helvetica Neue,Microsoft Yahei,Hiragino Sans GB,Microsoft Sans Serif,WenQuanYi Micro Hei,sans-serif;color:#000;font-weight:100;line-height:1.35}sr-rd-content-h1,sr-rd-content-h2,sr-rd-content-h3,sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h1,sr-rd-content h2,sr-rd-content h3,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{margin-top:1.2em;margin-bottom:.6em;line-height:1.35}sr-rd-content-h1,sr-rd-content h1{font-size:1.8em}sr-rd-content-h2,sr-rd-content h2{font-size:1.6em}sr-rd-content-h3,sr-rd-content h3{font-size:1.4em}sr-rd-content-h4,sr-rd-content-h5,sr-rd-content-h6,sr-rd-content h4,sr-rd-content h5,sr-rd-content h6{font-size:1.2em}sr-rd-content-ul,sr-rd-content ul{margin-left:1.3em!important;list-style:disc}sr-rd-content-ol,sr-rd-content ol{list-style:decimal;margin-left:1.9em!important}sr-rd-content-ol ol,sr-rd-content-ol ul,sr-rd-content-ul ol,sr-rd-content-ul ul,sr-rd-content li ol,sr-rd-content li ul{margin-bottom:.8em;margin-left:2em!important}sr-rd-content img{margin:0;padding:0;border:0;max-width:100%!important;height:auto;box-shadow:0 20px 20px -10px rgba(0,0,0,.1)}sr-rd-mult{min-width:0;background-color:#fff;box-shadow:0 1px 6px rgba(32,33,36,.28);border-radius:8px}sr-rd-mult sr-rd-mult-avatar div{margin:0}sr-rd-mult sr-rd-mult-avatar .sr-rd-content-center-small{margin:7px 0!important}sr-rd-mult sr-rd-mult-avatar span{display:block}sr-rd-mult sr-rd-mult-content{padding-left:0}@media only screen and (max-device-width:1024px){.simpread-theme-root,html.simpread-theme-root{font-size:80%!important}sr-rd-mult sr-rd-mult-avatar img{width:50px;height:50px;min-width:50px;min-height:50px}toc-bg toc{width:10px!important}toc-bg:hover toc{width:auto!important}}@media only screen and (max-device-width:414px){.simpread-theme-root,html.simpread-theme-root{font-size:70%!important}sr-rd-mult sr-rd-mult-avatar img{width:30px;height:30px;min-width:30px;min-height:30px}}@media only screen and (max-device-width:320px){.simpread-theme-root,html.simpread-theme-root{font-size:90%!important}sr-rd-content p{margin-bottom:.5em}}}</style>
                        <style type="text/css">undefinedsr-rd-content *, sr-rd-content p, sr-rd-content div {}sr-rd-content pre code, sr-rd-content pre code * {}sr-rd-desc {}sr-rd-content pre {}sr-rd-title {}</style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css"></style>
                        <style type="text/css">sr-rd-content *, sr-rd-content p, sr-rd-content div {
        font-size: 15px;
    }

    .annote-perview, .annote-perview * {
        color: rgb(85, 85, 85);
        font-weight: 400;
        line-height: 1.8;
    }</style>
                        
                        
                        <script>setTimeout(()=>{const e=location.hash.replace("#id=","");let t,a=!1;const n=t=>{for(let n of t){let t;if((t=e.length>6?n.getAttribute("data-id"):n.getAttribute("data-idx"))==e){n.scrollIntoView({behavior:"smooth",block:"start",inline:"nearest"}),a=!0;break}}};e&&(0==(t=document.getElementsByClassName("sr-unread-card")).length&&(t=document.getElementsByTagName("sr-annote")),n(t),a||n(t=document.getElementsByClassName("sr-annote")))},500);</script>
                        <script>document.addEventListener("DOMContentLoaded",function(){if("localhost"==location.hostname){const t=document.getElementsByTagName("img");for(let o of t){const t=o.src;t.startsWith("http")&&(o.src=location.origin+"/proxy?url="+t)}}},!1);</script>
                        <style>toc a {font-size: inherit!important;font-weight: 300!important;}</style><script>setTimeout(()=>{const max=document.getElementsByTagName('sr-annote-note-tip').length;for(let i=0;i<max;i++){const target=document.getElementsByTagName('sr-annote-note-tip')[i],value=target.dataset.value;value&&(target.innerText=value)}},1000);</script><title>简悦 | 06 | Torchvision（上）：数据读取，训练开始的第一步</title>
                    </head>
                    <body>
                        <sr-read style='font-family: "LXGW WenKai Screen";'>
                            <sr-rd-title>06 | Torchvision（上）：数据读取，训练开始的第一步</sr-rd-title>
                    <sr-rd-desc style="margin: 0;padding-top: 0;padding-bottom: 0;font-style: normal;font-size: 18px;">今天这次加餐，我们就一起来看看什么是机器学习，它是怎么分类的，都有哪些常见名词。在补充了这些基础知识之后，我还会和你聊聊模型训练的本质是什么</sr-rd-desc>
                    <sr-rd-content><h1 id="sr-toc-0"> 06 | Torchvision（上）：数据读取，训练开始的第一步</h1><div><span>方远</span> <span> 2021-10-22</span></div><div><div><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/5d/ee/5d992769e7c17e4662c4e33e461febee.jpg"></div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADEAAAABCAYAAAB35kaxAAAAAXNSR0IArs4c6QAAAChJREFUGFdjfPfu3X8GKBAUFASz3r9/DxNiQBbDxcamn1yzSLEDZi8A2agny86FR+IAAAAASUVORK5CYII="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAABCAYAAAA8TpVcAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFCYtjkAcT9D8ti7hUOAAAAAElFTkSuQmCC"></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAD0AAAABCAYAAABt2qY/AAAAAXNSR0IArs4c6QAAACdJREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULy2PQQK0YLewiZCQDhUS3LBhDf1QAAAABJRU5ErkJggg=="></div><div class="sr-rd-content-center-small"><img class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABEAAAABCAYAAAA4u0VhAAAAAXNSR0IArs4c6QAAAB1JREFUGFdjfPfu3X9BQUEGEHj//j2YBgFkMULyAF6lD8tbqYWOAAAAAElFTkSuQmCC"></div></div></div><div><div><div></div></div><div><div><div><div><div><div>00:00</div></div><div></div></div></div><a href="javascript:;"> 1.0x <i><span></span></i></a></div><div><span>讲述：方远</span><span>大小：12.11M</span><span> 时长：13:16</span></div></div><audio title="06 | Torchvision（上）：数据读取，训练开始的第一步" src="https://res001.geekbang.org/media/audio/66/49/66f7d7e468502f41596773a35560e249/ld/ld.m3u8" __idm_id__="81927"></audio></div><div><div><div><div data-slate-editor="true" data-key="4165" autocorrect="off" spellcheck="false" data-gramm="false"><div data-slate-type="paragraph" data-slate-object="block" data-key="4166"><span data-slate-object="text" data-key="4167"><span data-slate-leaf="true" data-offset-key="4167:0" data-first-offset="true"><span data-slate-string="true">你好，我是方远。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4168"><span data-slate-object="text" data-key="4169"><span data-slate-leaf="true" data-offset-key="4169:0" data-first-offset="true"><span data-slate-string="true">今天起我们进入模型训练篇的学习。如果将模型看作一辆汽车，那么它的开发过程就可以看作是一套完整的生产流程，环环相扣、缺一不可。这些环节包括</span></span></span><span data-slate-object="text" data-key="4170"><span data-slate-leaf="true" data-offset-key="4170:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">数据的读取、网络的设计、优化方法与损失函数的选择以及一些辅助的工具等</span></span></span></span><span data-slate-object="text" data-key="4171"><span data-slate-leaf="true" data-offset-key="4171:0" data-first-offset="true"><span data-slate-string="true">。未来你将尝试构建自己的豪华汽车，或者站在巨人的肩膀上对前人的作品进行优化。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4172"><span data-slate-object="text" data-key="4173"><span data-slate-leaf="true" data-offset-key="4173:0" data-first-offset="true"><span data-slate-string="true">试想一下，如果你对这些基础环节所使用的方法都不清楚，你还能很好地进行下去吗？所以通过这个模块，我们的目标是先把基础打好。通过这模块的学习，对于 PyTorch 都为我们提供了哪些丰富的 API，你就会了然于胸了。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4174"><span data-slate-object="text" data-key="4175"><span data-slate-leaf="true" data-offset-key="4175:0" data-first-offset="true"><span data-slate-string="true">Torchvision 是一个和 PyTorch 配合使用的 Python 包，包含很多图像处理的工具。我们先从数据处理入手，开始 PyTorch 的学习的第一步。这节课我们会先介绍 Torchvision 的常用数据集及其读取方法，在后面的两节课里，我再带你了解常用的图像处理方法与 Torchvision 其它有趣的功能。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4176" id="sr-toc-1"><span data-slate-object="text" data-key="4177"><span data-slate-leaf="true" data-offset-key="4177:0" data-first-offset="true"><span data-slate-string="true">PyTorch 中的数据读取</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4178"><span data-slate-object="text" data-key="4179"><span data-slate-leaf="true" data-offset-key="4179:0" data-first-offset="true"><span data-slate-string="true">训练开始的第一步，首先就是数据读取。PyTorch 为我们提供了一种十分方便的数据读取机制，即使用 Dataset 类与 DataLoader 类的组合，来得到数据迭代器。在训练或预测时，数据迭代器能够输出每一批次所需的数据，并且对数据进行相应的预处理与数据增强操作。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4180"><span data-slate-object="text" data-key="4181"><span data-slate-leaf="true" data-offset-key="4181:0" data-first-offset="true"><span data-slate-string="true">下面我们分别来看下 Dataset 类与 DataLoader 类。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4182" id="sr-toc-2"><span data-slate-object="text" data-key="4183"><span data-slate-leaf="true" data-offset-key="4183:0" data-first-offset="true"><span data-slate-string="true">Dataset 类</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4184"><span data-slate-object="text" data-key="4185"><span data-slate-leaf="true" data-offset-key="4185:0" data-first-offset="true"><span data-slate-string="true">PyTorch 中的 Dataset 类是一个抽象类，它可以用来表示数据集。我们通过继承 Dataset 类来自定义数据集的格式、大小和其它属性，后面就可以供 DataLoader 类直接使用。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4186"><span data-slate-object="text" data-key="4187"><span data-slate-leaf="true" data-offset-key="4187:0" data-first-offset="true"><span data-slate-string="true">其实这就表示，无论使用自定义的数据集，还是官方为我们封装好的数据集，其本质都是继承了 Dataset 类。而在继承 Dataset 类时，至少需要重写以下几个方法：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="4188"><div data-slate-type="list-line" data-slate-object="block" data-key="4189"><span data-slate-object="text" data-key="4190"><span data-slate-leaf="true" data-offset-key="4190:0" data-first-offset="true"><span data-slate-string="true">__init__()：构造函数，可自定义数据读取方法以及进行数据预处理；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4191"><span data-slate-object="text" data-key="4192"><span data-slate-leaf="true" data-offset-key="4192:0" data-first-offset="true"><span data-slate-string="true">__len__()：返回数据集大小；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4193"><span data-slate-object="text" data-key="4194"><span data-slate-leaf="true" data-offset-key="4194:0" data-first-offset="true"><span data-slate-string="true">__getitem__()：索引数据集中的某一个数据。</span></span></span></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4195"><span data-slate-object="text" data-key="4196"><span data-slate-leaf="true" data-offset-key="4196:0" data-first-offset="true"><span data-slate-string="true">光看原理不容易理解，下面我们来编写一个简单的例子，看下如何使用 Dataset 类定义一个 Tensor 类型的数据集。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4197"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4198"><span data-slate-object="text" data-key="4199"><span data-slate-leaf="true" data-offset-key="4199:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4200"><span data-slate-leaf="true" data-offset-key="4200:0" data-first-offset="true"><span data-slate-string="true"> torch</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4201"><span data-slate-object="text" data-key="4202"><span data-slate-leaf="true" data-offset-key="4202:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4203"><span data-slate-leaf="true" data-offset-key="4203:0" data-first-offset="true"><span data-slate-string="true"> torch.utils.data </span></span></span><span data-slate-object="text" data-key="4204"><span data-slate-leaf="true" data-offset-key="4204:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4205"><span data-slate-leaf="true" data-offset-key="4205:0" data-first-offset="true"><span data-slate-string="true"> Dataset</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4206"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4207"><span data-slate-object="text" data-key="4208"><span data-slate-leaf="true" data-offset-key="4208:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">class</span></span></span></span><span data-slate-object="text" data-key="4209"><span data-slate-leaf="true" data-offset-key="4209:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4210"><span data-slate-leaf="true" data-offset-key="4210:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">MyDataset</span></span></span></span><span data-slate-object="text" data-key="4211"><span data-slate-leaf="true" data-offset-key="4211:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4212"><span data-slate-leaf="true" data-offset-key="4212:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">Dataset</span></span></span></span><span data-slate-object="text" data-key="4213"><span data-slate-leaf="true" data-offset-key="4213:0" data-first-offset="true"><span data-slate-string="true">):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4214"><span data-slate-object="text" data-key="4215"><span data-slate-leaf="true" data-offset-key="4215:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4216"><span data-slate-leaf="true" data-offset-key="4216:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 构造函数</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4217"><span data-slate-object="text" data-key="4218"><span data-slate-leaf="true" data-offset-key="4218:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4219"><span data-slate-leaf="true" data-offset-key="4219:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">def</span></span></span></span><span data-slate-object="text" data-key="4220"><span data-slate-leaf="true" data-offset-key="4220:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4221"><span data-slate-leaf="true" data-offset-key="4221:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">__init__</span></span></span></span><span data-slate-object="text" data-key="4222"><span data-slate-leaf="true" data-offset-key="4222:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4223"><span data-slate-leaf="true" data-offset-key="4223:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">self, data_tensor, target_tensor</span></span></span></span><span data-slate-object="text" data-key="4224"><span data-slate-leaf="true" data-offset-key="4224:0" data-first-offset="true"><span data-slate-string="true">):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4225"><span data-slate-object="text" data-key="4226"><span data-slate-leaf="true" data-offset-key="4226:0" data-first-offset="true"><span data-slate-string="true">        self.data_tensor = data_tensor</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4227"><span data-slate-object="text" data-key="4228"><span data-slate-leaf="true" data-offset-key="4228:0" data-first-offset="true"><span data-slate-string="true">        self.target_tensor = target_tensor</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4229"><span data-slate-object="text" data-key="4230"><span data-slate-leaf="true" data-offset-key="4230:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4231"><span data-slate-leaf="true" data-offset-key="4231:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 返回数据集大小</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4232"><span data-slate-object="text" data-key="4233"><span data-slate-leaf="true" data-offset-key="4233:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4234"><span data-slate-leaf="true" data-offset-key="4234:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">def</span></span></span></span><span data-slate-object="text" data-key="4235"><span data-slate-leaf="true" data-offset-key="4235:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4236"><span data-slate-leaf="true" data-offset-key="4236:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">__len__</span></span></span></span><span data-slate-object="text" data-key="4237"><span data-slate-leaf="true" data-offset-key="4237:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4238"><span data-slate-leaf="true" data-offset-key="4238:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">self</span></span></span></span><span data-slate-object="text" data-key="4239"><span data-slate-leaf="true" data-offset-key="4239:0" data-first-offset="true"><span data-slate-string="true">):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4240"><span data-slate-object="text" data-key="4241"><span data-slate-leaf="true" data-offset-key="4241:0" data-first-offset="true"><span data-slate-string="true">        </span></span></span><span data-slate-object="text" data-key="4242"><span data-slate-leaf="true" data-offset-key="4242:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">return</span></span></span></span><span data-slate-object="text" data-key="4243"><span data-slate-leaf="true" data-offset-key="4243:0" data-first-offset="true"><span data-slate-string="true"> self.data_tensor.size(</span></span></span><span data-slate-object="text" data-key="4244"><span data-slate-leaf="true" data-offset-key="4244:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4245"><span data-slate-leaf="true" data-offset-key="4245:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4246"><span data-slate-object="text" data-key="4247"><span data-slate-leaf="true" data-offset-key="4247:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4248"><span data-slate-leaf="true" data-offset-key="4248:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 返回索引的数据与标签</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4249"><span data-slate-object="text" data-key="4250"><span data-slate-leaf="true" data-offset-key="4250:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4251"><span data-slate-leaf="true" data-offset-key="4251:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">def</span></span></span></span><span data-slate-object="text" data-key="4252"><span data-slate-leaf="true" data-offset-key="4252:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span><span data-slate-object="text" data-key="4253"><span data-slate-leaf="true" data-offset-key="4253:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">__getitem__</span></span></span></span><span data-slate-object="text" data-key="4254"><span data-slate-leaf="true" data-offset-key="4254:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4255"><span data-slate-leaf="true" data-offset-key="4255:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">self, index</span></span></span></span><span data-slate-object="text" data-key="4256"><span data-slate-leaf="true" data-offset-key="4256:0" data-first-offset="true"><span data-slate-string="true">):</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4257"><span data-slate-object="text" data-key="4258"><span data-slate-leaf="true" data-offset-key="4258:0" data-first-offset="true"><span data-slate-string="true">        </span></span></span><span data-slate-object="text" data-key="4259"><span data-slate-leaf="true" data-offset-key="4259:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">return</span></span></span></span><span data-slate-object="text" data-key="4260"><span data-slate-leaf="true" data-offset-key="4260:0" data-first-offset="true"><span data-slate-string="true"> self.data_tensor[index], self.target_tensor[index]</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4261"><span data-slate-object="text" data-key="4262"><span data-slate-leaf="true" data-offset-key="4262:0" data-first-offset="true"><span data-slate-string="true">结合代码可以看到，我们定义了一个名字为 MyDataset 的数据集，在构造函数中，传入 Tensor 类型的数据与标签；在 __len__ 函数中，直接返回 Tensor 的大小；在 __getitem__ 函数中返回索引的数据与标签。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4263"><span data-slate-object="text" data-key="4264"><span data-slate-leaf="true" data-offset-key="4264:0" data-first-offset="true"><span data-slate-string="true">下面，我们来看一下如何调用刚才定义的数据集。首先随机生成一个 10*3 维的数据 Tensor，然后生成 10 维的标签 Tensor，与数据 Tensor 相对应。利用这两个 Tensor，生成一个 MyDataset 的对象。查看数据集的大小可以直接用 len () 函数，索引调用数据可以直接使用下标。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4265"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div><div data-code-line-number="18"></div><div data-code-line-number="19"></div><div data-code-line-number="20"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4266"><span data-slate-object="text" data-key="4267"><span data-slate-leaf="true" data-offset-key="4267:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 生成数据</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4268"><span data-slate-object="text" data-key="4269"><span data-slate-leaf="true" data-offset-key="4269:0" data-first-offset="true"><span data-slate-string="true">data_tensor = torch.randn(</span></span></span><span data-slate-object="text" data-key="4270"><span data-slate-leaf="true" data-offset-key="4270:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">10</span></span></span></span><span data-slate-object="text" data-key="4271"><span data-slate-leaf="true" data-offset-key="4271:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="4272"><span data-slate-leaf="true" data-offset-key="4272:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">3</span></span></span></span><span data-slate-object="text" data-key="4273"><span data-slate-leaf="true" data-offset-key="4273:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4274"><span data-slate-object="text" data-key="4275"><span data-slate-leaf="true" data-offset-key="4275:0" data-first-offset="true"><span data-slate-string="true">target_tensor = torch.randint(</span></span></span><span data-slate-object="text" data-key="4276"><span data-slate-leaf="true" data-offset-key="4276:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">2</span></span></span></span><span data-slate-object="text" data-key="4277"><span data-slate-leaf="true" data-offset-key="4277:0" data-first-offset="true"><span data-slate-string="true">, (</span></span></span><span data-slate-object="text" data-key="4278"><span data-slate-leaf="true" data-offset-key="4278:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">10</span></span></span></span><span data-slate-object="text" data-key="4279"><span data-slate-leaf="true" data-offset-key="4279:0" data-first-offset="true"><span data-slate-string="true">,)) </span></span></span><span data-slate-object="text" data-key="4280"><span data-slate-leaf="true" data-offset-key="4280:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 标签是 0 或 1</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4281"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4282"><span data-slate-object="text" data-key="4283"><span data-slate-leaf="true" data-offset-key="4283:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 将数据封装成 Dataset</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4284"><span data-slate-object="text" data-key="4285"><span data-slate-leaf="true" data-offset-key="4285:0" data-first-offset="true"><span data-slate-string="true">my_dataset = MyDataset(data_tensor, target_tensor)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4286"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4287"><span data-slate-object="text" data-key="4288"><span data-slate-leaf="true" data-offset-key="4288:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 查看数据集大小</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4289"><span data-slate-object="text" data-key="4290"><span data-slate-leaf="true" data-offset-key="4290:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4291"><span data-slate-leaf="true" data-offset-key="4291:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4292"><span data-slate-leaf="true" data-offset-key="4292:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'Dataset size:'</span></span></span></span><span data-slate-object="text" data-key="4293"><span data-slate-leaf="true" data-offset-key="4293:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="4294"><span data-slate-leaf="true" data-offset-key="4294:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">len</span></span></span></span><span data-slate-object="text" data-key="4295"><span data-slate-leaf="true" data-offset-key="4295:0" data-first-offset="true"><span data-slate-string="true">(my_dataset))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4296"><span data-slate-object="text" data-key="4297"><span data-slate-leaf="true" data-offset-key="4297:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4298"><span data-slate-object="text" data-key="4299"><span data-slate-leaf="true" data-offset-key="4299:0" data-first-offset="true"><span data-slate-string="true">输出：</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4300"><span data-slate-object="text" data-key="4301"><span data-slate-leaf="true" data-offset-key="4301:0" data-first-offset="true"><span data-slate-string="true">Dataset size: 10</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4302"><span data-slate-object="text" data-key="4303"><span data-slate-leaf="true" data-offset-key="4303:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4304"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4305"><span data-slate-object="text" data-key="4306"><span data-slate-leaf="true" data-offset-key="4306:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 使用索引调用数据</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4307"><span data-slate-object="text" data-key="4308"><span data-slate-leaf="true" data-offset-key="4308:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4309"><span data-slate-leaf="true" data-offset-key="4309:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4310"><span data-slate-leaf="true" data-offset-key="4310:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'tensor_data[0]:'</span></span></span></span><span data-slate-object="text" data-key="4311"><span data-slate-leaf="true" data-offset-key="4311:0" data-first-offset="true"><span data-slate-string="true">, my_dataset[</span></span></span><span data-slate-object="text" data-key="4312"><span data-slate-leaf="true" data-offset-key="4312:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4313"><span data-slate-leaf="true" data-offset-key="4313:0" data-first-offset="true"><span data-slate-string="true">])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4314"><span data-slate-object="text" data-key="4315"><span data-slate-leaf="true" data-offset-key="4315:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4316"><span data-slate-object="text" data-key="4317"><span data-slate-leaf="true" data-offset-key="4317:0" data-first-offset="true"><span data-slate-string="true">输出:</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4318"><span data-slate-object="text" data-key="4319"><span data-slate-leaf="true" data-offset-key="4319:0" data-first-offset="true"><span data-slate-string="true">tensor_data[0]:  (tensor([ 0.4931, -0.0697,  0.4171]), tensor(0))</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4320"><span data-slate-object="text" data-key="4321"><span data-slate-leaf="true" data-offset-key="4321:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4322" id="sr-toc-3"><span data-slate-object="text" data-key="4323"><span data-slate-leaf="true" data-offset-key="4323:0" data-first-offset="true"><span data-slate-string="true">DataLoader 类</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4324"><span data-slate-object="text" data-key="4325"><span data-slate-leaf="true" data-offset-key="4325:0" data-first-offset="true"><span data-slate-string="true">在实际项目中，如果数据量很大，考虑到内存有限、I/O 速度等问题，在训练过程中不可能一次性的将所有数据全部加载到内存中，也不能只用一个进程去加载，所以就需要多进程、迭代加载，而 DataLoader 就是基于这些需要被设计出来的。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4326"><span data-slate-object="text" data-key="4327"><span data-slate-leaf="true" data-offset-key="4327:0" data-first-offset="true"><span data-slate-string="true">DataLoader 是一个迭代器，最基本的使用方法就是传入一个 Dataset 对象，它会根据参数 batch_size 的值生成一个 batch 的数据，节省内存的同时，它还可以实现多进程、数据打乱等处理。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4328"><span data-slate-object="text" data-key="4329"><span data-slate-leaf="true" data-offset-key="4329:0" data-first-offset="true"><span data-slate-string="true">DataLoader 类的调用方式如下：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4330"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div><div data-code-line-number="8"></div><div data-code-line-number="9"></div><div data-code-line-number="10"></div><div data-code-line-number="11"></div><div data-code-line-number="12"></div><div data-code-line-number="13"></div><div data-code-line-number="14"></div><div data-code-line-number="15"></div><div data-code-line-number="16"></div><div data-code-line-number="17"></div><div data-code-line-number="18"></div><div data-code-line-number="19"></div><div data-code-line-number="20"></div><div data-code-line-number="21"></div><div data-code-line-number="22"></div><div data-code-line-number="23"></div><div data-code-line-number="24"></div><div data-code-line-number="25"></div><div data-code-line-number="26"></div><div data-code-line-number="27"></div><div data-code-line-number="28"></div><div data-code-line-number="29"></div><div data-code-line-number="30"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4331"><span data-slate-object="text" data-key="4332"><span data-slate-leaf="true" data-offset-key="4332:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">from</span></span></span></span><span data-slate-object="text" data-key="4333"><span data-slate-leaf="true" data-offset-key="4333:0" data-first-offset="true"><span data-slate-string="true"> torch.utils.data </span></span></span><span data-slate-object="text" data-key="4334"><span data-slate-leaf="true" data-offset-key="4334:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4335"><span data-slate-leaf="true" data-offset-key="4335:0" data-first-offset="true"><span data-slate-string="true"> DataLoader</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4336"><span data-slate-object="text" data-key="4337"><span data-slate-leaf="true" data-offset-key="4337:0" data-first-offset="true"><span data-slate-string="true">tensor_dataloader = DataLoader(dataset=my_dataset, </span></span></span><span data-slate-object="text" data-key="4338"><span data-slate-leaf="true" data-offset-key="4338:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 传入的数据集，必须参数</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4339"><span data-slate-object="text" data-key="4340"><span data-slate-leaf="true" data-offset-key="4340:0" data-first-offset="true"><span data-slate-string="true">                               batch_size=</span></span></span><span data-slate-object="text" data-key="4341"><span data-slate-leaf="true" data-offset-key="4341:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">2</span></span></span></span><span data-slate-object="text" data-key="4342"><span data-slate-leaf="true" data-offset-key="4342:0" data-first-offset="true"><span data-slate-string="true">,       </span></span></span><span data-slate-object="text" data-key="4343"><span data-slate-leaf="true" data-offset-key="4343:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 输出的 batch 大小</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4344"><span data-slate-object="text" data-key="4345"><span data-slate-leaf="true" data-offset-key="4345:0" data-first-offset="true"><span data-slate-string="true">                               shuffle=</span></span></span><span data-slate-object="text" data-key="4346"><span data-slate-leaf="true" data-offset-key="4346:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">True</span></span></span></span><span data-slate-object="text" data-key="4347"><span data-slate-leaf="true" data-offset-key="4347:0" data-first-offset="true"><span data-slate-string="true">,       </span></span></span><span data-slate-object="text" data-key="4348"><span data-slate-leaf="true" data-offset-key="4348:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 数据是否打乱</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4349"><span data-slate-object="text" data-key="4350"><span data-slate-leaf="true" data-offset-key="4350:0" data-first-offset="true"><span data-slate-string="true">                               num_workers=</span></span></span><span data-slate-object="text" data-key="4351"><span data-slate-leaf="true" data-offset-key="4351:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4352"><span data-slate-leaf="true" data-offset-key="4352:0" data-first-offset="true"><span data-slate-string="true">)      </span></span></span><span data-slate-object="text" data-key="4353"><span data-slate-leaf="true" data-offset-key="4353:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 进程数，0 表示只有主进程</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4354"></div><div data-slate-type="code-line" data-slate-object="block" data-key="4355"><span data-slate-object="text" data-key="4356"><span data-slate-leaf="true" data-offset-key="4356:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 以循环形式输出</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4357"><span data-slate-object="text" data-key="4358"><span data-slate-leaf="true" data-offset-key="4358:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">for</span></span></span></span><span data-slate-object="text" data-key="4359"><span data-slate-leaf="true" data-offset-key="4359:0" data-first-offset="true"><span data-slate-string="true"> data, target </span></span></span><span data-slate-object="text" data-key="4360"><span data-slate-leaf="true" data-offset-key="4360:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">in</span></span></span></span><span data-slate-object="text" data-key="4361"><span data-slate-leaf="true" data-offset-key="4361:0" data-first-offset="true"><span data-slate-string="true"> tensor_dataloader: </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4362"><span data-slate-object="text" data-key="4363"><span data-slate-leaf="true" data-offset-key="4363:0" data-first-offset="true"><span data-slate-string="true">    </span></span></span><span data-slate-object="text" data-key="4364"><span data-slate-leaf="true" data-offset-key="4364:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4365"><span data-slate-leaf="true" data-offset-key="4365:0" data-first-offset="true"><span data-slate-string="true">(data, target)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4366"><span data-slate-object="text" data-key="4367"><span data-slate-leaf="true" data-offset-key="4367:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4368"><span data-slate-object="text" data-key="4369"><span data-slate-leaf="true" data-offset-key="4369:0" data-first-offset="true"><span data-slate-string="true">输出:</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4370"><span data-slate-object="text" data-key="4371"><span data-slate-leaf="true" data-offset-key="4371:0" data-first-offset="true"><span data-slate-string="true">tensor([[-0.1781, -1.1019, -0.1507],</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4372"><span data-slate-object="text" data-key="4373"><span data-slate-leaf="true" data-offset-key="4373:0" data-first-offset="true"><span data-slate-string="true">        [-0.6170,  0.2366,  0.1006]]) tensor([0, 0])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4374"><span data-slate-object="text" data-key="4375"><span data-slate-leaf="true" data-offset-key="4375:0" data-first-offset="true"><span data-slate-string="true">tensor([[0.9451, -0.4923, -1.8178],</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4376"><span data-slate-object="text" data-key="4377"><span data-slate-leaf="true" data-offset-key="4377:0" data-first-offset="true"><span data-slate-string="true">        [-0.4046, -0.5436, -1.7911]]) tensor([0, 0])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4378"><span data-slate-object="text" data-key="4379"><span data-slate-leaf="true" data-offset-key="4379:0" data-first-offset="true"><span data-slate-string="true">tensor([[-0.4561, -1.2480, -0.3051],</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4380"><span data-slate-object="text" data-key="4381"><span data-slate-leaf="true" data-offset-key="4381:0" data-first-offset="true"><span data-slate-string="true">        [-0.9738,  0.9465,  0.4812]]) tensor([1, 0])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4382"><span data-slate-object="text" data-key="4383"><span data-slate-leaf="true" data-offset-key="4383:0" data-first-offset="true"><span data-slate-string="true">tensor([[0.0260,  1.5276,  0.1687],</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4384"><span data-slate-object="text" data-key="4385"><span data-slate-leaf="true" data-offset-key="4385:0" data-first-offset="true"><span data-slate-string="true">        [1.3692, -0.0170, -1.6831]]) tensor([1, 0])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4386"><span data-slate-object="text" data-key="4387"><span data-slate-leaf="true" data-offset-key="4387:0" data-first-offset="true"><span data-slate-string="true">tensor([[0.0515, -0.8892, -0.1699],</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4388"><span data-slate-object="text" data-key="4389"><span data-slate-leaf="true" data-offset-key="4389:0" data-first-offset="true"><span data-slate-string="true">        [0.4931, -0.0697,  0.4171]]) tensor([1, 0])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4390"><span data-slate-object="text" data-key="4391"><span data-slate-leaf="true" data-offset-key="4391:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4392"><span data-slate-object="text" data-key="4393"><span data-slate-leaf="true" data-offset-key="4393:0" data-first-offset="true"><span data-slate-string="true"> </span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4394"><span data-slate-object="text" data-key="4395"><span data-slate-leaf="true" data-offset-key="4395:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 输出一个 batch</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4396"><span data-slate-object="text" data-key="4397"><span data-slate-leaf="true" data-offset-key="4397:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4398"><span data-slate-leaf="true" data-offset-key="4398:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4399"><span data-slate-leaf="true" data-offset-key="4399:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'One batch tensor data:'</span></span></span></span><span data-slate-object="text" data-key="4400"><span data-slate-leaf="true" data-offset-key="4400:0" data-first-offset="true"><span data-slate-string="true">, </span></span></span><span data-slate-object="text" data-key="4401"><span data-slate-leaf="true" data-offset-key="4401:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">iter</span></span></span></span><span data-slate-object="text" data-key="4402"><span data-slate-leaf="true" data-offset-key="4402:0" data-first-offset="true"><span data-slate-string="true">(tensor_dataloader).</span></span></span><span data-slate-object="text" data-key="4403"><span data-slate-leaf="true" data-offset-key="4403:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">next</span></span></span></span><span data-slate-object="text" data-key="4404"><span data-slate-leaf="true" data-offset-key="4404:0" data-first-offset="true"><span data-slate-string="true">())</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4405"><span data-slate-object="text" data-key="4406"><span data-slate-leaf="true" data-offset-key="4406:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'''</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4407"><span data-slate-object="text" data-key="4408"><span data-slate-leaf="true" data-offset-key="4408:0" data-first-offset="true"><span data-slate-string="true">输出:</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4409"><span data-slate-object="text" data-key="4410"><span data-slate-leaf="true" data-offset-key="4410:0" data-first-offset="true"><span data-slate-string="true">One batch tensor data:  [tensor([[ 0.9451, -0.4923, -1.8178],</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4411"><span data-slate-object="text" data-key="4412"><span data-slate-leaf="true" data-offset-key="4412:0" data-first-offset="true"><span data-slate-string="true">        [-0.4046, -0.5436, -1.7911]]), tensor([0, 0])]</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4413"><span data-slate-object="text" data-key="4414"><span data-slate-leaf="true" data-offset-key="4414:0" data-first-offset="true"><span data-slate-string="true">'''</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4415"><span data-slate-object="text" data-key="4416"><span data-slate-leaf="true" data-offset-key="4416:0" data-first-offset="true"><span data-slate-string="true">结合代码，我们梳理一下 DataLoader 中的几个参数，它们分别表示：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="4417"><div data-slate-type="list-line" data-slate-object="block" data-key="4418"><span data-slate-object="text" data-key="4419"><span data-slate-leaf="true" data-offset-key="4419:0" data-first-offset="true"><span data-slate-string="true">dataset：Dataset 类型，输入的数据集，必须参数；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4420"><span data-slate-object="text" data-key="4421"><span data-slate-leaf="true" data-offset-key="4421:0" data-first-offset="true"><span data-slate-string="true">batch_size：int 类型，每个 batch 有多少个样本；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4422"><span data-slate-object="text" data-key="4423"><span data-slate-leaf="true" data-offset-key="4423:0" data-first-offset="true"><span data-slate-string="true">shuffle：bool 类型，在每个 epoch 开始的时候，是否对数据进行重新打乱；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4424"><span data-slate-object="text" data-key="4425"><span data-slate-leaf="true" data-offset-key="4425:0" data-first-offset="true"><span data-slate-string="true">num_workers：int 类型，加载数据的进程数，0 意味着所有的数据都会被加载进主进程，默认为 0。</span></span></span></div></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4426" id="sr-toc-4"><span data-slate-object="text" data-key="4427"><span data-slate-leaf="true" data-offset-key="4427:0" data-first-offset="true"><span data-slate-string="true">什么是 Torchvision</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4428"><span data-slate-object="text" data-key="4429"><span data-slate-leaf="true" data-offset-key="4429:0" data-first-offset="true"><span data-slate-string="true">PyTroch 官方为我们提供了一些常用的图片数据集，如果你需要读取这些数据集，那么无需自己实现，只需要利用 Torchvision 就可以搞定。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4430"><span data-slate-object="text" data-key="4431"><span data-slate-leaf="true" data-offset-key="4431:0" data-first-offset="true"><span data-slate-string="true">Torchvision 是一个和 PyTorch 配合使用的 Python 包。它不只提供了一些常用数据集，还提供了几个已经搭建好的经典网络模型，以及集成了一些图像数据处理方面的工具，主要供数据预处理阶段使用。简单地说，Torchvision 库就是</span></span></span><span data-slate-object="text" data-key="4432"><span data-slate-leaf="true" data-offset-key="4432:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">常用数据集 + 常见网络模型 + 常用图像处理方法</span></span></span></span><span data-slate-object="text" data-key="4433"><span data-slate-leaf="true" data-offset-key="4433:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4434"><span data-slate-object="text" data-key="4435"><span data-slate-leaf="true" data-offset-key="4435:0" data-first-offset="true"><span data-slate-string="true">Torchvision 的安装方式同样非常简单，可以使用 conda 安装，命令如下：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="4436"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4437"><span data-slate-object="text" data-key="4438"><span data-slate-leaf="true" data-offset-key="4438:0" data-first-offset="true"><span data-slate-string="true">conda install torchvision -c pytorch</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4439"><span data-slate-object="text" data-key="4440"><span data-slate-leaf="true" data-offset-key="4440:0" data-first-offset="true"><span data-slate-string="true">或使用 pip 进行安装，命令如下：</span></span></span></div><div data-slate-type="pre" data-slate-object="block" data-key="4441"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4442"><span data-slate-object="text" data-key="4443"><span data-slate-leaf="true" data-offset-key="4443:0" data-first-offset="true"><span data-slate-string="true">pip install torchvision</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4444"><span data-slate-object="text" data-key="4445"><span data-slate-leaf="true" data-offset-key="4445:0" data-first-offset="true"><span data-slate-string="true">Torchvision 中默认使用的图像加载器是 PIL，因此为了确保 Torchvision 正常运行，我们还需要安装一个 Python 的第三方图像处理库 ——Pillow 库。Pillow 提供了广泛的文件格式支持，强大的图像处理能力，主要包括图像储存、图像显示、格式转换以及基本的图像处理操作等。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4446"><span data-slate-object="text" data-key="4447"><span data-slate-leaf="true" data-offset-key="4447:0" data-first-offset="true"><span data-slate-string="true">使用 conda 安装 Pillow 的命令如下：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4448"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4449"><span data-slate-object="text" data-key="4450"><span data-slate-leaf="true" data-offset-key="4450:0" data-first-offset="true"><span data-slate-string="true">conda install pillow</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4451"><span data-slate-object="text" data-key="4452"><span data-slate-leaf="true" data-offset-key="4452:0" data-first-offset="true"><span data-slate-string="true">使用 pip 安装 Pillow 的命令如下：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4453"><div><span></span></div><div><div data-code-line-number="1"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4454"><span data-slate-object="text" data-key="4455"><span data-slate-leaf="true" data-offset-key="4455:0" data-first-offset="true"><span data-slate-string="true">pip install pillow</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4456" id="sr-toc-5"><span data-slate-object="text" data-key="4457"><span data-slate-leaf="true" data-offset-key="4457:0" data-first-offset="true"><span data-slate-string="true">利用 Torchvision 读取数据</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4458"><span data-slate-object="text" data-key="4459"><span data-slate-leaf="true" data-offset-key="4459:0" data-first-offset="true"><span data-slate-string="true">安装好 Torchvision 之后，我们再来接着看看。Torchvision 库为我们读取数据提供了哪些支持。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4460"><span data-slate-object="text" data-key="4461"><span data-slate-leaf="true" data-offset-key="4461:0" data-first-offset="true"><span data-slate-string="true">Torchvision 库中的</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4462"><span data-slate-object="text" data-key="4463"><span data-slate-leaf="true" data-offset-key="4463:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4464"><span data-slate-leaf="true" data-offset-key="4464:0" data-first-offset="true"><span data-slate-string="true"> 包中提供了丰富的图像数据集的接口。常用的图像数据集，例如 MNIST、COCO 等，这个模块都为我们做了相应的封装。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4465"><span data-slate-object="text" data-key="4466"><span data-slate-leaf="true" data-offset-key="4466:0" data-first-offset="true"><span data-slate-string="true">下表中列出了</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4467"><span data-slate-object="text" data-key="4468"><span data-slate-leaf="true" data-offset-key="4468:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4469"><span data-slate-leaf="true" data-offset-key="4469:0" data-first-offset="true"><span data-slate-string="true"> 包所有支持的数据集。各个数据集的说明与接口，详见链接 </span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="4470"><span data-slate-object="text" data-key="4471"><span data-slate-leaf="true" data-offset-key="4471:0" data-first-offset="true"><span data-slate-string="true">https://pytorch.org/vision/stable/datasets.html</span></span></span></a><span data-slate-object="text" data-key="4472"><span data-slate-leaf="true" data-offset-key="4472:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4473"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/5f/44/5fa4d9067fa79b140d9e7646e7f28544.jpg?wh=1920x1162"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4474"><span data-slate-object="text" data-key="4475"><span data-slate-leaf="true" data-offset-key="4475:0" data-first-offset="true"><span data-slate-string="true">这里我想提醒你注意，</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4476"><span data-slate-object="text" data-key="4477"><span data-slate-leaf="true" data-offset-key="4477:0" data-first-offset="true"><span data-slate-string="true">torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4478"><span data-slate-leaf="true" data-offset-key="4478:0" data-first-offset="true"><span data-slate-string="true"> 这个包本身并不包含数据集的文件本身，它的工作方式是先从网络上把数据集下载到用户指定目录，然后再用它的加载器把数据集加载到内存中。最后，把这个加载后的数据集作为对象返回给用户。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4479"><span data-slate-object="text" data-key="4480"><span data-slate-leaf="true" data-offset-key="4480:0" data-first-offset="true"><span data-slate-string="true">为了让你进一步加深对知识的理解，我们以 MNIST 数据集为例，来说明一下这个模块具体的使用方法。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4481" id="sr-toc-6"><span data-slate-object="text" data-key="4482"><span data-slate-leaf="true" data-offset-key="4482:0" data-first-offset="true"><span data-slate-string="true">MNIST 数据集简介</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4483"><span data-slate-object="text" data-key="4484"><span data-slate-leaf="true" data-offset-key="4484:0" data-first-offset="true"><span data-slate-string="true">MNIST 数据集是一个著名的手写数字数据集，因为上手简单，在深度学习领域，手写数字识别是一个很经典的学习入门样例。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4485"><span data-slate-object="text" data-key="4486"><span data-slate-leaf="true" data-offset-key="4486:0" data-first-offset="true"><span data-slate-string="true">MNIST 数据集是 NIST 数据集的一个子集，MNIST 数据集你可以通过</span></span></span><a data-slate-type="link" data-slate-object="inline" data-key="4487"><span data-slate-object="text" data-key="4488"><span data-slate-leaf="true" data-offset-key="4488:0" data-first-offset="true"><span data-slate-string="true">这里</span></span></span></a><span data-slate-object="text" data-key="4489"><span data-slate-leaf="true" data-offset-key="4489:0" data-first-offset="true"><span data-slate-string="true">下载。它包含了四个部分，我用表格的方式为你做了梳理。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4490"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/b6/9d/b6f465e8d27ca7f7abc27932da46309d.jpg?wh=1920x1157"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4491"><span data-slate-object="text" data-key="4492"><span data-slate-leaf="true" data-offset-key="4492:0" data-first-offset="true"><span data-slate-string="true">MNIST 数据集是 ubyte 格式存储，我们先将 “训练集图片” 解析成图片格式，来直观地看一看数据集具体是什么样子的。具体怎么解析，我在后面数据预览再展开。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4493"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/08/15/08977ccc74a3d2055434174e545d0515.jpg?wh=1920x844"></div></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4494" id="sr-toc-7"><span data-slate-object="text" data-key="4495"><span data-slate-leaf="true" data-offset-key="4495:0" data-first-offset="true"><span data-slate-string="true">数据读取</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4496"><span data-slate-object="text" data-key="4497"><span data-slate-leaf="true" data-offset-key="4497:0" data-first-offset="true"><span data-slate-string="true">接下来，我们看一下如何使用 Torchvision 来读取 MNIST 数据集。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4498"><span data-slate-object="text" data-key="4499"><span data-slate-leaf="true" data-offset-key="4499:0" data-first-offset="true"><span data-slate-string="true">对于</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4500"><span data-slate-object="text" data-key="4501"><span data-slate-leaf="true" data-offset-key="4501:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4502"><span data-slate-leaf="true" data-offset-key="4502:0" data-first-offset="true"><span data-slate-string="true"> 所支持的所有数据集，它都内置了相应的数据集接口。例如刚才介绍的 MNIST 数据集，</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4503"><span data-slate-object="text" data-key="4504"><span data-slate-leaf="true" data-offset-key="4504:0" data-first-offset="true"><span data-slate-string="true">torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4505"><span data-slate-leaf="true" data-offset-key="4505:0" data-first-offset="true"><span data-slate-string="true"> 就有一个 MNIST 的接口，接口内封装了从下载、解压缩、读取数据、解析数据等全部过程。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4506"><span data-slate-object="text" data-key="4507"><span data-slate-leaf="true" data-offset-key="4507:0" data-first-offset="true"><span data-slate-string="true">这些接口的工作方式差不多，都是先从网络上把数据集下载到指定目录，然后再用加载器把数据集加载到内存中，最后将加载后的数据集作为对象返回给用户。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4508"><span data-slate-object="text" data-key="4509"><span data-slate-leaf="true" data-offset-key="4509:0" data-first-offset="true"><span data-slate-string="true">以 MNIST 为例，我们可以用如下方式调用：</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4510"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div><div data-code-line-number="3"></div><div data-code-line-number="4"></div><div data-code-line-number="5"></div><div data-code-line-number="6"></div><div data-code-line-number="7"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4511"><span data-slate-object="text" data-key="4512"><span data-slate-leaf="true" data-offset-key="4512:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true"># 以 MNIST 为例</span></span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4513"><span data-slate-object="text" data-key="4514"><span data-slate-leaf="true" data-offset-key="4514:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">import</span></span></span></span><span data-slate-object="text" data-key="4515"><span data-slate-leaf="true" data-offset-key="4515:0" data-first-offset="true"><span data-slate-string="true"> torchvision</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4516"><span data-slate-object="text" data-key="4517"><span data-slate-leaf="true" data-offset-key="4517:0" data-first-offset="true"><span data-slate-string="true">mnist_dataset = torchvision.datasets.MNIST(root=</span></span></span><span data-slate-object="text" data-key="4518"><span data-slate-leaf="true" data-offset-key="4518:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">'./data'</span></span></span></span><span data-slate-object="text" data-key="4519"><span data-slate-leaf="true" data-offset-key="4519:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4520"><span data-slate-object="text" data-key="4521"><span data-slate-leaf="true" data-offset-key="4521:0" data-first-offset="true"><span data-slate-string="true">                                       train=</span></span></span><span data-slate-object="text" data-key="4522"><span data-slate-leaf="true" data-offset-key="4522:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">True</span></span></span></span><span data-slate-object="text" data-key="4523"><span data-slate-leaf="true" data-offset-key="4523:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4524"><span data-slate-object="text" data-key="4525"><span data-slate-leaf="true" data-offset-key="4525:0" data-first-offset="true"><span data-slate-string="true">                                       transform=</span></span></span><span data-slate-object="text" data-key="4526"><span data-slate-leaf="true" data-offset-key="4526:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4527"><span data-slate-leaf="true" data-offset-key="4527:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4528"><span data-slate-object="text" data-key="4529"><span data-slate-leaf="true" data-offset-key="4529:0" data-first-offset="true"><span data-slate-string="true">                                       target_transform=</span></span></span><span data-slate-object="text" data-key="4530"><span data-slate-leaf="true" data-offset-key="4530:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">None</span></span></span></span><span data-slate-object="text" data-key="4531"><span data-slate-leaf="true" data-offset-key="4531:0" data-first-offset="true"><span data-slate-string="true">,</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4532"><span data-slate-object="text" data-key="4533"><span data-slate-leaf="true" data-offset-key="4533:0" data-first-offset="true"><span data-slate-string="true">                                       download=</span></span></span><span data-slate-object="text" data-key="4534"><span data-slate-leaf="true" data-offset-key="4534:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">True</span></span></span></span><span data-slate-object="text" data-key="4535"><span data-slate-leaf="true" data-offset-key="4535:0" data-first-offset="true"><span data-slate-string="true">)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4536"><span data-slate-type="code" data-slate-object="inline" data-key="4537"><span data-slate-object="text" data-key="4538"><span data-slate-leaf="true" data-offset-key="4538:0" data-first-offset="true"><span data-slate-string="true">torchvision.datasets.MNIST</span></span></span></span><span data-slate-object="text" data-key="4539"><span data-slate-leaf="true" data-offset-key="4539:0" data-first-offset="true"><span data-slate-string="true"> 是一个类，对它进行实例化，即可返回一个 MNIST 数据集对象。构造函数包括包含 5 个参数：</span></span></span></div><div data-slate-type="list" data-slate-object="block" data-key="4540"><div data-slate-type="list-line" data-slate-object="block" data-key="4541"><span data-slate-object="text" data-key="4542"><span data-slate-leaf="true" data-offset-key="4542:0" data-first-offset="true"><span data-slate-string="true">root：是一个字符串，用于指定你想要保存 MNIST 数据集的位置。如果 download 是 Flase，则会从目标位置读取数据集；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4543"><span data-slate-object="text" data-key="4544"><span data-slate-leaf="true" data-offset-key="4544:0" data-first-offset="true"><span data-slate-string="true">download：是布尔类型，表示是否下载数据集。如果为 True，则会自动从网上下载这个数据集，存储到 root 指定的位置。如果指定位置已经存在数据集文件，则不会重复下载；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4545"><span data-slate-object="text" data-key="4546"><span data-slate-leaf="true" data-offset-key="4546:0" data-first-offset="true"><span data-slate-string="true">train：是布尔类型，表示是否加载训练集数据。如果为 True，则只加载训练数据。如果为 False，则只加载测试数据集。</span></span></span><span data-slate-object="text" data-key="4547"><span data-slate-leaf="true" data-offset-key="4547:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">这里需要注意，并不是所有的数据集都做了训练集和测试集的划分，这个参数并不一定是有效参数，具体需要参考官方接口说明文档</span></span></span></span><span data-slate-object="text" data-key="4548"><span data-slate-leaf="true" data-offset-key="4548:0" data-first-offset="true"><span data-slate-string="true">；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4549"><span data-slate-object="text" data-key="4550"><span data-slate-leaf="true" data-offset-key="4550:0" data-first-offset="true"><span data-slate-string="true">transform：用于对图像进行预处理操作，例如数据增强、归一化、旋转或缩放等。这些操作我们会在下节课展开讲解；</span></span></span></div><div data-slate-type="list-line" data-slate-object="block" data-key="4551"><span data-slate-object="text" data-key="4552"><span data-slate-leaf="true" data-offset-key="4552:0" data-first-offset="true"><span data-slate-string="true">target_transform：用于对图像标签进行预处理操作。</span></span></span></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4553"><span data-slate-object="text" data-key="4554"><span data-slate-leaf="true" data-offset-key="4554:0" data-first-offset="true"><span data-slate-string="true">运行上述的代码，我们可以得到下图所示的效果。从图中我们可以看出，程序首先去指定的网址下载了 MNIST 数据集，然后进行了解压缩等操作。如果你再次运行相同的代码，则不会再有下载的过程。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4555"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/dc/8a/dcec80c2aa0e63f5450c85b7cda5c88a.png?wh=1920x1387"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4556"><span data-slate-object="text" data-key="4557"><span data-slate-leaf="true" data-offset-key="4557:0" data-first-offset="true"><span data-slate-string="true">看到这，你可能还有疑问，好奇我们得到的 mnist_dataset 是什么呢？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4558"><span data-slate-object="text" data-key="4559"><span data-slate-leaf="true" data-offset-key="4559:0" data-first-offset="true"><span data-slate-string="true">如果你用 type 函数查看一下 mnist_dataset 的类型，就可以得到</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4560"><span data-slate-object="text" data-key="4561"><span data-slate-leaf="true" data-offset-key="4561:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets.mnist.MNIST</span></span></span></span><span data-slate-object="text" data-key="4562"><span data-slate-leaf="true" data-offset-key="4562:0" data-first-offset="true"><span data-slate-string="true"> ，而这个类是之前我们介绍过的 Dataset 类的派生类。相当于</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4563"><span data-slate-object="text" data-key="4564"><span data-slate-leaf="true" data-offset-key="4564:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4565"><span data-slate-leaf="true" data-offset-key="4565:0" data-first-offset="true"><span data-slate-string="true"> ，它已经帮我们写好了对 Dataset 类的继承，完成了对数据集的封装，我们直接使用即可。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4566"><span data-slate-object="text" data-key="4567"><span data-slate-leaf="true" data-offset-key="4567:0" data-first-offset="true"><span data-slate-string="true">这里我们主要以 MNIST 为例，进行了说明。其它的数据集使用方法类似，调用的时候你只要需要将类名 “MNIST” 换成其它数据集名字即可。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4568"><span data-slate-object="text" data-key="4569"><span data-slate-leaf="true" data-offset-key="4569:0" data-first-offset="true"><span data-slate-string="true">对于不同的数据集，数据格式都不尽相同，而</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4570"><span data-slate-object="text" data-key="4571"><span data-slate-leaf="true" data-offset-key="4571:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4572"><span data-slate-leaf="true" data-offset-key="4572:0" data-first-offset="true"><span data-slate-string="true"> 则帮助我们完成了各种不同格式的数据的解析与读取，可以说十分便捷。而对于那些没有官方接口的图像数据集，我们也可以使用以</span></span></span><span data-slate-type="code" data-slate-object="inline" data-key="4573"><span data-slate-object="text" data-key="4574"><span data-slate-leaf="true" data-offset-key="4574:0" data-first-offset="true"><span data-slate-string="true"> torchvision.datasets.ImageFolder</span></span></span></span><span data-slate-object="text" data-key="4575"><span data-slate-leaf="true" data-offset-key="4575:0" data-first-offset="true"><span data-slate-string="true"> 接口来自行定义，在图像分类的实战篇中，就是使用 ImageFolder 进行数据读取的，你可以到那个时候再看一看。</span></span></span></div><h3 data-slate-type="heading" data-slate-object="block" data-key="4576" id="sr-toc-8"><span data-slate-object="text" data-key="4577"><span data-slate-leaf="true" data-offset-key="4577:0" data-first-offset="true"><span data-slate-string="true">数据预览</span></span></span></h3><div data-slate-type="paragraph" data-slate-object="block" data-key="4578"><span data-slate-object="text" data-key="4579"><span data-slate-leaf="true" data-offset-key="4579:0" data-first-offset="true"><span data-slate-string="true">完成了数据读取工作，我们得到的是对应的 mnist_dataset，刚才已经讲过了，这是一个封装了的数据集。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4580"><span data-slate-object="text" data-key="4581"><span data-slate-leaf="true" data-offset-key="4581:0" data-first-offset="true"><span data-slate-string="true">如果想要查看 mnist_dataset 中的具体内容，我们需要把它转化为列表。（如果 IOPub&nbsp;data&nbsp;rate 超限，可以只加载测试集数据，令 train=False）</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4582"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4583"><span data-slate-object="text" data-key="4584"><span data-slate-leaf="true" data-offset-key="4584:0" data-first-offset="true"><span data-slate-string="true">mnist_dataset_list = </span></span></span><span data-slate-object="text" data-key="4585"><span data-slate-leaf="true" data-offset-key="4585:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">list</span></span></span></span><span data-slate-object="text" data-key="4586"><span data-slate-leaf="true" data-offset-key="4586:0" data-first-offset="true"><span data-slate-string="true">(mnist_dataset)</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4587"><span data-slate-object="text" data-key="4588"><span data-slate-leaf="true" data-offset-key="4588:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4589"><span data-slate-leaf="true" data-offset-key="4589:0" data-first-offset="true"><span data-slate-string="true">(mnist_dataset_list)</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4590"><span data-slate-object="text" data-key="4591"><span data-slate-leaf="true" data-offset-key="4591:0" data-first-offset="true"><span data-slate-string="true">执行结果如下图所示。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4592"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/9c/12/9c7838a309b6e9ffa8yy33a44b00d312.png?wh=1920x434"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4593"><span data-slate-object="text" data-key="4594"><span data-slate-leaf="true" data-offset-key="4594:0" data-first-offset="true"><span data-slate-string="true">从运行结果中可以看出，转换后的数据集对象变成了一个元组列表，每个元组有两个元素，第一个元素是图像数据，第二个元素是图像的标签。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4595"><span data-slate-object="text" data-key="4596"><span data-slate-leaf="true" data-offset-key="4596:0" data-first-offset="true"><span data-slate-string="true">这里图像数据是 PIL.Image.Image 类型的，这种类型可以直接在 Jupyter 中显示出来。显示一条数据的代码如下。</span></span></span></div><div data-code-language="python" data-slate-type="pre" data-slate-object="block" data-key="4597"><div><span></span></div><div><div data-code-line-number="1"></div><div data-code-line-number="2"></div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><div data-origin="pm_code_preview"><div data-slate-type="code-line" data-slate-object="block" data-key="4598"><span data-slate-object="text" data-key="4599"><span data-slate-leaf="true" data-offset-key="4599:0" data-first-offset="true"><span data-slate-string="true">display(mnist_dataset_list[</span></span></span><span data-slate-object="text" data-key="4600"><span data-slate-leaf="true" data-offset-key="4600:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4601"><span data-slate-leaf="true" data-offset-key="4601:0" data-first-offset="true"><span data-slate-string="true">][</span></span></span><span data-slate-object="text" data-key="4602"><span data-slate-leaf="true" data-offset-key="4602:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4603"><span data-slate-leaf="true" data-offset-key="4603:0" data-first-offset="true"><span data-slate-string="true">])</span></span></span></div><div data-slate-type="code-line" data-slate-object="block" data-key="4604"><span data-slate-object="text" data-key="4605"><span data-slate-leaf="true" data-offset-key="4605:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">print</span></span></span></span><span data-slate-object="text" data-key="4606"><span data-slate-leaf="true" data-offset-key="4606:0" data-first-offset="true"><span data-slate-string="true">(</span></span></span><span data-slate-object="text" data-key="4607"><span data-slate-leaf="true" data-offset-key="4607:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">"Image label is:"</span></span></span></span><span data-slate-object="text" data-key="4608"><span data-slate-leaf="true" data-offset-key="4608:0" data-first-offset="true"><span data-slate-string="true">, mnist_dataset_list[</span></span></span><span data-slate-object="text" data-key="4609"><span data-slate-leaf="true" data-offset-key="4609:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">0</span></span></span></span><span data-slate-object="text" data-key="4610"><span data-slate-leaf="true" data-offset-key="4610:0" data-first-offset="true"><span data-slate-string="true">][</span></span></span><span data-slate-object="text" data-key="4611"><span data-slate-leaf="true" data-offset-key="4611:0" data-first-offset="true"><span data-slate-type="mark-class" data-slate-object="mark"><span data-slate-string="true">1</span></span></span></span><span data-slate-object="text" data-key="4612"><span data-slate-leaf="true" data-offset-key="4612:0" data-first-offset="true"><span data-slate-string="true">])</span></span></span></div></div></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4613"><span data-slate-object="text" data-key="4614"><span data-slate-leaf="true" data-offset-key="4614:0" data-first-offset="true"><span data-slate-string="true">运行结果如下图所示。可以看出，数据集 mnist_dataset 中的第一条数据是图片手写数字 “7”，对应的标签是 “7”。</span></span></span></div><div data-slate-type="image" data-slate-object="block" data-key="4615"><div class="sr-rd-content-center"><img class="sr-rd-content-img" src="https://static001.geekbang.org/resource/image/21/c3/211289da00fc13fd21f72573aee049c3.png?wh=1466x242"></div></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4616"><span data-slate-object="text" data-key="4617"><span data-slate-leaf="true" data-offset-key="4617:0" data-first-offset="true"><span data-slate-string="true">好，如果你也得到了上面的运行结果，说明你的操作没问题，恭喜你成功完成了读取操作。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4618" id="sr-toc-9"><span data-slate-object="text" data-key="4619"><span data-slate-leaf="true" data-offset-key="4619:0" data-first-offset="true"><span data-slate-string="true">小结</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4620"><span data-slate-object="text" data-key="4621"><span data-slate-leaf="true" data-offset-key="4621:0" data-first-offset="true"><span data-slate-string="true">恭喜你完成了这节课的学习。我们已经迈出了模型训练的第一步，学会了如何读取数据。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4622"><span data-slate-object="text" data-key="4623"><span data-slate-leaf="true" data-offset-key="4623:0" data-first-offset="true"><span data-slate-string="true">今天的重点就是掌握</span></span></span><span data-slate-object="text" data-key="4624"><span data-slate-leaf="true" data-offset-key="4624:0" data-first-offset="true"><span data-slate-type="bold" data-slate-object="mark"><span data-slate-string="true">两种读取数据的方法，也就是自定义和读取常用图像数据集</span></span></span></span><span data-slate-object="text" data-key="4625"><span data-slate-leaf="true" data-offset-key="4625:0" data-first-offset="true"><span data-slate-string="true">。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4626"><span data-slate-object="text" data-key="4627"><span data-slate-leaf="true" data-offset-key="4627:0" data-first-offset="true"><span data-slate-string="true">最通用的数据读取方法，就是自己定义一个 Dataset 的派生类。而读取常用的图像数据集，就可以利用 PyTorch 提供的视觉包 Torchvision。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4628"><span data-slate-object="text" data-key="4629"><span data-slate-leaf="true" data-offset-key="4629:0" data-first-offset="true"><span data-slate-string="true">Torchvision 库为我们读取数据提供了丰富的图像数据集的接口。我用手写数字识别这个经典例子，给你示范了如何使用 Torchvision 来读取 MNIST 数据集。</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4630"><span data-slate-type="code" data-slate-object="inline" data-key="4631"><span data-slate-object="text" data-key="4632"><span data-slate-leaf="true" data-offset-key="4632:0" data-first-offset="true"><span data-slate-string="true">torchvision.datasets</span></span></span></span><span data-slate-object="text" data-key="4633"><span data-slate-leaf="true" data-offset-key="4633:0" data-first-offset="true"><span data-slate-string="true"> 继承了 Dataset 类，它在预定义许多常用的数据集的同时，还预留了数据预处理与数据增强的接口。在下一节课中，我们就会接触到这些数据增强函数，并学习如何进行数据增强。</span></span></span></div><h2 data-slate-type="heading" data-slate-object="block" data-key="4634" id="sr-toc-10"><span data-slate-object="text" data-key="4635"><span data-slate-leaf="true" data-offset-key="4635:0" data-first-offset="true"><span data-slate-string="true">每课一练</span></span></span></h2><div data-slate-type="paragraph" data-slate-object="block" data-key="4636"><span data-slate-object="text" data-key="4637"><span data-slate-leaf="true" data-offset-key="4637:0" data-first-offset="true"><span data-slate-string="true">在 PyTorch 中，我们要定义一个数据集，应该继承哪一个类呢？</span></span></span></div><div data-slate-type="paragraph" data-slate-object="block" data-key="4638"><span data-slate-object="text" data-key="4639"><span data-slate-leaf="true" data-offset-key="4639:0" data-first-offset="true"><span data-slate-string="true">欢迎你在留言区和我交流互动，也推荐你把这节课内容分享给更多的朋友、同事，跟他一起学习进步。</span></span></span></div></div></div></div><div><div></div><div></div><div><div data-simplebar="init"><div><div><div></div></div><div><div><div><div><textarea placeholder="将学到的知识总结成笔记，方便日后快速查找及复习"></textarea></div></div></div></div><div></div></div><div><div></div></div><div><div></div></div></div><div><div>确认放弃笔记？</div><div>放弃后所记笔记将不保留。</div></div><div><div>新功能上线，你的历史笔记已初始化为私密笔记，是否一键批量公开？</div><div>批量公开的笔记不会为你同步至部落</div></div><div></div></div><div><div><div>公开</div><div>同步至部落</div></div><div>取消</div><div>完成</div></div><div><span>0/2000</span></div></div><div><div><span>划线</span></div><div></div><div></div><div></div><div><span>笔记</span></div><div></div><div><span>复制</span></div></div></div><div><div><div><span></span></div><p><span>10</span> 人觉得很赞<a href="javascript:void(0);">给文章提建议</a></p></div></div><div><span>©</span> 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。 </div></div><div><div><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div><div>Geek__653581f21177</div></div><div><textarea placeholder="由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。" rows="16"></textarea></div><div><div>Ctrl + Enter 发表</div><div>0/2000 字符</div><div>提交留言</div></div></div><div><h2 id="sr-toc-11">精选留言 (28)</h2><ul><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://thirdwx.qlogo.cn/mmopen/vi_32/SKmvhbNe9LMPQ0ib8ZqbJEfHicUxzxCSKVXiaibn7OrmXGUFQjkesgvODymZz4kibzqOGxuRq42t3sB2ibcBIIGWRgSg/132"></div></div><div><div><div><span>超人不会飞</span></div></div><div>tensor_dataloader 是一个迭代器
iter（tensor_dataloader) 是一个迭代器对象

iter (tensor_dataloader).next () 是输出迭代器的下一个元素

兄弟们我这波理解到位不</div><div><p>作者回复：你好，超人不会飞。感谢你的留言。
tensor_dataloader 是一个 dataloader 对象，用 iter () 强制类型转换成迭代器的对象，next () 是输出迭代器下一个元素。^^</p></div><div><div>2021-10-25</div><div><div><i></i><span>3</span></div><div><i></i><span>5</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/28/d6/1b/b0f912fd.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Spoon</span></div></div><div>老师好， 想问下。。为啥你说是 10x3 维啊 数据不是 2 维的吗，下面标签不是一维的吗。。。有点 confuse 了。。
data_tensor = torch.randn (10, 3)
target_tensor = torch.randint (2, (10,)) # 标签是 0 或 1</div><div><p>作者回复：你好，Spoon。感谢你的留言。
数据是 3 维，标签是 1 维，一共有 10 条数据。
10*3 是指 data_tensor 的 size，10*1 是指 target_tensor 的 size。
torch.randint (2, (10,)) 这句代码的意思是指生成 10 个随机数，随机数的范围只能是 0 或者 1。
可以运行下代码，分别打印一下 data_tensor 和 target_tensor 的内容，一看就能明白了：）</p></div><div><div>2021-10-22</div><div><div><i></i><span>4</span></div><div><i></i><span>2</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/10/bf/51/1791ae60.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>JC</span></div></div><div>国内直接下载 MNIST 数据集，可能会有些问题
可以通过本地下载文件，放入到某目录，然后在该目录下使用 python -m http.server 启动一个本地 server
最后把 mnist.py 文件里的 mirrors 上方添加一行 http://localhost:8000/MNIST/</div><div><div>2022-05-15</div><div><div><i></i><span></span></div><div><i></i><span>1</span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2b/e0/ca/adfaa551.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span> 孙新</span><span><div class="sr-rd-content-center"><img class="" src="https://static001.geekbang.org/resource/image/89/43/89yyff4c4c2e2b73ce4931bb01a6a943.png"></div></span></div></div><div>display (mnist_dataset_list [0][0])  这一行没有成功，提示 display 错误
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
NameError: name 'display' is not defined
我用的环境有问题吗？还是说需要什么 IDE 才能出效果？
</div><div><p>作者回复：你好，孙新，感谢你的留言。
这个 display () 函数是 Jupyter 自带的，如果想在其他 IDE 中使用，可以尝试：
from IPython import display</p></div><div><div>2022-09-02</div><div><div><i></i><span>2</span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>John (易筋)</span></div></div><div>PIL Image Module
The Image module provides a class with the same name which is used to represent a PIL image. The module also provides a number of factory functions, including functions to load images from files, and to create new images.

Examples
Open, rotate, and display an image (using the default viewer)
The following script loads an image, rotates it 45 degrees, and displays it using an external viewer (usually xv on Unix, and the Paint program on Windows).

from PIL import Image
with Image.open("hopper.jpg") as im:
    im.rotate(45).show()
</div><div><div>2022-07-29</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/27/ad/2b/46b4a196.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>ACT</span></div></div><div>Dataset</div><div><p>作者回复: 👍🏻 ^^</p></div><div><div>2022-07-28</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>John (易筋)</span></div></div><div>IOPub data rate 超限 解决 

This works for me in Mac and Windows (taken from here):

1. To create a jupyter_notebook_config.py file, with all the defaults commented out, you can use the following command line:

$ jupyter notebook --generate-config

2. Open the file and search for c.NotebookApp.iopub_data_rate_limit

3. 取消注释 Comment out the line c.NotebookApp.iopub_data_rate_limit = 1000000 and change it to a higher default rate. l used c.NotebookApp.iopub_data_rate_limit = 10000000

参考：
https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-in-jupyter-notebook-when-viewing-image
</div><div><p>作者回复: 👍🏻👍🏻👍🏻</p></div><div><div>2022-07-28</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/10/bf/51/1791ae60.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/resource/image/eb/56/eb5afbf568af2917033e5a860de0b756.png?x-oss-process=image/resize,w_28"></div></div><div><div><div><span>JC</span></div></div><div>国内直接下载 MNIST 数据集，可能会有些问题
可以通过本地下载文件，放入到某目录，然后在该目录下使用 python -m http.server 启动一个本地 server
最后把 mnist.py 文件里的 mirrors 上方添加一行 http://localhost:8000/MNIST/</div><div><p>作者回复: 👍🏻👍🏻👍🏻 ^^</p></div><div><div>2022-05-15</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>亚林</span></div></div><div>Dataset</div><div><p>作者回复: 👍🏻👍🏻^^
torch.utils.data.Dataset 类</p></div><div><div>2022-05-11</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2d/0c/1f/fcc777e1.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>乐呵的 hehe</span></div></div><div>老师，您好，下面这个问题，我也有些疑惑，但是我不在微信群里，您可以在这里再解释一下吗？谢谢！
-------------------------------------------------------------------
from torch.utils.data import DataLoader

tensor_dataloader = DataLoader (dataset=my_dataset, batch_size=2, shuffle=True,
                                               num_workers=0)# 进程数，0 表示只有主进程

# 以循环形式输出
for data, target in tensor_dataloader: 
    print (data, target)

# 输出一个 batch
print ('One batch tensor data:', iter (tensor_dataloader).next ())

输出结果：
tensor ([[ 0.7989,  3.1884,  1.2282],

        [-0.6210, -0.9707,  2.5557]]) tensor ([1, 0])

tensor ([[-0.8162, -0.5454,  2.1312],

        [ 0.8296, -0.2082,  1.7351]]) tensor ([0, 0])

tensor ([[ 1.3808,  0.2034,  0.3342],

        [ 0.4650, -1.1422, -0.4364]]) tensor ([1, 1])

tensor ([[ 1.0286, -1.1956,  0.4743],

        [ 3.1708, -0.0568, -1.5444]]) tensor ([1, 0])

tensor ([[ 0.1358,  1.2954, -0.0674],

        [-0.7422, -0.2062,  2.4920]]) tensor ([0, 0])

One batch tensor data:  [tensor ([[ 3.1708, -0.0568, -1.5444],

        [-0.7422, -0.2062,  2.4920]]), tensor ([0, 0])]

迭代器输出的 tensor 怎么会都不在一个 batch 里呢？正常情况下，不是应该输出第二个 batch 里的 tensor 嘛？</div><div><p>作者回复：您好，感谢留言。
因为设置了 shuffle=True 参数。
数据会 shuffle 一下</p></div><div><div>2022-04-27</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/25/89/23/e71f180b.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Geek_fc975d</span></div></div><div>这节课收获颇丰</div><div><p>编辑回复：谢谢反馈，很开心对你有帮助啊～希望后续内容一样能让你觉得不虚此行。</p></div><div><div>2022-04-08</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/25/89/23/e71f180b.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Geek_fc975d</span></div></div><div>为什么我只有__next__函数，而没有 next () 函数</div><div><p>作者回复: hello，你好，感谢留言。
你是说这块吗？
print ('One batch tensor data:', iter (tensor_dataloader).next ())
不会啊，next ()，是 Python 迭代器的内容，跟 Pytorch 没有关系。
具体你是怎么做的呢？</p></div><div><div>2022-04-07</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/d2/f9/6c3ca4db.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>黑羽</span></div></div><div>老师，如果自己有一个图片的数据集，也需要先定义 dataset 类来读取吗</div><div><p>作者回复：你好，黑羽，谢谢留言。
最好是写一个类继承 dataset，然后用 dataloader 来加载数据。
不使用 dataset 的话，你也得自己写一套代码完成相同的功能，那为什么不直接使用 Pytorch 提供的方法呢？^^</p></div><div><div>2021-12-24</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2b/5e/f9/96896116.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>天凉好个秋</span></div></div><div>老师请问 迭代器输出的 batch 和 for 循环输出的 batch 不同的原因是设置了 shuffle=True 后，每次调用实例化对象后都会进行一次打乱吗？</div><div><p>作者回复：你好，天凉好个秋。
是的。是因为把 shuffle 设置为 True 了。</p></div><div><div>2021-12-18</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://thirdwx.qlogo.cn/mmopen/vi_32/dQQR8nfd3k8zO9Z7TjOxSuRb3z6QH9Y7hGZibPuganp8Xspic2LPAIYggKafsP98U46Lc3X1BQ4qw9ROxLZXP4WA/132"></div></div><div><div><div><span>Geek_86b454</span></div></div><div>老师，我是个新手，我想请你帮个忙，能不能帮我下载到 huggingface 的数据集 glue，好几天了，我弄不好</div><div><div>2021-12-15</div><div><div><i></i><span></span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/fc/de/6e2cb960.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>autiplex</span></div></div><div>老师请问 conda install torchvision -c pytorch 后面的 - c pytorch 代表什么</div><div><p>作者回复：你好，autiplex，感谢你的留言。
用 conda 安装软件的标准语法格式为：
conda install -c &lt;channel&gt; &lt;software&gt;
其中 - c 这个参数很重要，通过它来指定软件下载的镜像位置。

-c pytorch 代表去 pytorch 的官方镜像的列表中下载。（去 pytorch 的官网下载）</p></div><div><div>2021-11-11</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2b/13/3e/d028cddd.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>王珎</span></div></div><div>在 PyTorch 中定义数据集，应该继承 Dataset 类</div><div><p>作者回复：你好，王珎。感谢你的留言。
是的，要继承 torch.utils.data.Dataset^^</p></div><div><div>2021-11-08</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="data:image/jpeg;base64,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"></div></div><div><div><div><span>clee</span></div></div><div>你好，我在引入 PIL 的时候遇到一个版本问题，没找到解决办法，请问是哪儿有问题呢？
ImportError: dlopen (/Users/xx/opt/anaconda3/lib/python3.8/site-packages/PIL/_imaging.cpython-38-darwin.so, 2): Library not loaded: @rpath/libjpeg.9.dylib
  Referenced from: /Users/xx/opt/anaconda3/lib/python3.8/site-packages/PIL/_imaging.cpython-38-darwin.so
  Reason: Incompatible library version: _imaging.cpython-38-darwin.so requires version 14.0.0 or later, but libjpeg.9.dylib provides version 12.0.0</div><div><p>作者回复：你好，clee，谢谢你的留言。
可以尝试升级一下 pillow 的版本。
我的运行环境是：
Python 3.7.4
pillow 7.0.0
torchvision 0.10.0
供参考。</p></div><div><div>2021-11-06</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/2a/e1/48/3a981e55.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>林于翔</span></div></div><div>from torch.utils.data import DataLoader
tensor_dataloader = DataLoader (dataset=my_dataset, # 传入的数据集，必须参数
                               batch_size=2,       # 输出的 batch 大小
                               shuffle=True,       # 是否对数据进行重新打乱；
                               num_workers=0)      # 进程数，0 表示只有主进程

# 以循环形式输出
for data, target in tensor_dataloader: 
    print (data, target)

# 输出一个 batch
print ('One batch tensor data:', iter (tensor_dataloader).next ())


输出结果：
tensor ([[ 0.7989,  3.1884,  1.2282],
        [-0.6210, -0.9707,  2.5557]]) tensor ([1, 0])
tensor ([[-0.8162, -0.5454,  2.1312],
        [ 0.8296, -0.2082,  1.7351]]) tensor ([0, 0])
tensor ([[ 1.3808,  0.2034,  0.3342],
        [ 0.4650, -1.1422, -0.4364]]) tensor ([1, 1])
tensor ([[ 1.0286, -1.1956,  0.4743],
        [ 3.1708, -0.0568, -1.5444]]) tensor ([1, 0])
tensor ([[ 0.1358,  1.2954, -0.0674],
        [-0.7422, -0.2062,  2.4920]]) tensor ([0, 0])
One batch tensor data:  [tensor ([[ 3.1708, -0.0568, -1.5444],
        [-0.7422, -0.2062,  2.4920]]), tensor ([0, 0])]

迭代器输出的 tensor 怎么会都不在一个 batch 里呢？正常情况下，不是应该输出第二个 batch 里的 tensor 嘛？</div><div><p>作者回复：你好，林于翔。谢谢你的留言。微信回复完了哈。</p></div><div><div>2021-11-03</div><div><div><i></i><span>4</span></div><div><i></i><span></span></div></div></div></div></div></li><li><div><div data-v-3d2acdda=""><div class="sr-rd-content-center-small"><img class="" src="https://static001.geekbang.org/account/avatar/00/12/e6/3c/b03ed9c2.jpg?x-oss-process=image/resize,m_fill,h_68,w_68"></div></div><div><div><div><span>Swaggy</span></div></div><div>老师好，我现在遇到一个问题，就是同一份代码，我在 1.9.1 中运行，会因为内存不足 Kill 掉，我开了 htop 和 nvidia smi 查看，一开始内存就直接拉满，下边的虚拟内存提示需要两倍的内存，然后 GPU 只用了五分之一还会横跳到 0。一共 300epochs 跑到第 97-98epoch 就会卡住不动，内存依旧拉满，六个 CPU 核心恢复正常状态，之前是一直拉满，然后 GPU 也恢复正常占用。我反复折腾了几次最后都只能强制关机。最后，我把环境换成 1.5.1 的版本，顺利跑完，只用了四百多秒。因为本身就是一个很简单的 lstm 网络，然后在新环境中内存占用一半多点，CPU 全部拉满，GPU 只用了五分之一多点。我想请问老师，我这种情况是为什么，版本区别这么大的吗？我遇到类似情况应该怎么排查，是不是我写的 dataset 部分有问题，因为本身数据量也不大，以 mb 计算的，网络更是很简单。对了，电脑配置 CPU 是 i5-9600k，六核十二线程，GPU 2070 单卡，内存 16g。希望老师能指点迷津，非常感谢</div><div><p>作者回复：你好，Swaggy，感谢你的留言。
遇到这种问题我一般会这么排查。
首先看看，PyTorch、CUDA 以及显卡驱动的型号是不是都对上了。
然后，看看，数据、模型、损失是否加 cuda () 了。
你可以用 watch 命令看看 nvidia-smi，网络比较小，如果只用 nvidia-smi 看的话，可能没有卡到利用率高的时候，因为通过你的描述我感觉没用到 GPU。
最后，给 batch_size 设置小一点看看。如果能确保在 1.5.1 中是用 GPU 训练的话，我觉得环境没配好的可能性大一点</p></div><div><div>2021-10-30</div><div><div><i></i></div><div><i></i><span></span></div></div></div></div></div></li></ul><div> 收起评论<span></span></div></div></sr-rd-content>
                            <toc-bg><toc style="width: initial;overflow: auto!important;"class="simpread-font simpread-theme-root" data-reactid=".j"><outline class="toc-level-h1" data-reactid=".j.0" style="width: 175px;"><active data-reactid=".j.0.0" ></active><a class="toc-outline-theme-github" href="#sr-toc-0" data-reactid=".j.0.1"><span data-reactid=".j.0.1.0"> 06 | Torchvision（上）：数据读取，训练开始的第一步</span></a></outline><outline class="toc-level-h2" data-reactid=".j.1" style="width: 165px;"><active data-reactid=".j.1.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-1" data-reactid=".j.1.1"><span data-reactid=".j.1.1.0">PyTorch 中的数据读取</span></a></outline><outline class="toc-level-h3" data-reactid=".j.2" style="width: 155px;"><active data-reactid=".j.2.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-2" data-reactid=".j.2.1"><span data-reactid=".j.2.1.0">Dataset 类</span></a></outline><outline class="toc-level-h3" data-reactid=".j.3" style="width: 155px;"><active data-reactid=".j.3.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-3" data-reactid=".j.3.1"><span data-reactid=".j.3.1.0">DataLoader 类</span></a></outline><outline class="toc-level-h2" data-reactid=".j.4" style="width: 165px;"><active data-reactid=".j.4.0"></active><a class="toc-outline-theme-github" href="#sr-toc-4" data-reactid=".j.4.1"><span data-reactid=".j.4.1.0">什么是 Torchvision</span></a></outline><outline class="toc-level-h2" data-reactid=".j.5" style="width: 165px;"><active data-reactid=".j.5.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-5" data-reactid=".j.5.1"><span data-reactid=".j.5.1.0">利用 Torchvision 读取数据</span></a></outline><outline class="toc-level-h3" data-reactid=".j.6" style="width: 155px;"><active data-reactid=".j.6.0"></active><pangu> </pangu><a class="toc-outline-theme-github" href="#sr-toc-6" data-reactid=".j.6.1"><span data-reactid=".j.6.1.0">MNIST 数据集简介</span></a></outline><outline class="toc-level-h3" data-reactid=".j.7" style="width: 155px;"><active data-reactid=".j.7.0"></active><a class="toc-outline-theme-github" href="#sr-toc-7" data-reactid=".j.7.1"><span data-reactid=".j.7.1.0">数据读取</span></a></outline><outline class="toc-level-h3" data-reactid=".j.8" style="width: 155px;"><active data-reactid=".j.8.0"></active><a class="toc-outline-theme-github" href="#sr-toc-8" data-reactid=".j.8.1"><span data-reactid=".j.8.1.0">数据预览</span></a></outline><outline class="toc-level-h2" data-reactid=".j.9" style="width: 165px;"><active data-reactid=".j.9.0"></active><a class="toc-outline-theme-github" href="#sr-toc-9" data-reactid=".j.9.1"><span data-reactid=".j.9.1.0">小结</span></a></outline><outline class="toc-level-h2" data-reactid=".j.a" style="width: 165px;"><active data-reactid=".j.a.0"></active><a class="toc-outline-theme-github" href="#sr-toc-10" data-reactid=".j.a.1"><span data-reactid=".j.a.1.0">每课一练</span></a></outline><outline class="toc-level-h2" data-reactid=".j.b" style="width: 165px;"><active data-reactid=".j.b.0"></active><a class="toc-outline-theme-github" href="#sr-toc-11" data-reactid=".j.b.1"><span data-reactid=".j.b.1.0">精选留言 (28)</span></a></outline></toc></toc-bg>
                            <sr-rd-footer>
                                <sr-rd-footer-group>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                    <sr-rd-footer-text>全文完</sr-rd-footer-text>
                                    <sr-rd-footer-line></sr-rd-footer-line>
                                </sr-rd-footer-group>
                                <sr-rd-footer-copywrite>
                                    <div>本文由 <a href="http://ksria.com/simpread" target="_blank">简悦 SimpRead</a> 转码，用以提升阅读体验，<a href="https://time.geekbang.org/column/article/429048" target="_blank">原文地址 </a></div>
                                </sr-rd-footer-copywrite>
                            </sr-rd-footer>
                        </sr-read>
                    </body>
                </html>